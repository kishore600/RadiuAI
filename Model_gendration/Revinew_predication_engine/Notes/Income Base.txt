Current Accuracy Estimate: 60-75%


Why this range?

~75% Accuracy: When used in the center of a large country 
        (e.g., Texas, USA or Maharashtra, India), far from any border. The geocoding is highly reliable here.

~60% Accuracy: When used near a country border or in areas with poor geocoding data. 
            The risk of misidentifying the country is much higher.

The 100% Accurate Part: The function is excellent at reliably fetching the correct national GDP 
per capita number from the World Bank once it knows the country code.


The Inaccurate Part: The function's goal is to find income "within a radius," but it does not and cannot do this. 
It finds the national average for the country the point is in. If you run this in a wealthy neighborhood in a poor country, 
it will return the poor country's low average. This is a fundamental flaw in its design.


1. Class Initialization (__init__)

class RadiusIncomeFetcher:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        })

What it does: This is the constructor that runs when you create a new RadiusIncomeFetcher object.

Why: It sets up a single, reusable requests.Session() object. This is more efficient than creating a 
new connection for every HTTP request. It also sets a common web browser "User-Agent" 
header to help avoid being blocked by the APIs it will call.


2. Point Generation (generate_points_in_radius)

What it does: Generates a list of random geographic coordinates (latitude/longitude points) within a specified circle

Why: To account for potential GPS inaccuracy. Instead of relying on one single point, it creates multiple sample points. If most points agree on the same country,
 the result is more reliable.

Key Steps:

    Always includes the original (center_lat, center_lon) point.

    For each additional point:

        1. Picks a random distance from the center (between 0 and the radius_km).

        2. Picks a random direction (bearing) from the center (between 0 and 360 degrees).

        3. Uses spherical geometry math to calculate the new latitude and longitude based on this 
            distance and direction.

    Returns the list of all points.
    
    @lru_cache(maxsize=1000)
3. Main Reverse Geocoding Function (reverse_geocode_with_fallback)

def reverse_geocode_with_fallback(self, lat: float, lon: float) -> dict:

What it does: This is the core "Where is this point on Earth?" function. It takes a latitude and longitude and 
returns the country code and name for that location.

Why: It needs to know the country to look up the correct economic data.

Key Features:

@lru_cache: This is a decorator that automatically caches the results. If you ask for the same (lat, lon) twice, it returns the saved answer instantly instead of calling the API again. 
                     This saves time and avoids hitting API rate limits.

Fallback System: It tries three different free geocoding services in order. If the first one fails or gives no answer, it tries the next one. 
                        This makes the system much more robust.

4. Geocoding Service Functions (_geocode_nominatim, _geocode_geonames, _geocode_bigdatacloud)

def _geocode_nominatim(self, lat: float, lon: float) -> dict:

What they do: These are the "worker" functions that actually call the external geocoding APIs.
                         They each format the request URL, call their specific API, and parse the JSON response to extract the country code and name.

Why: Different services can be used as backups. Nominatim (OpenStreetMap) is the primary, 
        but if it's down, the code can still work using GeoNames or BigDataCloud.


5. World Bank Data Fetcher (get_worldbank_data)

@lru_cache(maxsize=1000)
def get_worldbank_data(self, country_code: str, indicator: str, start_year: int, end_year: int) -> list:

What it does: Fetches economic data for a specific country and indicator (e.g., "GDP per capita") from the 
                        World Bank's public API over a range of years.

Why: This is where the actual "income" number comes from.


6. Single Point Income Fetcher (fetch_income_for_single_point)

def fetch_income_for_single_point(self, lat, lon, indicator, start_year, end_year) -> dict:

What it does: This is the main workflow for a single coordinate. It combines the previous functions into one sequence.

The Step-by-Step Process:

    Geocode: Call reverse_geocode_with_fallback(lat, lon) to get the country_code.

    Fetch Data: Call get_worldbank_data(country_code, ...) to get the primary economic data.

    Try Alternatives: If step 2 returns no data, call the alternative indicator functions.

    Package Result: Return a neat dictionary containing the country info and the year-value data.


7. Radius Average Fetcher (fetch_avg_income_in_radius)

def fetch_avg_income_in_radius(self, center_lat, center_lon, radius_km=2, ...) -> pd.DataFrame:

What it does: This is the main, top-level function that orchestrates everything and returns the final result.



How to Improve This Function Above 90%

Phase 1

1, Implement a Premium Geocoder ($)

    Problem: Free services (Nominatim, GeoNames) can be slow, rate-limited, and less accurate, especially for remote areas.

    Solution: Integrate a paid service like Google Maps Geocoding API or Mapbox Geocoding API.

    Why: They are significantly faster, more accurate, and can provide additional data like province/state, which is crucial for the next step.

    Result: Drastically reduces country misidentification, boosting confidence scores to near 100% for most non-border areas.

 2. Integrate Sub-National Data

    Problem: National GDP is useless for local estimates.

    Solution: Find and integrate data at a sub-national level (states, regions, metropolitan areas).

    Data Sources:

        1. OECD Regional Database: Provides economic data for regions in OECD countries.

        2. World Bank Subnational Poverty & GDP Data: Available for some countries.

        3. National Statistical Offices: Many countries (USA, UK, Germany, India) publish regional GDP or income data. This requires building a custom dataset.

    Implementation: Modify get_worldbank_data or create a new function get_regional_data(country_code, region_name).

    Result: If you can get the user's state/region, you can return a much more relevant regional income average.


Phase 2: Advanced Estimation & Modeling (Accuracy: 90%+)

    3. Use Proxy Data for Local Estimation

        This is the key to true local estimation. Since local income data is rare, we use proxies that correlate strongly with wealth.

        Nighttime Light Intensity: Satellite data on how bright an area is at night is a very strong proxy for economic activity.

        Source: NASA's Black Marble data or NOAA's VIIRS data.

        How: Download a light intensity map, sample the brightness at your coordinates, and calibrate it against known national/regional GDP data to estimate local GDP.

    4. Population Density: Wealth correlates with urban density.

        Source: WorldPop dataset.

        How: Weight your regional estimate by population density (e.g., an urban area in a poor region might be wealthier than the regional average).

    5. OpenStreetMap (OSM) Data:

        How: Use the OSM Overpass API to count amenities around the coordinates.

        Wealth Indicators: High density of cafes, restaurants, banks, universities.

        Poverty Indicators: Lack of paved roads, certain amenities.

        Result: You can create a "local development score."

    6. Build a Simple Machine Learning Model

        Concept: Train a model to predict income based on the proxy data above.

        Process:

            1. Collect Training Data: For a list of cities/regions where you know the local income (from steps 1/2).

            2. Extract Features: For each location, extract features: nighttime light value, population density, OSM amenity counts, etc.

            3. Train a Model: Use a simple regression model (like Random Forest) to learn the relationship between these features and known income.

            4. Predict: For a new user's location, extract its features and use the model to predict local income.

        Result: This model can provide a hyper-local estimate, far surpassing the accuracy of any single national number.

    Refinement and Validation
