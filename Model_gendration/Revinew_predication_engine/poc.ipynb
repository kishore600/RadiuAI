{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic Density Score (0–10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating traffic scores for 2km radius:\n",
      "================================================================================\n",
      "\n",
      "Location: Times Square, NYC (40.7589, -73.9851)\n",
      "Traffic Score: 0.6/100\n",
      "POI Density: 0.08 per km²\n",
      "Population Density: 360 per km²\n",
      "Road Density: 0.0 per km²\n",
      "Normalized Factors:\n",
      "  POIs: 0.0\n",
      "  Population: 0.02\n",
      "  Roads: 0.0\n",
      "Top POI Categories:\n",
      "  1. public: 16\n",
      "  2. healthcare: 15\n",
      "  3. education: 14\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Location: Los Angeles, CA (34.0522, -118.2437)\n",
      "Traffic Score: 0.6/100\n",
      "POI Density: 0.08 per km²\n",
      "Population Density: 360 per km²\n",
      "Road Density: 0.0 per km²\n",
      "Normalized Factors:\n",
      "  POIs: 0.0\n",
      "  Population: 0.02\n",
      "  Roads: 0.0\n",
      "Top POI Categories:\n",
      "  1. public: 18\n",
      "  2. food: 16\n",
      "  3. education: 16\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Location: London, UK (51.5074, -0.1278)\n",
      "Traffic Score: 1.6/100\n",
      "POI Density: 0.08 per km²\n",
      "Population Density: 1000 per km²\n",
      "Road Density: 0.0 per km²\n",
      "Normalized Factors:\n",
      "  POIs: 0.0\n",
      "  Population: 0.05\n",
      "  Roads: 0.0\n",
      "Top POI Categories:\n",
      "  1. commercial: 18\n",
      "  2. transport: 11\n",
      "  3. food: 8\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Location: Tokyo, Japan (35.6762, 139.6503)\n",
      "Traffic Score: 5.3/100\n",
      "POI Density: 0.08 per km²\n",
      "Population Density: 3470 per km²\n",
      "Road Density: 0.0 per km²\n",
      "Normalized Factors:\n",
      "  POIs: 0.0\n",
      "  Population: 0.17\n",
      "  Roads: 0.0\n",
      "Top POI Categories:\n",
      "  1. public: 19\n",
      "  2. entertainment: 18\n",
      "  3. commercial: 9\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Location: Delhi, India (28.6139, 77.209)\n",
      "Traffic Score: 7.0/100\n",
      "POI Density: 0.08 per km²\n",
      "Population Density: 4640 per km²\n",
      "Road Density: 0.0 per km²\n",
      "Normalized Factors:\n",
      "  POIs: 0.0\n",
      "  Population: 0.23\n",
      "  Roads: 0.0\n",
      "Top POI Categories:\n",
      "  1. commercial: 19\n",
      "  2. food: 19\n",
      "  3. education: 16\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Location: Paris, France (48.8566, 2.3522)\n",
      "Traffic Score: 1.8/100\n",
      "POI Density: 0.08 per km²\n",
      "Population Density: 1190 per km²\n",
      "Road Density: 0.0 per km²\n",
      "Normalized Factors:\n",
      "  POIs: 0.0\n",
      "  Population: 0.06\n",
      "  Roads: 0.0\n",
      "Top POI Categories:\n",
      "  1. commercial: 18\n",
      "  2. retail: 18\n",
      "  3. healthcare: 18\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Location: Moscow, Russia (55.7558, 37.6173)\n",
      "Traffic Score: 0.2/100\n",
      "POI Density: 0.08 per km²\n",
      "Population Density: 90 per km²\n",
      "Road Density: 0.0 per km²\n",
      "Normalized Factors:\n",
      "  POIs: 0.0\n",
      "  Population: 0.0\n",
      "  Roads: 0.0\n",
      "Top POI Categories:\n",
      "  1. food: 19\n",
      "  2. transport: 16\n",
      "  3. retail: 11\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Location: Sydney, Australia (-33.8688, 151.2093)\n",
      "Traffic Score: 0.1/100\n",
      "POI Density: 0.08 per km²\n",
      "Population Density: 30 per km²\n",
      "Road Density: 0.0 per km²\n",
      "Normalized Factors:\n",
      "  POIs: 0.0\n",
      "  Population: 0.0\n",
      "  Roads: 0.0\n",
      "Top POI Categories:\n",
      "  1. food: 18\n",
      "  2. transport: 18\n",
      "  3. retail: 16\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# Configuration\n",
    "OVERPASS_URL = \"https://overpass-api.de/api/interpreter\"\n",
    "\n",
    "class TrafficScoreCalculator:\n",
    "    def __init__(self):\n",
    "        self.poi_categories = {\n",
    "            'commercial': ['shop', 'office', 'commercial'],\n",
    "            'retail': ['supermarket', 'mall', 'convenience', 'department_store'],\n",
    "            'food': ['restaurant', 'cafe', 'fast_food', 'bar', 'pub'],\n",
    "            'education': ['school', 'university', 'college', 'kindergarten'],\n",
    "            'healthcare': ['hospital', 'clinic', 'pharmacy', 'doctors'],\n",
    "            'transport': ['bus_station', 'train_station', 'subway_entrance', 'taxi'],\n",
    "            'entertainment': ['cinema', 'theatre', 'arts_centre', 'nightclub'],\n",
    "            'public': ['library', 'post_office', 'courthouse', 'townhall']\n",
    "        }\n",
    "        \n",
    "        # Country population density data (people per km²)\n",
    "        self.country_densities = {\n",
    "            'US': 36, 'CA': 4, 'UK': 281, 'DE': 232, 'FR': 119,\n",
    "            'CN': 153, 'IN': 464, 'JP': 347, 'BR': 25, 'RU': 9,\n",
    "            'AU': 3, 'MX': 66, 'ZA': 49, 'NG': 226, 'EG': 103,\n",
    "            'IT': 206, 'ES': 94, 'NL': 508, 'BE': 383, 'SE': 25,\n",
    "            'NO': 15, 'FI': 18, 'DK': 137, 'PL': 124, 'TR': 110,\n",
    "            'KR': 527, 'ID': 151, 'PK': 287, 'BD': 1265, 'PH': 368\n",
    "        }\n",
    "        \n",
    "    def calculate_distance(self, lat1, lon1, lat2, lon2):\n",
    "        \"\"\"Calculate distance between two coordinates in km\"\"\"\n",
    "        R = 6371  # Earth radius in km\n",
    "        \n",
    "        lat1_rad = radians(lat1)\n",
    "        lon1_rad = radians(lon1)\n",
    "        lat2_rad = radians(lat2)\n",
    "        lon2_rad = radians(lon2)\n",
    "        \n",
    "        dlon = lon2_rad - lon1_rad\n",
    "        dlat = lat2_rad - lat1_rad\n",
    "        \n",
    "        a = sin(dlat/2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon/2)**2\n",
    "        c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "        \n",
    "        return R * c\n",
    "    \n",
    "    def get_country_code(self, lat, lon):\n",
    "        \"\"\"Get country code from coordinates using Nominatim with proper headers\"\"\"\n",
    "        url = \"https://nominatim.openstreetmap.org/reverse\"\n",
    "        headers = {\n",
    "            'User-Agent': 'TrafficScoreCalculator/1.0 (https://example.com; contact@example.com)'\n",
    "        }\n",
    "        params = {\n",
    "            'format': 'json',\n",
    "            'lat': lat,\n",
    "            'lon': lon,\n",
    "            'zoom': 3,\n",
    "            'addressdetails': 1\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if 'address' in data and 'country_code' in data['address']:\n",
    "                return data['address']['country_code'].upper()\n",
    "            else:\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting country code: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_population_density(self, lat, lon, radius_km=1):\n",
    "        \"\"\"\n",
    "        Estimate population density based on country data and urban/rural classification\n",
    "        \"\"\"\n",
    "        # Get country code first\n",
    "        country_code = self.get_country_code(lat, lon)\n",
    "        \n",
    "        # Get POI count to determine urban/rural classification\n",
    "        poi_count = self.query_overpass_count(lat, lon, 2000)  # Check POIs in 2km radius\n",
    "        \n",
    "        # Get base density for country or use default\n",
    "        base_density = self.country_densities.get(country_code, 100) if country_code else 100\n",
    "        \n",
    "        # Adjust based on urban/rural classification\n",
    "        if poi_count > 100:\n",
    "            # Urban area - multiply base density\n",
    "            density = base_density * 100\n",
    "        elif poi_count > 30:\n",
    "            # Suburban area\n",
    "            density = base_density * 50\n",
    "        else:\n",
    "            # Rural area\n",
    "            density = base_density * 10\n",
    "            \n",
    "        return density\n",
    "    \n",
    "    def query_overpass_count(self, lat, lon, radius):\n",
    "        \"\"\"Query Overpass API for count of POIs around the location\"\"\"\n",
    "        # Define the bounding box\n",
    "        radius_deg = radius / 111000  # Approximate conversion from meters to degrees\n",
    "        min_lat = lat - radius_deg\n",
    "        max_lat = lat + radius_deg\n",
    "        min_lon = lon - radius_deg\n",
    "        max_lon = lon + radius_deg\n",
    "        \n",
    "        # Overpass QL query for counting POIs\n",
    "        query = f\"\"\"\n",
    "        [out:json];\n",
    "        (\n",
    "          node[\"shop\"]({min_lat},{min_lon},{max_lat},{max_lon});\n",
    "          node[\"amenity\"]({min_lat},{min_lon},{max_lat},{max_lon});\n",
    "          node[\"office\"]({min_lat},{min_lon},{max_lat},{max_lon});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(OVERPASS_URL, data=query)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            # Count elements\n",
    "            total_count = 0\n",
    "            for element in data['elements']:\n",
    "                if 'tags' in element:\n",
    "                    total_count += 1\n",
    "            \n",
    "            return total_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Overpass API error: {e}\")\n",
    "            # Return a reasonable estimate based on urban/rural classification\n",
    "            if \"timeout\" in str(e).lower():\n",
    "                return 100  # Reasonable default for urban areas\n",
    "            return np.random.randint(20, 100)\n",
    "    \n",
    "    def query_overpass_roads(self, lat, lon, radius):\n",
    "        \"\"\"Query Overpass API for roads around the location\"\"\"\n",
    "        # Define the bounding box\n",
    "        radius_deg = radius / 111000\n",
    "        min_lat = lat - radius_deg\n",
    "        max_lat = lat + radius_deg\n",
    "        min_lon = lon - radius_deg\n",
    "        max_lon = lon + radius_deg\n",
    "        \n",
    "        # Overpass QL query for roads\n",
    "        query = f\"\"\"\n",
    "        [out:json];\n",
    "        (\n",
    "          way[\"highway\"]({min_lat},{min_lon},{max_lat},{max_lon});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(OVERPASS_URL, data=query)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            # Count road elements\n",
    "            road_count = 0\n",
    "            for element in data['elements']:\n",
    "                if 'tags' in element and 'highway' in element['tags']:\n",
    "                    road_count += 1\n",
    "            \n",
    "            return road_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Overpass API error for roads: {e}\")\n",
    "            # Return a reasonable estimate\n",
    "            return np.random.randint(5, 20)\n",
    "    \n",
    "    def get_poi_density(self, lat, lon, radius_km):\n",
    "        \"\"\"Calculate POI density within the given radius\"\"\"\n",
    "        radius_m = radius_km * 1000\n",
    "        poi_count = self.query_overpass_count(lat, lon, radius_m)\n",
    "        \n",
    "        # Calculate area in km²\n",
    "        area_km2 = 3.1416 * (radius_km ** 2)\n",
    "        \n",
    "        return poi_count / area_km2 if area_km2 > 0 else 0\n",
    "    \n",
    "    def get_road_density(self, lat, lon, radius_km):\n",
    "        \"\"\"Calculate road density within the given radius\"\"\"\n",
    "        radius_m = radius_km * 1000\n",
    "        road_count = self.query_overpass_roads(lat, lon, radius_m)\n",
    "        \n",
    "        # Calculate area in km²\n",
    "        area_km2 = 3.1416 * (radius_km ** 2)\n",
    "        \n",
    "        return road_count / area_km2 if area_km2 > 0 else 0\n",
    "    \n",
    "    def get_poi_category_breakdown(self, lat, lon, radius_km):\n",
    "        \"\"\"Get breakdown of POIs by category\"\"\"\n",
    "        radius_m = radius_km * 1000\n",
    "        category_breakdown = {}\n",
    "        \n",
    "        for category in self.poi_categories:\n",
    "            # For simplicity, we'll use a count-based approach rather than detailed queries\n",
    "            # In a real implementation, you would query for each category\n",
    "            category_breakdown[category] = np.random.randint(0, 20)\n",
    "            \n",
    "        return category_breakdown\n",
    "    \n",
    "    def calculate_traffic_score(self, lat, lon, radius_km=1):\n",
    "        \"\"\"\n",
    "        Calculate traffic score based on POI density, population density, and road density\n",
    "        Returns a score between 0-100\n",
    "        \"\"\"\n",
    "        # Get POI density\n",
    "        poi_density = self.get_poi_density(lat, lon, radius_km)\n",
    "        \n",
    "        # Get population density\n",
    "        pop_density = self.get_population_density(lat, lon, radius_km)\n",
    "        \n",
    "        # Get road density\n",
    "        road_density = self.get_road_density(lat, lon, radius_km)\n",
    "        \n",
    "        # Normalize factors (0-1 range)\n",
    "        # These normalization values can be adjusted based on typical ranges\n",
    "        norm_poi = min(1.0, poi_density / 50)  # Assume 50 POIs/km² is very high\n",
    "        norm_pop = min(1.0, pop_density / 20000)  # Assume 20,000 people/km² is very high\n",
    "        norm_road = min(1.0, road_density / 10)  # Assume 10 roads/km² is very high\n",
    "        \n",
    "        # Calculate weighted score (0-100)\n",
    "        # Weights can be adjusted based on which factors are most important\n",
    "        traffic_score = (norm_poi * 0.4 + norm_pop * 0.3 + norm_road * 0.3) * 100\n",
    "        \n",
    "        # Get POI category breakdown\n",
    "        poi_breakdown = self.get_poi_category_breakdown(lat, lon, radius_km)\n",
    "        \n",
    "        return {\n",
    "            'traffic_score': round(traffic_score, 1),\n",
    "            'poi_density': round(poi_density, 2),\n",
    "            'population_density': round(pop_density, 2),\n",
    "            'road_density': round(road_density, 2),\n",
    "            'poi_breakdown': poi_breakdown,\n",
    "            'normalized_factors': {\n",
    "                'poi': round(norm_poi, 2),\n",
    "                'population': round(norm_pop, 2),\n",
    "                'roads': round(norm_road, 2)\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    calculator = TrafficScoreCalculator()\n",
    "    \n",
    "    # Test locations (latitude, longitude)\n",
    "    test_locations = [\n",
    "        (40.7589, -73.9851, \"Times Square, NYC\"),\n",
    "        (34.0522, -118.2437, \"Los Angeles, CA\"),\n",
    "        (51.5074, -0.1278, \"London, UK\"),\n",
    "        (35.6762, 139.6503, \"Tokyo, Japan\"),\n",
    "        (28.6139, 77.2090, \"Delhi, India\"),\n",
    "        (48.8566, 2.3522, \"Paris, France\"),\n",
    "        (55.7558, 37.6173, \"Moscow, Russia\"),\n",
    "        (-33.8688, 151.2093, \"Sydney, Australia\")\n",
    "    ]\n",
    "    \n",
    "    radius_km = 2  \n",
    "    \n",
    "    print(f\"Calculating traffic scores for {radius_km}km radius:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for lat, lon, name in test_locations:\n",
    "        result = calculator.calculate_traffic_score(lat, lon, radius_km)\n",
    "        \n",
    "        print(f\"\\nLocation: {name} ({lat}, {lon})\")\n",
    "        print(f\"Traffic Score: {result['traffic_score']}/100\")\n",
    "        print(f\"POI Density: {result['poi_density']} per km²\")\n",
    "        print(f\"Population Density: {result['population_density']} per km²\")\n",
    "        print(f\"Road Density: {result['road_density']} per km²\")\n",
    "        print(\"Normalized Factors:\")\n",
    "        print(f\"  POIs: {result['normalized_factors']['poi']}\")\n",
    "        print(f\"  Population: {result['normalized_factors']['population']}\")\n",
    "        print(f\"  Roads: {result['normalized_factors']['roads']}\")\n",
    "        \n",
    "        # Print top 3 POI categories\n",
    "        sorted_categories = sorted(result['poi_breakdown'].items(), key=lambda x: x[1], reverse=True)\n",
    "        print(\"Top POI Categories:\")\n",
    "        for i, (category, count) in enumerate(sorted_categories[:3]):\n",
    "            if count > 0:\n",
    "                print(f\"  {i+1}. {category}: {count}\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "        time.sleep(2)  # Be nice to the API\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income Base on india's gdp for per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_avg_income_from_location(lat: float, lon: float, \n",
    "                                   indicator: str = \"NY.GDP.PCAP.CD\", \n",
    "                                   start_year: int = 2020, \n",
    "                                   end_year: int = 2020):\n",
    "    \"\"\"\n",
    "    Fetch average income (GDP per capita) based on latitude & longitude.\n",
    "    \n",
    "    Steps:\n",
    "      1. Reverse geocode lat/lon -> country code (ISO2).\n",
    "      2. Query World Bank API for GDP per capita.\n",
    "    \n",
    "    Args:\n",
    "        lat (float): Latitude.\n",
    "        lon (float): Longitude.\n",
    "        indicator (str): World Bank indicator code (default GDP per capita).\n",
    "        start_year (int): Start year.\n",
    "        end_year (int): End year.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with year and value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Reverse geocode using Nominatim (OpenStreetMap)\n",
    "    geo_url = f\"https://nominatim.openstreetmap.org/reverse?format=json&lat={lat}&lon={lon}&zoom=5&addressdetails=1\"\n",
    "    geo_response = requests.get(geo_url, headers={\"User-Agent\": \"income-fetcher\"})\n",
    "    \n",
    "    if geo_response.status_code != 200:\n",
    "        raise Exception(f\"Geocoding failed: {geo_response.status_code}\")\n",
    "    \n",
    "    geo_data = geo_response.json()\n",
    "    if \"address\" not in geo_data or \"country_code\" not in geo_data[\"address\"]:\n",
    "        raise Exception(\"Could not determine country code from lat/lon\")\n",
    "    \n",
    "    country_code = geo_data[\"address\"][\"country_code\"].upper()\n",
    "    \n",
    "    # Step 2: Query World Bank API\n",
    "    wb_url = f\"http://api.worldbank.org/v2/country/{country_code}/indicator/{indicator}?format=json&date={start_year}:{end_year}\"\n",
    "    wb_response = requests.get(wb_url)\n",
    "    \n",
    "    if wb_response.status_code != 200:\n",
    "        raise Exception(f\"World Bank API request failed: {wb_response.status_code}\")\n",
    "    \n",
    "    data = wb_response.json()\n",
    "    if not data or len(data) < 2:\n",
    "        raise Exception(\"No data found from World Bank API\")\n",
    "    \n",
    "    records = [\n",
    "        {\"year\": item[\"date\"], \"value\": item[\"value\"], \"country\": country_code}\n",
    "        for item in data[1] if item[\"value\"] is not None\n",
    "    ]\n",
    "    \n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "# Example: Chennai, India (approx lat/lon)\n",
    "income_df = fetch_avg_income_from_location(13.0827, 80.2707, start_year=2020, end_year=2020)\n",
    "print(income_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing competition count (in radius) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status\": \"success\",\n",
      "  \"total_competitors\": 4,\n",
      "  \"search_parameters\": {\n",
      "    \"latitude\": 11.0168,\n",
      "    \"longitude\": 76.9558,\n",
      "    \"radius\": 1000,\n",
      "    \"business_types\": [\n",
      "      \"supermarket\"\n",
      "    ]\n",
      "  },\n",
      "  \"competitors\": [\n",
      "    {\n",
      "      \"name\": \"Spencers\",\n",
      "      \"type\": \"supermarket\",\n",
      "      \"distance\": 234.493622578696,\n",
      "      \"latitude\": 11.0170651,\n",
      "      \"longitude\": 76.9579314,\n",
      "      \"address\": \"Patel Road\",\n",
      "      \"google_maps_url\": \"https://www.google.com/maps?q=11.0170651,76.9579314\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Giriyaas\",\n",
      "      \"type\": \"supermarket\",\n",
      "      \"distance\": 473.6077724884785,\n",
      "      \"latitude\": 11.0168427,\n",
      "      \"longitude\": 76.960139,\n",
      "      \"address\": \"Address not specified\",\n",
      "      \"google_maps_url\": \"https://www.google.com/maps?q=11.0168427,76.960139\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"VIVEK'S\",\n",
      "      \"type\": \"supermarket\",\n",
      "      \"distance\": 706.2968141935211,\n",
      "      \"latitude\": 11.01896,\n",
      "      \"longitude\": 76.9618855,\n",
      "      \"address\": \"Address not specified\",\n",
      "      \"google_maps_url\": \"https://www.google.com/maps?q=11.01896,76.9618855\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"VIVEK'S\",\n",
      "      \"type\": \"supermarket\",\n",
      "      \"distance\": 795.9234455366184,\n",
      "      \"latitude\": 11.0191127,\n",
      "      \"longitude\": 76.9627012,\n",
      "      \"address\": \"Address not specified\",\n",
      "      \"google_maps_url\": \"https://www.google.com/maps?q=11.0191127,76.9627012\"\n",
      "    }\n",
      "  ],\n",
      "  \"statistics\": {\n",
      "    \"closest\": {\n",
      "      \"name\": \"Spencers\",\n",
      "      \"distance\": 234.493622578696,\n",
      "      \"type\": \"supermarket\"\n",
      "    },\n",
      "    \"farthest\": {\n",
      "      \"name\": \"VIVEK'S\",\n",
      "      \"distance\": 795.9234455366184,\n",
      "      \"type\": \"supermarket\"\n",
      "    },\n",
      "    \"average_distance\": 552.5804136993286,\n",
      "    \"business_density\": 1.2732406201955062,\n",
      "    \"count_by_type\": {\n",
      "      \"supermarket\": 4\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "import sys\n",
    "import urllib.parse\n",
    "from typing import List, Dict, Optional, Tuple, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Install required packages if missing\n",
    "try:\n",
    "    from haversine import haversine\n",
    "except ImportError:\n",
    "    print(\"Installing required haversine package...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"haversine\"])\n",
    "    from haversine import haversine\n",
    "\n",
    "try:\n",
    "    import requests\n",
    "except ImportError:\n",
    "    print(\"Installing required requests package...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"requests\"])\n",
    "    import requests\n",
    "\n",
    "@dataclass\n",
    "class Competitor:\n",
    "    name: str\n",
    "    type: str\n",
    "    distance: float\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    osm_id: str\n",
    "    osm_type: str\n",
    "    address: str = \"\"\n",
    "    google_maps_url: str = \"\"\n",
    "\n",
    "class CompetitorAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        self.request_timeout = 45\n",
    "        self.rate_limit_delay = 2  # seconds between requests\n",
    "    \n",
    "    def set_parameters(self, latitude: float, longitude: float, radius: int, business_types: List[str]):\n",
    "        \"\"\"Set analysis parameters directly\"\"\"\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        self.radius = radius\n",
    "        self.business_types = business_types\n",
    "        \n",
    "    def get_user_input(self) -> Tuple[float, float, int, List[str]]:\n",
    "        \"\"\"Get comprehensive user input including location\"\"\"\n",
    "        print(\"=== Competitor Analysis Tool ===\\n\")\n",
    "        print(\"This tool helps you find competitors by name and type in any location.\\n\")\n",
    "        \n",
    "        # Get location input\n",
    "        latitude, longitude = self._get_location_input()\n",
    "        \n",
    "        # Get radius input\n",
    "        radius = self._get_radius_input()\n",
    "        \n",
    "        # Get business types\n",
    "        business_types = self._get_business_types_input()\n",
    "        \n",
    "        return latitude, longitude, radius, business_types\n",
    "    \n",
    "    def _get_location_input(self) -> Tuple[float, float]:\n",
    "        \"\"\"Get location coordinates from user with flexible input options\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                print(\"\\n📍 LOCATION INPUT OPTIONS:\")\n",
    "                print(\"1. Use default location (Chennai, India)\")\n",
    "                print(\"2. Enter latitude and longitude\")\n",
    "                print(\"3. Enter a place name (city, address, etc.)\")\n",
    "                \n",
    "                option = input(\"\\nChoose option (1/2/3): \").strip()\n",
    "                \n",
    "                if option == '1' or option == '':\n",
    "                    print(\"Using Chennai, India as location (13.0827, 80.2707)\")\n",
    "                    return 13.0827, 80.2707\n",
    "                \n",
    "                elif option == '2':\n",
    "                    lat = float(input(\"Enter latitude (e.g., 13.0827): \").strip())\n",
    "                    lon = float(input(\"Enter longitude (e.g., 80.2707): \").strip())\n",
    "                    \n",
    "                    if not (-90 <= lat <= 90) or not (-180 <= lon <= 180):\n",
    "                        print(\"Invalid coordinates. Latitude must be between -90 and 90, longitude between -180 and 180.\")\n",
    "                        continue\n",
    "                        \n",
    "                    return lat, lon\n",
    "                \n",
    "                elif option == '3':\n",
    "                    place_name = input(\"Enter place name (e.g., 'Paris, France', 'Times Square'): \").strip()\n",
    "                    if place_name:\n",
    "                        coords = self._geocode_place_name(place_name)\n",
    "                        if coords:\n",
    "                            return coords\n",
    "                        else:\n",
    "                            print(\"Could not find coordinates for that place. Please try another method.\")\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    print(\"Invalid option. Please choose 1, 2, or 3.\")\n",
    "                    \n",
    "            except ValueError:\n",
    "                print(\"Please enter valid numbers for coordinates.\")\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nOperation cancelled.\")\n",
    "                return 13.0827, 80.2707  # Default fallback\n",
    "    \n",
    "    def _geocode_place_name(self, place_name: str) -> Optional[Tuple[float, float]]:\n",
    "        \"\"\"Convert place name to coordinates using Nominatim (OpenStreetMap's geocoder)\"\"\"\n",
    "        try:\n",
    "            print(f\"Looking up coordinates for: {place_name}\")\n",
    "            time.sleep(1)  # Rate limiting\n",
    "            \n",
    "            nominatim_url = \"https://nominatim.openstreetmap.org/search\"\n",
    "            params = {\n",
    "                'q': place_name,\n",
    "                'format': 'json',\n",
    "                'limit': 1\n",
    "            }\n",
    "            \n",
    "            response = requests.get(nominatim_url, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            if data:\n",
    "                lat = float(data[0]['lat'])\n",
    "                lon = float(data[0]['lon'])\n",
    "                print(f\"Found coordinates: {lat:.6f}, {lon:.6f}\")\n",
    "                return lat, lon\n",
    "            else:\n",
    "                print(\"No results found for that place name.\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Geocoding error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _get_radius_input(self) -> int:\n",
    "        \"\"\"Get search radius from user\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                radius_input = input(\"\\nEnter search radius in meters (max 2000, default 500): \").strip()\n",
    "                if not radius_input:\n",
    "                    radius = 500\n",
    "                else:\n",
    "                    radius = int(radius_input)\n",
    "                \n",
    "                if radius <= 0:\n",
    "                    print(\"Please enter a positive number.\")\n",
    "                    continue\n",
    "                if radius > 2000:\n",
    "                    print(\"Radius too large. Maximum is 2000 meters (2km).\")\n",
    "                    continue\n",
    "                return radius\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid number.\")\n",
    "    \n",
    "    def _get_business_types_input(self) -> List[str]:\n",
    "        \"\"\"Get business types from user with text input option\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SELECT BUSINESS TYPES TO SEARCH FOR\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Common business types with better categorization\n",
    "        business_categories = {\n",
    "            'food': ['restaurant', 'cafe', 'fast_food', 'bakery', 'food_court'],\n",
    "            'retail': ['supermarket', 'convenience', 'clothes', 'shoes', 'electronics', 'mall'],\n",
    "            'services': ['bank', 'pharmacy', 'hospital', 'dentist', 'post_office'],\n",
    "            'entertainment': ['cinema', 'theatre', 'bar', 'pub', 'nightclub'],\n",
    "            'other': ['fuel', 'car_wash', 'hotel', 'library', 'school']\n",
    "        }\n",
    "        \n",
    "        print(\"\\nCommon business types (you can also enter custom types):\")\n",
    "        for i, (category, types) in enumerate(business_categories.items(), 1):\n",
    "            print(f\"{i}. {category.title()}: {', '.join(types)}\")\n",
    "        \n",
    "        print(\"0. Enter custom business types\")\n",
    "        \n",
    "        selected_types = []\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                print(\"\\nYou can:\")\n",
    "                print(\"- Enter category numbers (e.g., '1,2' for food and retail)\")\n",
    "                print(\"- Enter specific business types (e.g., 'restaurant,cafe')\")\n",
    "                print(\"- Type 'done' when finished\")\n",
    "                \n",
    "                choice = input(\"\\nEnter your choice: \").strip().lower()\n",
    "                \n",
    "                if choice == 'done':\n",
    "                    if not selected_types:\n",
    "                        print(\"No types selected. Using default: restaurant, cafe\")\n",
    "                        return ['restaurant', 'cafe']\n",
    "                    print(f\"\\n✅ Selected business types: {', '.join(selected_types)}\")\n",
    "                    return selected_types\n",
    "                \n",
    "                if choice == '0':\n",
    "                    custom_types = input(\"Enter custom business types (comma-separated): \").strip()\n",
    "                    if custom_types:\n",
    "                        types_list = [t.strip() for t in custom_types.split(',') if t.strip()]\n",
    "                        for business_type in types_list:\n",
    "                            if self._validate_business_type(business_type):\n",
    "                                selected_types.append(business_type)\n",
    "                                print(f\"✓ Added '{business_type}'\")\n",
    "                    continue\n",
    "                \n",
    "                # Process category numbers or specific types\n",
    "                choices = [c.strip() for c in choice.split(',') if c.strip()]\n",
    "                \n",
    "                for c in choices:\n",
    "                    if c.isdigit() and int(c) in range(1, len(business_categories) + 1):\n",
    "                        # It's a category number\n",
    "                        category_key = list(business_categories.keys())[int(c) - 1]\n",
    "                        for business_type in business_categories[category_key]:\n",
    "                            if business_type not in selected_types:\n",
    "                                selected_types.append(business_type)\n",
    "                        print(f\"✓ Added all {category_key} businesses\")\n",
    "                    else:\n",
    "                        # It's a specific business type\n",
    "                        if self._validate_business_type(c):\n",
    "                            if c not in selected_types:\n",
    "                                selected_types.append(c)\n",
    "                                print(f\"✓ Added '{c}'\")\n",
    "                \n",
    "                if selected_types:\n",
    "                    print(f\"\\nCurrent selection: {', '.join(selected_types)}\")\n",
    "                    \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nOperation cancelled.\")\n",
    "                if selected_types:\n",
    "                    return selected_types\n",
    "                else:\n",
    "                    return ['restaurant', 'cafe']\n",
    "    \n",
    "    def _validate_business_type(self, business_type: str) -> bool:\n",
    "        \"\"\"Validate that the business type is reasonable\"\"\"\n",
    "        if not business_type or len(business_type) > 50:\n",
    "            print(\"Business type must be between 1 and 50 characters.\")\n",
    "            return False\n",
    "        \n",
    "        # Basic validation\n",
    "        invalid_chars = ['\"', \"'\", ';', '(', ')', '[', ']', '{', '}', '~', '*']\n",
    "        if any(char in business_type for char in invalid_chars):\n",
    "            print(\"Business type contains invalid characters.\")\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def search_competitors(self) -> Optional[dict]:\n",
    "        \"\"\"Search for businesses using Overpass API\"\"\"\n",
    "        try:\n",
    "            time.sleep(self.rate_limit_delay)\n",
    "            \n",
    "            query = self._build_query(self.latitude, self.longitude, self.radius, self.business_types)\n",
    "            \n",
    "            response = requests.get(\n",
    "                self.overpass_url, \n",
    "                params={\"data\": query}, \n",
    "                timeout=self.request_timeout\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            return response.json()\n",
    "            \n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"⏰ Request timed out. The server is taking too long to respond.\")\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(\"📡 Network connection error. Please check your internet connection.\")\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"❌ HTTP error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {e}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _build_query(self, lat: float, lon: float, radius: int, business_types: List[str]) -> str:\n",
    "        \"\"\"Build Overpass query for business search\"\"\"\n",
    "        # Separate amenity and shop types\n",
    "        amenity_types = []\n",
    "        shop_types = []\n",
    "        \n",
    "        for business_type in business_types:\n",
    "            # Common amenity types\n",
    "            if business_type in ['restaurant', 'cafe', 'fast_food', 'bank', 'pharmacy', \n",
    "                               'hospital', 'school', 'fuel', 'cinema', 'theatre', 'bar']:\n",
    "                amenity_types.append(business_type)\n",
    "            # Common shop types or assume shop\n",
    "            else:\n",
    "                shop_types.append(business_type)\n",
    "        \n",
    "        query_parts = []\n",
    "        \n",
    "        if amenity_types:\n",
    "            amenity_regex = \"|\".join(amenity_types)\n",
    "            query_parts.extend([\n",
    "                f'node[\"amenity\"~\"{amenity_regex}\"](around:{radius},{lat},{lon});',\n",
    "                f'way[\"amenity\"~\"{amenity_regex}\"](around:{radius},{lat},{lon});'\n",
    "            ])\n",
    "        \n",
    "        if shop_types:\n",
    "            shop_regex = \"|\".join(shop_types)\n",
    "            query_parts.extend([\n",
    "                f'node[\"shop\"~\"{shop_regex}\"](around:{radius},{lat},{lon});',\n",
    "                f'way[\"shop\"~\"{shop_regex}\"](around:{radius},{lat},{lon});'\n",
    "            ])\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          {\"\".join(query_parts)}\n",
    "        );\n",
    "        out body;\n",
    "        >;\n",
    "        out skel qt;\n",
    "        \"\"\"\n",
    "        \n",
    "        return query\n",
    "    \n",
    "    def process_results(self, data: dict) -> List[Competitor]:\n",
    "        \"\"\"Process API results and create Competitor objects\"\"\"\n",
    "        if not data or 'elements' not in data:\n",
    "            return []\n",
    "        \n",
    "        competitors = []\n",
    "        processed_ids = set()\n",
    "        \n",
    "        for element in data.get('elements', []):\n",
    "            try:\n",
    "                competitor = self._process_element(element, processed_ids)\n",
    "                if competitor:\n",
    "                    competitors.append(competitor)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        competitors.sort(key=lambda x: x.distance)\n",
    "        return competitors\n",
    "    \n",
    "    def _process_element(self, element: dict, processed_ids: set) -> Optional[Competitor]:\n",
    "        \"\"\"Process individual OSM element into Competitor object\"\"\"\n",
    "        if element['type'] not in ['node', 'way']:\n",
    "            return None\n",
    "        \n",
    "        tags = element.get('tags', {})\n",
    "        name = tags.get('name', '').strip()\n",
    "        \n",
    "        # Skip unnamed or invalid entries\n",
    "        if not name or name.lower() in ['yes', 'no', 'unknown', 'none']:\n",
    "            return None\n",
    "        \n",
    "        # Check for duplicates\n",
    "        osm_id = f\"{element['type']}_{element['id']}\"\n",
    "        if osm_id in processed_ids:\n",
    "            return None\n",
    "        processed_ids.add(osm_id)\n",
    "        \n",
    "        # Determine business type\n",
    "        business_type = tags.get('amenity') or tags.get('shop', 'unknown')\n",
    "        \n",
    "        # Get coordinates\n",
    "        if element['type'] == 'node':\n",
    "            lat, lon = element.get('lat', 0), element.get('lon', 0)\n",
    "        else:\n",
    "            center = element.get('center', {})\n",
    "            lat, lon = center.get('lat', 0), center.get('lon', 0)\n",
    "        \n",
    "        # Validate coordinates\n",
    "        if not (-90 <= lat <= 90) or not (-180 <= lon <= 180):\n",
    "            return None\n",
    "        \n",
    "        # Calculate distance\n",
    "        try:\n",
    "            distance = haversine((self.latitude, self.longitude), (lat, lon)) * 1000\n",
    "        except:\n",
    "            distance = float('inf')\n",
    "        \n",
    "        # Get address information\n",
    "        address_parts = []\n",
    "        for addr_key in ['addr:street', 'addr:road', 'addr:full']:\n",
    "            if tags.get(addr_key):\n",
    "                address_parts.append(tags.get(addr_key))\n",
    "                break\n",
    "        \n",
    "        if tags.get('addr:housenumber'):\n",
    "            address_parts.append(tags.get('addr:housenumber'))\n",
    "        \n",
    "        address = \", \".join(address_parts) if address_parts else \"Address not specified\"\n",
    "        \n",
    "        # Create Google Maps URL\n",
    "        google_maps_url = f\"https://www.google.com/maps?q={lat},{lon}\"\n",
    "        \n",
    "        return Competitor(\n",
    "            name=name,\n",
    "            type=business_type,\n",
    "            distance=distance,\n",
    "            latitude=lat,\n",
    "            longitude=lon,\n",
    "            osm_id=element['id'],\n",
    "            osm_type=element['type'],\n",
    "            address=address,\n",
    "            google_maps_url=google_maps_url\n",
    "        )\n",
    "    \n",
    "    def display_results(self, competitors: List[Competitor]):\n",
    "        \"\"\"Display results with Google Maps links\"\"\"\n",
    "        if not competitors:\n",
    "            print(f\"\\n❌ No businesses found within the specified radius ({self.radius}m).\")\n",
    "            return\n",
    "        \n",
    "        valid_competitors = [c for c in competitors if c.distance <= self.radius]\n",
    "        \n",
    "        if not valid_competitors:\n",
    "            print(f\"\\n❌ No businesses found within {self.radius} meters.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{'🎯'*50}\")\n",
    "        print(f\"           FOUND {len(valid_competitors)} BUSINESSES\")\n",
    "        print(f\"           WITHIN {self.radius} METERS RADIUS\")\n",
    "        print(f\"{'🎯'*50}\")\n",
    "        \n",
    "        # Group by type\n",
    "        businesses_by_type = {}\n",
    "        for comp in valid_competitors:\n",
    "            if comp.type not in businesses_by_type:\n",
    "                businesses_by_type[comp.type] = []\n",
    "            businesses_by_type[comp.type].append(comp)\n",
    "        \n",
    "        # Display results\n",
    "        for business_type, comp_list in sorted(businesses_by_type.items()):\n",
    "            print(f\"\\n📋 {business_type.upper()} ({len(comp_list)} found):\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            for i, comp in enumerate(comp_list, 1):\n",
    "                print(f\"{i:2d}. {comp.name}\")\n",
    "                print(f\"    📍 Distance: {comp.distance:.0f}m\")\n",
    "                print(f\"    📍 Coordinates: {comp.latitude:.6f}, {comp.longitude:.6f}\")\n",
    "                print(f\"    🏠 Address: {comp.address}\")\n",
    "                print(f\"    🗺️  Google Maps: {comp.google_maps_url}\")\n",
    "                print()\n",
    "        \n",
    "        # Statistics\n",
    "        print(f\"{'📊'*50}\")\n",
    "        print(\"BUSINESS INTELLIGENCE SUMMARY:\")\n",
    "        print(f\"{'📊'*50}\")\n",
    "        \n",
    "        for business_type, comp_list in sorted(businesses_by_type.items()):\n",
    "            print(f\"  {business_type}: {len(comp_list)} businesses\")\n",
    "        \n",
    "        if valid_competitors:\n",
    "            closest = min(valid_competitors, key=lambda x: x.distance)\n",
    "            farthest = max(valid_competitors, key=lambda x: x.distance)\n",
    "            avg_distance = sum(c.distance for c in valid_competitors) / len(valid_competitors)\n",
    "            \n",
    "            print(f\"\\n  📍 Closest: {closest.name} ({closest.distance:.0f}m - {closest.type})\")\n",
    "            print(f\"  📍 Farthest: {farthest.name} ({farthest.distance:.0f}m - {farthest.type})\")\n",
    "            print(f\"  📍 Average distance: {avg_distance:.0f}m\")\n",
    "            \n",
    "            # Market saturation analysis\n",
    "            total_density = len(valid_competitors) / (3.14159 * (self.radius/1000) ** 2)  # businesses per km²\n",
    "            print(f\"  📍 Business density: {total_density:.1f} businesses per km²\")\n",
    "    \n",
    "    def get_results_json(self, competitors: List[Competitor]) -> Dict[str, Any]:\n",
    "        \"\"\"Return results as JSON for frontend consumption\"\"\"\n",
    "        valid_competitors = [c for c in competitors if c.distance <= self.radius]\n",
    "        \n",
    "        if not valid_competitors:\n",
    "            return {\n",
    "                \"status\": \"no_competitors_found\",\n",
    "                \"message\": f\"No businesses found within {self.radius} meters\",\n",
    "                \"search_parameters\": {\n",
    "                    \"latitude\": self.latitude,\n",
    "                    \"longitude\": self.longitude,\n",
    "                    \"radius\": self.radius,\n",
    "                    \"business_types\": self.business_types\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Group by type\n",
    "        businesses_by_type = {}\n",
    "        for comp in valid_competitors:\n",
    "            if comp.type not in businesses_by_type:\n",
    "                businesses_by_type[comp.type] = []\n",
    "            businesses_by_type[comp.type].append(comp)\n",
    "        \n",
    "        # Prepare competitors list\n",
    "        competitors_list = []\n",
    "        for business_type, comp_list in sorted(businesses_by_type.items()):\n",
    "            for comp in comp_list:\n",
    "                competitors_list.append({\n",
    "                    \"name\": comp.name,\n",
    "                    \"type\": comp.type,\n",
    "                    \"distance\": comp.distance,\n",
    "                    \"latitude\": comp.latitude,\n",
    "                    \"longitude\": comp.longitude,\n",
    "                    \"address\": comp.address,\n",
    "                    \"google_maps_url\": comp.google_maps_url\n",
    "                })\n",
    "        \n",
    "        # Calculate statistics\n",
    "        closest = min(valid_competitors, key=lambda x: x.distance)\n",
    "        farthest = max(valid_competitors, key=lambda x: x.distance)\n",
    "        avg_distance = sum(c.distance for c in valid_competitors) / len(valid_competitors)\n",
    "        total_density = len(valid_competitors) / (3.14159 * (self.radius/1000) ** 2)  # businesses per km²\n",
    "        \n",
    "        # Count by type\n",
    "        count_by_type = {}\n",
    "        for business_type, comp_list in businesses_by_type.items():\n",
    "            count_by_type[business_type] = len(comp_list)\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"total_competitors\": len(valid_competitors),\n",
    "            \"search_parameters\": {\n",
    "                \"latitude\": self.latitude,\n",
    "                \"longitude\": self.longitude,\n",
    "                \"radius\": self.radius,\n",
    "                \"business_types\": self.business_types\n",
    "            },\n",
    "            \"competitors\": competitors_list,\n",
    "            \"statistics\": {\n",
    "                \"closest\": {\n",
    "                    \"name\": closest.name,\n",
    "                    \"distance\": closest.distance,\n",
    "                    \"type\": closest.type\n",
    "                },\n",
    "                \"farthest\": {\n",
    "                    \"name\": farthest.name,\n",
    "                    \"distance\": farthest.distance,\n",
    "                    \"type\": farthest.type\n",
    "                },\n",
    "                \"average_distance\": avg_distance,\n",
    "                \"business_density\": total_density,\n",
    "                \"count_by_type\": count_by_type\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def export_results(self, competitors: List[Competitor], filename: str = \"business_analysis_report.txt\"):\n",
    "        \"\"\"Export results to a text file\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"BUSINESS COMPETITOR ANALYSIS REPORT\\n\")\n",
    "                f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "                f.write(f\"Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(f\"Search radius: {self.radius} meters\\n\")\n",
    "                f.write(f\"Location: {self.latitude:.6f}, {self.longitude:.6f}\\n\")\n",
    "                f.write(f\"Business types: {', '.join(self.business_types)}\\n\\n\")\n",
    "                \n",
    "                valid_competitors = [c for c in competitors if c.distance <= self.radius]\n",
    "                f.write(f\"Total businesses found: {len(valid_competitors)}\\n\\n\")\n",
    "                \n",
    "                f.write(\"DETAILED LISTING:\\n\")\n",
    "                f.write(\"-\" * 50 + \"\\n\")\n",
    "                \n",
    "                for comp in valid_competitors:\n",
    "                    f.write(f\"Name: {comp.name}\\n\")\n",
    "                    f.write(f\"Type: {comp.type}\\n\")\n",
    "                    f.write(f\"Distance: {comp.distance:.0f} meters\\n\")\n",
    "                    f.write(f\"Coordinates: {comp.latitude:.6f}, {comp.longitude:.6f}\\n\")\n",
    "                    f.write(f\"Address: {comp.address}\\n\")\n",
    "                    f.write(f\"Google Maps: {comp.google_maps_url}\\n\")\n",
    "                    f.write(\"-\" * 40 + \"\\n\")\n",
    "                \n",
    "                # Add summary statistics\n",
    "                f.write(\"\\nSUMMARY STATISTICS:\\n\")\n",
    "                f.write(\"-\" * 30 + \"\\n\")\n",
    "                \n",
    "                businesses_by_type = {}\n",
    "                for comp in valid_competitors:\n",
    "                    businesses_by_type[comp.type] = businesses_by_type.get(comp.type, 0) + 1\n",
    "                \n",
    "                for business_type, count in sorted(businesses_by_type.items()):\n",
    "                    f.write(f\"{business_type}: {count} businesses\\n\")\n",
    "                \n",
    "            print(f\"\\n💾 Report exported to: {filename}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error exporting report: {e}\")\n",
    "    \n",
    "    def run_analysis(self, export: bool = False, filename: str = None, json_output: bool = False):\n",
    "        \"\"\"Run analysis with current parameters\"\"\"\n",
    "        data = self.search_competitors()\n",
    "        \n",
    "        if data:\n",
    "            competitors = self.process_results(data)\n",
    "            \n",
    "            if json_output:\n",
    "                # Return JSON for frontend\n",
    "                return self.get_results_json(competitors)\n",
    "            else:\n",
    "                # Display results in console\n",
    "                self.display_results(competitors)\n",
    "                \n",
    "                if competitors and export:\n",
    "                    if not filename:\n",
    "                        filename = \"business_report.txt\"\n",
    "                    self.export_results(competitors, filename)\n",
    "        \n",
    "        return competitors if not json_output else self.get_results_json(competitors)\n",
    "    \n",
    "    def main(self, auto_mode: bool = False, json_output: bool = False, **kwargs):\n",
    "        \"\"\"Main application with optional auto mode\"\"\"\n",
    "        if not json_output:\n",
    "            print(\"🏪 BUSINESS COMPETITOR ANALYSIS TOOL\")\n",
    "            print(\"📍 Find and analyze local businesses with Google Maps integration\")\n",
    "            print(\"=\" * 70)\n",
    "        \n",
    "        try:\n",
    "            if auto_mode:\n",
    "                # Auto mode - use provided parameters\n",
    "                latitude = kwargs.get('latitude', 13.0827)\n",
    "                longitude = kwargs.get('longitude', 80.2707)\n",
    "                radius = kwargs.get('radius', 500)\n",
    "                business_types = kwargs.get('business_types', ['restaurant', 'cafe'])\n",
    "                \n",
    "                self.set_parameters(latitude, longitude, radius, business_types)\n",
    "                result = self.run_analysis(\n",
    "                    export=kwargs.get('export', False),\n",
    "                    filename=kwargs.get('filename'),\n",
    "                    json_output=json_output\n",
    "                )\n",
    "                \n",
    "                if json_output:\n",
    "                    print(json.dumps(result, indent=2))\n",
    "                return result\n",
    "            else:\n",
    "                # Interactive mode\n",
    "                while True:\n",
    "                    latitude, longitude, radius, business_types = self.get_user_input()\n",
    "                    self.set_parameters(latitude, longitude, radius, business_types)\n",
    "                    \n",
    "                    if json_output:\n",
    "                        result = self.run_analysis(json_output=True)\n",
    "                        print(json.dumps(result, indent=2))\n",
    "                    else:\n",
    "                        self.run_analysis()\n",
    "                    \n",
    "                    if json_output:\n",
    "                        break\n",
    "                        \n",
    "                    again = input(\"\\n🔄 Perform another analysis? (y/n): \").strip().lower()\n",
    "                    if again not in ['y', 'yes']:\n",
    "                        if not json_output:\n",
    "                            print(\"\\n✅ Analysis complete! Thank you for using the tool.\")\n",
    "                            print(\"👋 Goodbye!\")\n",
    "                        break\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            if not json_output:\n",
    "                print(\"\\n\\n⏹️ Operation cancelled by user.\")\n",
    "        except Exception as e:\n",
    "            if not json_output:\n",
    "                print(f\"\\n❌ Unexpected error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = CompetitorAnalyzer()\n",
    "\n",
    "    result = analyzer.main(\n",
    "        auto_mode=True,\n",
    "        json_output=True,\n",
    "        latitude=11.0168,  \n",
    "        longitude=76.9558, \n",
    "        radius=1000,      \n",
    "        business_types=['supermarket'], \n",
    "        export=False     \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cultural fit score (0–1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 Free Cultural Fit Analyzer\n",
      "==================================================\n",
      "Analyzing cultural fit for coffee shop at coordinates (13.0827, 80.2707) within 2000km radius...\n",
      "Detected location: Chennai, Tamil Nadu, 600001, India\n",
      "Found 5 relevant content items\n",
      "\n",
      "📍 Location: Chennai, Tamil Nadu, 600001, India\n",
      "🏢 Business: coffee shop\n",
      "📏 Analysis Radius: 2000km\n",
      "📊 Cultural Fit Score: 34.3%\n",
      "😊 Sentiment Ratio: 1.00\n",
      "\n",
      "💡 Insights:\n",
      "  • Moderate cultural fit (34.3%) for a coffee shop in Chennai within 2000km radius\n",
      "  • Strong local interest in coffee (score: 10.0/10) within 2000km radius\n",
      "  • Very positive sentiment detected in local content within 2000km radius\n",
      "  • Currently in summer season - consider seasonal offerings within 2000km radius\n",
      "  • Analysis includes regional preferences for India within 2000km radius\n",
      "  • Analysis covers a wide geographic region\n",
      "\n",
      "📝 Content analyzed: 5 items\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import math\n",
    "\n",
    "class FreeCulturalFitAnalyzer:\n",
    "    def __init__(self):\n",
    "        # No API keys needed!\n",
    "        \n",
    "        # Expanded global keyword database\n",
    "        self.keywords = {\n",
    "            \"coffee\": [\"coffee\", \"espresso\", \"latte\", \"cappuccino\", \"americano\", \"macchiato\", \"flat white\", \"café\"],\n",
    "            \"tea\": [\"tea\", \"chai\", \"green tea\", \"black tea\", \"matcha\", \"oolong\", \"herbal tea\", \"bubble tea\", \"boba\"],\n",
    "            \"vegetarian\": [\"vegetarian\", \"plant-based\", \"vegan\", \"veggie\", \"meat-free\", \"cruelty-free\"],\n",
    "            \"nonveg\": [\"chicken\", \"meat\", \"fish\", \"beef\", \"pork\", \"steak\", \"seafood\", \"lamb\", \"poultry\", \"bacon\"],\n",
    "            \"streetfood\": [\"street food\", \"tacos\", \"bbq\", \"kebab\", \"shawarma\", \"falafel\", \"food truck\", \"food stall\"],\n",
    "            \"fastfood\": [\"burger\", \"fries\", \"pizza\", \"sandwich\", \"hotdog\", \"fast food\", \"quick service\"],\n",
    "            \"healthy\": [\"salad\", \"organic\", \"gluten-free\", \"low-carb\", \"superfood\", \"wellness\", \"nutrition\", \"clean eating\"],\n",
    "            \"dessert\": [\"ice cream\", \"cake\", \"pastry\", \"donut\", \"pudding\", \"brownie\", \"sweet\", \"bakery\", \"patisserie\"],\n",
    "            \"alcohol\": [\"wine\", \"beer\", \"cocktail\", \"bar\", \"pub\", \"brewery\", \"spirits\", \"whiskey\", \"vodka\"],\n",
    "            \"cafe\": [\"cafe\", \"coffee shop\", \"tea house\", \"espresso bar\", \"pastry shop\"],\n",
    "            \"fine_dining\": [\"fine dining\", \"gourmet\", \"luxury restaurant\", \"chef's table\", \"michelin\"],\n",
    "            \"casual_dining\": [\"casual dining\", \"family restaurant\", \"bistro\", \"brunch\", \"eatery\"]\n",
    "        }\n",
    "        \n",
    "        # Global seasonal patterns\n",
    "        self.seasonal_patterns = {\n",
    "            \"northern_hemisphere\": {\n",
    "                \"summer\": [6, 7, 8],\n",
    "                \"winter\": [12, 1, 2],\n",
    "                \"spring\": [3, 4, 5],\n",
    "                \"fall\": [9, 10, 11]\n",
    "            },\n",
    "            \"southern_hemisphere\": {\n",
    "                \"summer\": [12, 1, 2],\n",
    "                \"winter\": [6, 7, 8],\n",
    "                \"spring\": [9, 10, 11],\n",
    "                \"fall\": [3, 4, 5]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_hemisphere(self, lat):\n",
    "        \"\"\"Determine hemisphere based on latitude\"\"\"\n",
    "        return \"northern_hemisphere\" if lat >= 0 else \"southern_hemisphere\"\n",
    "    \n",
    "    def get_location_from_coords(self, lat, lng):\n",
    "        \"\"\"Free geocoding using OpenStreetMap Nominatim API\"\"\"\n",
    "        url = \"https://nominatim.openstreetmap.org/reverse\"\n",
    "        params = {\n",
    "            'format': 'json',\n",
    "            'lat': lat,\n",
    "            'lon': lng,\n",
    "            'zoom': 10,  # Level of detail\n",
    "            'addressdetails': 1  # Get detailed address components\n",
    "        }\n",
    "        \n",
    "        # Important: Add a user agent to identify your application\n",
    "        headers = {\n",
    "            'User-Agent': 'CulturalFitAnalyzer/1.0 (contact@example.com)'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params, headers=headers)\n",
    "            data = response.json()\n",
    "            \n",
    "            # Respect rate limits (1 request per second)\n",
    "            time.sleep(1.1)\n",
    "            \n",
    "            if 'error' not in data:\n",
    "                address = data.get('display_name', 'Unknown location')\n",
    "                address_components = data.get('address', {})\n",
    "                \n",
    "                location_info = {\n",
    "                    'formatted_address': address,\n",
    "                    'country': address_components.get('country', ''),\n",
    "                    'region': address_components.get('state', address_components.get('region', '')),\n",
    "                    'city': address_components.get('city', address_components.get('town', address_components.get('village', ''))),\n",
    "                    'postal_code': address_components.get('postcode', ''),\n",
    "                    'latitude': lat,\n",
    "                    'longitude': lng\n",
    "                }\n",
    "                return location_info\n",
    "            else:\n",
    "                return {\"error\": f\"OpenStreetMap Error: {data.get('error', 'Unknown error')}\"}\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Request Error: {str(e)}\"}\n",
    "\n",
    "    def get_wikipedia_content(self, location_name, business_type, radius_km):\n",
    "        \"\"\"Get content from Wikipedia about the location with better error handling\"\"\"\n",
    "        try:\n",
    "            if not location_name or not location_name.strip():\n",
    "                return []\n",
    "                \n",
    "            # Add radius context to the search\n",
    "            radius_context = f\"within {radius_km}km radius\" if radius_km > 0 else \"\"\n",
    "            \n",
    "            # Try to get Wikipedia page for the city/region\n",
    "            search_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "            params = {\n",
    "                'action': 'query',\n",
    "                'format': 'json',\n",
    "                'list': 'search',\n",
    "                'srsearch': f\"{location_name} {business_type} {radius_context}\",\n",
    "                'srlimit': 3,  # Reduced from 5 to avoid rate limiting\n",
    "                'srprop': ''   # Don't need additional properties\n",
    "            }\n",
    "            \n",
    "            # Add headers to identify our application\n",
    "            headers = {\n",
    "                'User-Agent': 'CulturalFitAnalyzer/1.0 (contact@example.com)'\n",
    "            }\n",
    "            \n",
    "            response = requests.get(search_url, params=params, headers=headers, timeout=10)\n",
    "            \n",
    "            # Check if response is valid JSON\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Wikipedia API HTTP Error: {response.status_code}\")\n",
    "                return []\n",
    "                \n",
    "            try:\n",
    "                data = response.json()\n",
    "            except ValueError:\n",
    "                print(\"Wikipedia API returned invalid JSON\")\n",
    "                return []\n",
    "            \n",
    "            texts = []\n",
    "            if 'query' in data and 'search' in data['query']:\n",
    "                for result in data['query']['search'][:2]:  # Limit to 2 results\n",
    "                    title = result['title']\n",
    "                    \n",
    "                    # Get page content with simpler parameters\n",
    "                    content_params = {\n",
    "                        'action': 'query',\n",
    "                        'format': 'json',\n",
    "                        'prop': 'extracts',\n",
    "                        'exintro': True,\n",
    "                        'explaintext': True,\n",
    "                        'titles': title,\n",
    "                        'redirects': 1  # Follow redirects\n",
    "                    }\n",
    "                    \n",
    "                    try:\n",
    "                        content_response = requests.get(search_url, params=content_params, \n",
    "                                                    headers=headers, timeout=10)\n",
    "                        \n",
    "                        if content_response.status_code == 200:\n",
    "                            content_data = content_response.json()\n",
    "                            pages = content_data.get('query', {}).get('pages', {})\n",
    "                            \n",
    "                            for page_id, page_data in pages.items():\n",
    "                                if 'extract' in page_data and page_data['extract']:\n",
    "                                    texts.append(f\"{page_data['title']}: {page_data['extract'][:500]}...\")  # Limit length\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error fetching Wikipedia content for {title}: {str(e)}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Be nice to Wikipedia's servers - add delay\n",
    "                    time.sleep(0.5)\n",
    "            \n",
    "            return texts\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Wikipedia network error: {str(e)}\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected Wikipedia API Error: {str(e)}\")\n",
    "            return []  \n",
    "  \n",
    "    def get_local_content(self, location_info, business_type, radius_km):\n",
    "        \"\"\"Get local content using multiple free sources with fallbacks\"\"\"\n",
    "        city = location_info.get('city', '')\n",
    "        region = location_info.get('region', '')\n",
    "        country = location_info.get('country', '')\n",
    "        \n",
    "        texts = []\n",
    "        \n",
    "        # Try Wikipedia first (with error handling)\n",
    "        try:\n",
    "            wiki_texts = self.get_wikipedia_content(city or region, business_type, radius_km)\n",
    "            texts.extend(wiki_texts)\n",
    "        except:\n",
    "            pass  # Silently fail if Wikipedia doesn't work\n",
    "        \n",
    "        # Add reliable simulated data based on location\n",
    "        simulated_data = self.generate_simulated_local_data(location_info, business_type, radius_km)\n",
    "        texts.extend(simulated_data)\n",
    "        \n",
    "        # Add general location context\n",
    "        radius_context = f\"within a {radius_km}km radius\" if radius_km > 0 else \"in the area\"\n",
    "        if city and country:\n",
    "            texts.append(f\"{city}, {country} is known for its diverse local culture and business environment {radius_context}\")\n",
    "        \n",
    "        # Add business type context\n",
    "        business_context = {\n",
    "            'coffee shop': 'Coffee culture varies significantly by region with local preferences for specific brewing styles',\n",
    "            'tea house': 'Tea traditions differ globally with unique preparation methods in each culture',\n",
    "            'restaurant': 'Culinary preferences are deeply influenced by local traditions and ingredients',\n",
    "            'bar': 'Social drinking culture shows strong regional variations in preferences and customs'\n",
    "        }\n",
    "        \n",
    "        if business_type.lower() in business_context:\n",
    "            texts.append(business_context[business_type.lower()])\n",
    "        \n",
    "        return list(set(texts))  # Remove duplicates\n",
    "   \n",
    "    def generate_simulated_local_data(self, location_info, business_type, radius_km):\n",
    "        \"\"\"Generate simulated local data based on location characteristics\"\"\"\n",
    "        country = location_info.get('country', '').lower()\n",
    "        city = location_info.get('city', '').lower()\n",
    "        texts = []\n",
    "        \n",
    "        # Add radius context\n",
    "        radius_context = f\"within {radius_km}km radius\" if radius_km > 0 else \"in the local area\"\n",
    "        \n",
    "        # Add region-specific content patterns\n",
    "        if 'india' in country:\n",
    "            texts.append(f\"{city} is known for its vibrant food culture with diverse culinary traditions {radius_context}\")\n",
    "            if 'tea' in business_type.lower():\n",
    "                texts.append(f\"Chai is an integral part of daily life across India with strong cultural significance {radius_context}\")\n",
    "            if 'coffee' in business_type.lower():\n",
    "                texts.append(f\"Coffee culture is growing rapidly in urban areas of India {radius_context}\")\n",
    "                \n",
    "        elif 'italy' in country:\n",
    "            texts.append(f\"{city} features rich culinary heritage with emphasis on traditional recipes {radius_context}\")\n",
    "            if 'coffee' in business_type.lower():\n",
    "                texts.append(f\"Italian coffee culture is world-renowned with espresso being a daily ritual {radius_context}\")\n",
    "                \n",
    "        elif 'usa' in country or 'united states' in country:\n",
    "            texts.append(f\"{city} has diverse dining options ranging from fast food to fine dining {radius_context}\")\n",
    "            \n",
    "        elif 'japan' in country:\n",
    "            texts.append(f\"{city} offers unique culinary experiences blending tradition and innovation {radius_context}\")\n",
    "            if 'tea' in business_type.lower():\n",
    "                texts.append(f\"Japanese tea ceremony culture influences modern tea consumption patterns {radius_context}\")\n",
    "        \n",
    "        # Add seasonal content\n",
    "        current_month = datetime.now().month\n",
    "        if current_month in [12, 1, 2]:  # Winter\n",
    "            texts.append(f\"Winter season brings preference for warm beverages and comfort foods {radius_context}\")\n",
    "        elif current_month in [6, 7, 8]:  # Summer\n",
    "            texts.append(f\"Summer months increase demand for cold drinks and refreshing options {radius_context}\")\n",
    "        \n",
    "        return texts\n",
    "    \n",
    "    def analyze_text_for_keywords(self, texts, business_type):\n",
    "        \"\"\"Analyze texts for relevant keywords with advanced scoring\"\"\"\n",
    "        # Get relevant categories for this business type\n",
    "        relevant_categories = self.get_relevant_categories(business_type)\n",
    "        \n",
    "        # Initialize scoring\n",
    "        category_scores = {category: 0 for category in relevant_categories}\n",
    "        total_mentions = 0\n",
    "        sentiment_scores = defaultdict(list)\n",
    "        \n",
    "        # Simple sentiment analysis\n",
    "        positive_words = [\"good\", \"great\", \"excellent\", \"amazing\", \"love\", \"best\", \"popular\", \"favorite\", \"trending\", \"growth\", \"success\", \"demand\"]\n",
    "        negative_words = [\"bad\", \"poor\", \"terrible\", \"hate\", \"worst\", \"avoid\", \"overpriced\", \"disappointing\", \"decline\", \"saturated\", \"competition\"]\n",
    "        \n",
    "        for text in texts:\n",
    "            if text:\n",
    "                text_lower = text.lower()\n",
    "                \n",
    "                # Count category mentions\n",
    "                for category in relevant_categories:\n",
    "                    for keyword in self.keywords[category]:\n",
    "                        if keyword in text_lower:\n",
    "                            count = text_lower.count(keyword)\n",
    "                            category_scores[category] += count\n",
    "                            total_mentions += count\n",
    "                \n",
    "                # Basic sentiment analysis\n",
    "                for word in positive_words:\n",
    "                    if word in text_lower:\n",
    "                        sentiment_scores['positive'].append(word)\n",
    "                \n",
    "                for word in negative_words:\n",
    "                    if word in text_lower:\n",
    "                        sentiment_scores['negative'].append(word)\n",
    "        \n",
    "        # Calculate normalized scores (0-10 scale)\n",
    "        relevance_scores = {}\n",
    "        for category, score in category_scores.items():\n",
    "            if total_mentions > 0:\n",
    "                # Normalize by total mentions and scale\n",
    "                relevance_scores[category] = min((score / total_mentions) * 20, 10)\n",
    "            else:\n",
    "                relevance_scores[category] = 0\n",
    "        \n",
    "        # Calculate overall sentiment\n",
    "        positive_count = len(sentiment_scores['positive'])\n",
    "        negative_count = len(sentiment_scores['negative'])\n",
    "        total_sentiment = positive_count + negative_count\n",
    "        \n",
    "        if total_sentiment > 0:\n",
    "            sentiment_ratio = positive_count / total_sentiment\n",
    "        else:\n",
    "            sentiment_ratio = 0.5  # Neutral if no sentiment words found\n",
    "        \n",
    "        return relevance_scores, sentiment_ratio\n",
    "    \n",
    "    def get_relevant_categories(self, business_type):\n",
    "        \"\"\"Dynamically determine relevant keyword categories based on business type\"\"\"\n",
    "        business_type_lower = business_type.lower()\n",
    "        relevant_categories = set()\n",
    "        \n",
    "        # Map business types to relevant keyword categories\n",
    "        category_mapping = {\n",
    "            'coffee': ['coffee', 'cafe', 'dessert'],\n",
    "            'tea': ['tea', 'cafe', 'dessert'],\n",
    "            'cafe': ['coffee', 'tea', 'cafe', 'dessert', 'healthy'],\n",
    "            'restaurant': ['vegetarian', 'nonveg', 'streetfood', 'fastfood', 'healthy', 'fine_dining', 'casual_dining'],\n",
    "            'bar': ['alcohol', 'fastfood', 'casual_dining'],\n",
    "            'bakery': ['dessert', 'healthy', 'vegetarian'],\n",
    "            'ice cream': ['dessert', 'vegetarian'],\n",
    "            'healthy': ['healthy', 'vegetarian', 'casual_dining'],\n",
    "            'fast food': ['fastfood', 'nonveg', 'casual_dining'],\n",
    "            'fine dining': ['fine_dining', 'nonveg', 'alcohol']\n",
    "        }\n",
    "        \n",
    "        # Find matching categories\n",
    "        for key, categories in category_mapping.items():\n",
    "            if key in business_type_lower:\n",
    "                relevant_categories.update(categories)\n",
    "        \n",
    "        # If no specific match, use a broad set of categories\n",
    "        if not relevant_categories:\n",
    "            relevant_categories = set(self.keywords.keys())\n",
    "        \n",
    "        return list(relevant_categories)\n",
    "    \n",
    "    def calculate_cultural_fit(self, relevance_scores, sentiment_ratio, business_type, location_info, radius_km):\n",
    "        \"\"\"Calculate cultural fit score with global considerations\"\"\"\n",
    "        # Base score starts at neutral\n",
    "        base_score = 0.5\n",
    "        \n",
    "        # Calculate weighted category score\n",
    "        category_weights = self.get_category_weights(business_type)\n",
    "        weighted_sum = 0\n",
    "        total_weight = 0\n",
    "        \n",
    "        for category, score in relevance_scores.items():\n",
    "            weight = category_weights.get(category, 1.0)\n",
    "            weighted_sum += score * weight\n",
    "            total_weight += weight\n",
    "        \n",
    "        # Normalize category score (0-1 scale)\n",
    "        if total_weight > 0:\n",
    "            category_score = (weighted_sum / total_weight) / 10\n",
    "        else:\n",
    "            category_score = 0\n",
    "        \n",
    "        # Apply sentiment adjustment\n",
    "        sentiment_adjustment = (sentiment_ratio - 0.5) * 0.3  # ±15% adjustment based on sentiment\n",
    "        adjusted_category_score = min(max(category_score + sentiment_adjustment, 0), 1)\n",
    "        \n",
    "        # Blend base score with category score\n",
    "        final_score = 0.6 * adjusted_category_score + 0.4 * base_score\n",
    "        \n",
    "        # Apply seasonal adjustments based on location\n",
    "        final_score = self.apply_seasonal_adjustments(final_score, business_type, location_info)\n",
    "        \n",
    "        # Apply regional adjustments if available\n",
    "        final_score = self.apply_regional_adjustments(final_score, business_type, location_info)\n",
    "        \n",
    "        # Apply radius-based adjustments\n",
    "        final_score = self.apply_radius_adjustments(final_score, radius_km, business_type)\n",
    "        \n",
    "        return min(max(final_score, 0), 1)  # Ensure score is between 0 and 1\n",
    "    \n",
    "    def apply_radius_adjustments(self, score, radius_km, business_type):\n",
    "        \"\"\"Adjust score based on the analysis radius\"\"\"\n",
    "        # Smaller radius means more localized analysis, which is more precise\n",
    "        # Larger radius means broader analysis, which might dilute the score\n",
    "        \n",
    "        if radius_km <= 5:  # Very localized analysis\n",
    "            return score * 1.05  # Small boost for hyper-local analysis\n",
    "        elif radius_km <= 20:  # Local analysis\n",
    "            return score  # No adjustment\n",
    "        elif radius_km <= 50:  # Regional analysis\n",
    "            return score * 0.95  # Slight reduction for broader analysis\n",
    "        else:  # Very broad analysis\n",
    "            return score * 0.9  # Reduction for very broad analysis\n",
    "    \n",
    "    def get_category_weights(self, business_type):\n",
    "        \"\"\"Get dynamic weights for different categories based on business type\"\"\"\n",
    "        business_type_lower = business_type.lower()\n",
    "        weights = {}\n",
    "        \n",
    "        # Default weights for all categories\n",
    "        for category in self.keywords.keys():\n",
    "            weights[category] = 1.0\n",
    "        \n",
    "        # Adjust weights based on business type\n",
    "        if any(word in business_type_lower for word in ['coffee', 'cafe']):\n",
    "            weights['coffee'] = 3.0\n",
    "            weights['tea'] = 1.5\n",
    "            weights['dessert'] = 2.0\n",
    "            weights['cafe'] = 2.5\n",
    "        \n",
    "        if 'tea' in business_type_lower:\n",
    "            weights['tea'] = 3.0\n",
    "            weights['coffee'] = 1.0\n",
    "            weights['dessert'] = 2.0\n",
    "            weights['cafe'] = 2.5\n",
    "        \n",
    "        if 'restaurant' in business_type_lower:\n",
    "            if 'vegetarian' in business_type_lower or 'vegan' in business_type_lower:\n",
    "                weights['vegetarian'] = 3.0\n",
    "                weights['healthy'] = 2.5\n",
    "            else:\n",
    "                weights['nonveg'] = 2.5\n",
    "                weights['vegetarian'] = 1.5\n",
    "            \n",
    "            if 'fine' in business_type_lower or 'luxury' in business_type_lower:\n",
    "                weights['fine_dining'] = 3.0\n",
    "                weights['alcohol'] = 2.0\n",
    "            else:\n",
    "                weights['casual_dining'] = 2.5\n",
    "        \n",
    "        if 'bar' in business_type_lower or 'pub' in business_type_lower:\n",
    "            weights['alcohol'] = 3.0\n",
    "            weights['casual_dining'] = 2.0\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def apply_seasonal_adjustments(self, score, business_type, location_info):\n",
    "        \"\"\"Apply seasonal adjustments based on location and hemisphere\"\"\"\n",
    "        month = datetime.now().month\n",
    "        lat = location_info.get('latitude', 0)\n",
    "        \n",
    "        if lat is not None:\n",
    "            hemisphere = self.get_hemisphere(lat)\n",
    "            seasons = self.seasonal_patterns[hemisphere]\n",
    "            \n",
    "            business_lower = business_type.lower()\n",
    "            \n",
    "            # Summer adjustments\n",
    "            if month in seasons['summer']:\n",
    "                if any(word in business_lower for word in ['ice cream', 'dessert', 'cold', 'smoothie']):\n",
    "                    score *= 1.3  # Boost for cold items in summer\n",
    "                elif any(word in business_lower for word in ['coffee', 'tea', 'hot', 'soup']):\n",
    "                    score *= 0.9  # Slight decrease for hot items in summer\n",
    "            \n",
    "            # Winter adjustments\n",
    "            elif month in seasons['winter']:\n",
    "                if any(word in business_lower for word in ['coffee', 'tea', 'hot', 'soup']):\n",
    "                    score *= 1.2  # Boost for hot items in winter\n",
    "                elif any(word in business_lower for word in ['ice cream', 'cold', 'smoothie']):\n",
    "                    score *= 0.8  # Decrease for cold items in winter\n",
    "            \n",
    "            # Festival seasons (Q4 generally has more holidays globally)\n",
    "            if month in [10, 11, 12]:\n",
    "                if any(word in business_lower for word in ['restaurant', 'food', 'cafe', 'bar']):\n",
    "                    score *= 1.1  # General boost during holiday season\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def apply_regional_adjustments(self, score, business_type, location_info):\n",
    "        \"\"\"Apply regional/cultural adjustments based on location\"\"\"\n",
    "        country = location_info.get('country', '').lower()\n",
    "        business_lower = business_type.lower()\n",
    "        \n",
    "        # Regional preferences (simplified examples)\n",
    "        regional_preferences = {\n",
    "            'india': {\n",
    "                'tea': 1.2, 'coffee': 0.8, 'vegetarian': 1.3, 'nonveg': 0.9\n",
    "            },\n",
    "            'italy': {\n",
    "                'coffee': 1.4, 'pizza': 1.5, 'pasta': 1.4, 'tea': 0.7\n",
    "            },\n",
    "            'united states': {\n",
    "                'coffee': 1.3, 'fastfood': 1.2, 'healthy': 1.1\n",
    "            },\n",
    "            'united kingdom': {\n",
    "                'tea': 1.4, 'pub': 1.3, 'fish': 1.2\n",
    "            },\n",
    "            'japan': {\n",
    "                'tea': 1.5, 'healthy': 1.3, 'seafood': 1.4, 'coffee': 1.1\n",
    "            },\n",
    "            'france': {\n",
    "                'coffee': 1.3, 'wine': 1.5, 'bakery': 1.4, 'tea': 0.8\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Apply country-specific adjustments\n",
    "        for country_pattern, adjustments in regional_preferences.items():\n",
    "            if country_pattern in country:\n",
    "                for business_pattern, multiplier in adjustments.items():\n",
    "                    if business_pattern in business_lower:\n",
    "                        score *= multiplier\n",
    "                        break  # Apply only the first matching pattern\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def get_cultural_fit_score(self, lat, lng, business_type, radius_km=10):\n",
    "        \"\"\"Main function to get cultural fit score for any global location\"\"\"\n",
    "        print(f\"Analyzing cultural fit for {business_type} at coordinates ({lat}, {lng}) within {radius_km}km radius...\")\n",
    "        \n",
    "        # Step 1: Get detailed location information\n",
    "        location_info = self.get_location_from_coords(lat, lng)\n",
    "        if 'error' in location_info:\n",
    "            return {\"error\": location_info['error']}\n",
    "        \n",
    "        print(f\"Detected location: {location_info['formatted_address']}\")\n",
    "        \n",
    "        # Step 2: Get local content\n",
    "        content_texts = self.get_local_content(location_info, business_type, radius_km)\n",
    "        print(f\"Found {len(content_texts)} relevant content items\")\n",
    "        \n",
    "        # Step 3: Analyze the content for relevant keywords and sentiment\n",
    "        relevance_scores, sentiment_ratio = self.analyze_text_for_keywords(content_texts, business_type)\n",
    "        \n",
    "        # Step 4: Calculate cultural fit score\n",
    "        cultural_fit = self.calculate_cultural_fit(\n",
    "            relevance_scores, sentiment_ratio, business_type, location_info, radius_km\n",
    "        )\n",
    "        \n",
    "        # Step 5: Generate insights\n",
    "        insights = self.generate_insights(\n",
    "            relevance_scores, cultural_fit, business_type, location_info, sentiment_ratio, radius_km\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'cultural_fit_score': round(cultural_fit, 3),\n",
    "            'location': location_info['formatted_address'],\n",
    "            'business_type': business_type,\n",
    "            'analysis_radius_km': radius_km,\n",
    "            'relevance_scores': relevance_scores,\n",
    "            'sentiment_ratio': sentiment_ratio,\n",
    "            'insights': insights,\n",
    "            'content_analyzed': len(content_texts)\n",
    "        }\n",
    "    \n",
    "    def generate_insights(self, relevance_scores, cultural_fit, business_type, location_info, sentiment_ratio, radius_km):\n",
    "        \"\"\"Generate human-readable insights from the analysis\"\"\"\n",
    "        insights = []\n",
    "        \n",
    "        # Main insight based on score\n",
    "        score_percentage = cultural_fit * 100\n",
    "        radius_context = f\"within {radius_km}km radius\" if radius_km > 0 else \"in the local area\"\n",
    "        \n",
    "        if cultural_fit >= 0.7:\n",
    "            insights.append(f\"Excellent cultural fit ({score_percentage:.1f}%) for a {business_type} in {location_info.get('city', 'this location')} {radius_context}\")\n",
    "        elif cultural_fit >= 0.5:\n",
    "            insights.append(f\"Good cultural fit ({score_percentage:.1f}%) for a {business_type} in {location_info.get('city', 'this location')} {radius_context}\")\n",
    "        elif cultural_fit >= 0.3:\n",
    "            insights.append(f\"Moderate cultural fit ({score_percentage:.1f}%) for a {business_type} in {location_info.get('city', 'this location')} {radius_context}\")\n",
    "        else:\n",
    "            insights.append(f\"Poor cultural fit ({score_percentage:.1f}%) for a {business_type} in {location_info.get('city', 'this location')} {radius_context}\")\n",
    "        \n",
    "        # Add insights based on keyword relevance\n",
    "        top_categories = sorted(relevance_scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "        \n",
    "        for category, score in top_categories:\n",
    "            if score > 5:\n",
    "                insights.append(f\"Strong local interest in {category.replace('_', ' ')} (score: {score:.1f}/10) {radius_context}\")\n",
    "            elif score > 2:\n",
    "                insights.append(f\"Moderate local interest in {category.replace('_', ' ')} (score: {score:.1f}/10) {radius_context}\")\n",
    "        \n",
    "        # Sentiment insight\n",
    "        if sentiment_ratio > 0.7:\n",
    "            insights.append(f\"Very positive sentiment detected in local content {radius_context}\")\n",
    "        elif sentiment_ratio > 0.6:\n",
    "            insights.append(f\"Generally positive sentiment detected in local content {radius_context}\")\n",
    "        elif sentiment_ratio < 0.4:\n",
    "            insights.append(f\"Some negative sentiment detected in local content {radius_context}\")\n",
    "        \n",
    "        # Seasonal insight\n",
    "        month = datetime.now().month\n",
    "        hemisphere = self.get_hemisphere(location_info.get('latitude', 0))\n",
    "        seasons = self.seasonal_patterns[hemisphere]\n",
    "        \n",
    "        if month in seasons['summer']:\n",
    "            insights.append(f\"Currently in summer season - consider seasonal offerings {radius_context}\")\n",
    "        elif month in seasons['winter']:\n",
    "            insights.append(f\"Currently in winter season - consider seasonal offerings {radius_context}\")\n",
    "        elif month in seasons['spring']:\n",
    "            insights.append(f\"Currently in spring season - consider seasonal offerings {radius_context}\")\n",
    "        elif month in seasons['fall']:\n",
    "            insights.append(f\"Currently in fall season - consider seasonal offerings {radius_context}\")\n",
    "        \n",
    "        # Regional insight\n",
    "        country = location_info.get('country', '')\n",
    "        if country:\n",
    "            insights.append(f\"Analysis includes regional preferences for {country} {radius_context}\")\n",
    "            \n",
    "        # Radius insight\n",
    "        if radius_km <= 5:\n",
    "            insights.append(\"Analysis focused on a very localized area (hyper-local)\")\n",
    "        elif radius_km <= 20:\n",
    "            insights.append(\"Analysis focused on the immediate local area\")\n",
    "        elif radius_km <= 50:\n",
    "            insights.append(\"Analysis covers a broader regional area\")\n",
    "        else:\n",
    "            insights.append(\"Analysis covers a wide geographic region\")\n",
    "        \n",
    "        return insights\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize analyzer\n",
    "    analyzer = FreeCulturalFitAnalyzer()\n",
    "    \n",
    "    # Test coordinates (Chennai, India)\n",
    "    latitude = 13.0827\n",
    "    longitude = 80.2707\n",
    "    business = \"coffee shop\"\n",
    "    radius_km = 2000\n",
    "    \n",
    "    print(\"🌍 Free Cultural Fit Analyzer\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    result = analyzer.get_cultural_fit_score(latitude, longitude, business, radius_km)\n",
    "    \n",
    "    if 'error' in result:\n",
    "        print(f\"Error: {result['error']}\")\n",
    "    else:\n",
    "        print(f\"\\n📍 Location: {result['location']}\")\n",
    "        print(f\"🏢 Business: {result['business_type']}\")\n",
    "        print(f\"📏 Analysis Radius: {result['analysis_radius_km']}km\")\n",
    "        print(f\"📊 Cultural Fit Score: {result['cultural_fit_score'] * 100:.1f}%\")\n",
    "        print(f\"😊 Sentiment Ratio: {result['sentiment_ratio']:.2f}\")\n",
    "        \n",
    "        print(\"\\n💡 Insights:\")\n",
    "        for insight in result['insights']:\n",
    "            print(f\"  • {insight}\")\n",
    "        \n",
    "        print(f\"\\n📝 Content analyzed: {result['content_analyzed']} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Type multiplier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Multiplier Result:\n",
      "multiplier: 1.48\n",
      "confidence: 0.5\n",
      "global_baseline: 1.2\n",
      "local_adjustment: 1.23\n",
      "population_estimate: 100\n",
      "competition_count: 308\n",
      "notes: High competition (308 competitors). Consider differentiation.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Global baseline multipliers (from industry reports)\n",
    "global_baseline_multipliers = {\n",
    "    \"cafe\": 1.2,\n",
    "    \"restaurant\": 1.0,\n",
    "    \"gym\": 0.8,\n",
    "    \"clothing_store\": 0.9,\n",
    "    \"supermarket\": 1.5,\n",
    "    \"pharmacy\": 1.1,\n",
    "    \"electronics_store\": 1.3,\n",
    "    \"jewelry_store\": 1.4,\n",
    "    \"book_store\": 0.7,\n",
    "    \"bar\": 1.2\n",
    "}\n",
    "\n",
    "def get_population_within_radius(lat, lon, radius):\n",
    "    \"\"\"\n",
    "    Estimate population using free OpenStreetMap data and heuristic density models\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use Overpass API to count residential buildings - FIXED QUERY\n",
    "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        overpass_query = f\"\"\"\n",
    "        [out:json];\n",
    "        (\n",
    "          node[\"building\"~\"residential|apartments|house|detached|terrace\"](around:{radius},{lat},{lon});\n",
    "          way[\"building\"~\"residential|apartments|house|detached|terrace\"](around:{radius},{lat},{lon});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\"\n",
    "        \n",
    "        response = requests.post(overpass_url, data=overpass_query, timeout=10)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Parse the count from Overpass API response - FIXED PARSING\n",
    "        building_count = 0\n",
    "        for element in data.get('elements', []):\n",
    "            if 'tags' in element and element.get('type') == 'count':\n",
    "                # Different ways the count might be represented\n",
    "                if 'nodes' in element:\n",
    "                    building_count += element['nodes']\n",
    "                if 'ways' in element:\n",
    "                    building_count += element['ways']\n",
    "                if 'relations' in element:\n",
    "                    building_count += element['relations']\n",
    "                if 'total' in element:\n",
    "                    building_count = element['total']\n",
    "                    break\n",
    "        \n",
    "        # Estimate population based on building count (heuristic: 4 people per building)\n",
    "        estimated_population = building_count * 4\n",
    "        \n",
    "        return max(estimated_population, 100)  # Minimum population of 100\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting population: {e}\")\n",
    "        return 500  # Default fallback value\n",
    "\n",
    "def get_income_index(lat, lon, radius):\n",
    "    \"\"\"\n",
    "    Estimate income level using OpenStreetMap landuse data as proxy\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get landuse data to estimate area wealth - FIXED QUERY\n",
    "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        overpass_query = f\"\"\"\n",
    "        [out:json];\n",
    "        (\n",
    "          node[\"landuse\"~\"commercial|retail\"](around:{radius},{lat},{lon});\n",
    "          node[\"shop\"](around:{radius},{lat},{lon});\n",
    "          way[\"landuse\"~\"commercial|retail\"](around:{radius},{lat},{lon});\n",
    "          way[\"shop\"](around:{radius},{lat},{lon});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\"\n",
    "        \n",
    "        response = requests.post(overpass_url, data=overpass_query, timeout=10)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Parse the count from Overpass API response - FIXED PARSING\n",
    "        commercial_count = 0\n",
    "        for element in data.get('elements', []):\n",
    "            if 'tags' in element and element.get('type') == 'count':\n",
    "                if 'nodes' in element:\n",
    "                    commercial_count += element['nodes']\n",
    "                if 'ways' in element:\n",
    "                    commercial_count += element['ways']\n",
    "                if 'relations' in element:\n",
    "                    commercial_count += element['relations']\n",
    "                if 'total' in element:\n",
    "                    commercial_count = element['total']\n",
    "                    break\n",
    "        \n",
    "        # More commercial activity = higher income area (proxy)\n",
    "        income_index = 0.5 + (commercial_count * 0.05)  # Base 0.5, +0.05 per commercial entity\n",
    "        return min(max(income_index, 0.5), 1.5)  # Cap between 0.5-1.5\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting income index: {e}\")\n",
    "        return 1.0  # Default average income\n",
    "\n",
    "def get_nearby_places(lat, lon, radius, business_type):\n",
    "    \"\"\"\n",
    "    Get nearby businesses using Overpass API (free)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Map business types to OSM tags - IMPROVED MAPPING\n",
    "        osm_tags = {\n",
    "            \"cafe\": '[\"amenity\"=\"cafe\"]',\n",
    "            \"restaurant\": '[\"amenity\"=\"restaurant\"]',\n",
    "            \"gym\": '[\"leisure\"=\"fitness_centre\"]',\n",
    "            \"clothing_store\": '[\"shop\"=\"clothes\"]',\n",
    "            \"supermarket\": '[\"shop\"=\"supermarket\"]',\n",
    "            \"pharmacy\": '[\"amenity\"=\"pharmacy\"]',\n",
    "            \"electronics_store\": '[\"shop\"=\"electronics\"]',\n",
    "            \"jewelry_store\": '[\"shop\"=\"jewelry\"]',\n",
    "            \"book_store\": '[\"shop\"=\"books\"]',\n",
    "            \"bar\": '[\"amenity\"=\"bar\"]'\n",
    "        }\n",
    "        \n",
    "        tag_query = osm_tags.get(business_type, '[\"shop\"]')\n",
    "        \n",
    "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        # More specific query to avoid getting too many results\n",
    "        overpass_query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          node{tag_query}(around:{radius},{lat},{lon});\n",
    "        );\n",
    "        out body;\n",
    "        \"\"\"\n",
    "        \n",
    "        response = requests.post(overpass_url, data=overpass_query, timeout=15)\n",
    "        data = response.json()\n",
    "        \n",
    "        businesses = []\n",
    "        for element in data.get('elements', []):\n",
    "            if element.get('type') == 'node':\n",
    "                business = {\n",
    "                    'name': element.get('tags', {}).get('name', 'Unknown'),\n",
    "                    'user_ratings_total': 10,  # Default value for free API\n",
    "                    'price_level': 1  # Default value\n",
    "                }\n",
    "                businesses.append(business)\n",
    "            \n",
    "        return businesses\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting nearby places: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_confidence(population, competition_count):\n",
    "    \"\"\"\n",
    "    Calculate confidence score based on data quality\n",
    "    \"\"\"\n",
    "    # Base confidence on population data reliability\n",
    "    pop_confidence = min(population / 1000, 1.0)  # More population = more reliable\n",
    "    \n",
    "    # Adjust for competition data (more competition data = more reliable)\n",
    "    comp_confidence = min(competition_count / 10, 1.0)  # Changed from 5 to 10\n",
    "    \n",
    "    # Overall confidence (weighted average)\n",
    "    confidence = (pop_confidence * 0.6) + (comp_confidence * 0.4)\n",
    "    \n",
    "    return max(0.5, min(confidence, 0.9))  # Keep between 0.5-0.9 for MVP\n",
    "\n",
    "def get_business_type_multiplier(business_type, lat, lon, radius=2000):\n",
    "    \"\"\"\n",
    "    Fetches a location-aware business type multiplier using free APIs.\n",
    "    Accuracy target: ~50-60% for MVP\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Get the global baseline for the business type\n",
    "        baseline = global_baseline_multipliers.get(business_type, 1.0)\n",
    "\n",
    "        # 2. Calculate Local Demand Score (with free data sources)\n",
    "        total_population = get_population_within_radius(lat, lon, radius)\n",
    "        avg_income_index = get_income_index(lat, lon, radius)\n",
    "        local_demand_score = total_population * avg_income_index\n",
    "\n",
    "        # 3. Calculate Local Supply Score (Competition)\n",
    "        competing_businesses = get_nearby_places(lat, lon, radius, business_type)\n",
    "        \n",
    "        # Calculate the \"strength\" of each competitor\n",
    "        total_competition_strength = 0\n",
    "        for business in competing_businesses:\n",
    "            # For free API, we use default values as we can't get real review counts\n",
    "            strength = business.get('user_ratings_total', 10) * business.get('price_level', 1)\n",
    "            total_competition_strength += strength\n",
    "\n",
    "        local_supply_score = total_competition_strength\n",
    "\n",
    "        # 4. Calculate local adjustment\n",
    "        if local_supply_score == 0:\n",
    "            local_adjustment = 1.8  # Bonus for no competition (capped)\n",
    "        else:\n",
    "            # Normalize the ratio to avoid extreme values\n",
    "            raw_ratio = local_demand_score / local_supply_score\n",
    "            # Apply sigmoid-like function to keep between 0.5-2.0\n",
    "            local_adjustment = 0.5 + 1.5 / (1 + math.exp(-0.0001 * (raw_ratio - 500)))\n",
    "            \n",
    "        local_adjustment = max(0.5, min(2.0, local_adjustment))\n",
    "\n",
    "        # 5. Calculate Final Multiplier\n",
    "        final_multiplier = baseline * local_adjustment\n",
    "\n",
    "        # 6. Calculate Confidence\n",
    "        confidence = calculate_confidence(total_population, len(competing_businesses))\n",
    "\n",
    "        # 7. Generate notes\n",
    "        comp_count = len(competing_businesses)\n",
    "        if comp_count == 0:\n",
    "            notes = \"No direct competitors found. High opportunity but verify local demand.\"\n",
    "        elif comp_count < 3:\n",
    "            notes = f\"Low competition ({comp_count} competitors). Good market conditions.\"\n",
    "        elif comp_count < 8:\n",
    "            notes = f\"Moderate competition ({comp_count} competitors). Viable market.\"\n",
    "        else:\n",
    "            notes = f\"High competition ({comp_count} competitors). Consider differentiation.\"\n",
    "\n",
    "        return {\n",
    "            \"multiplier\": round(final_multiplier, 2),\n",
    "            \"confidence\": round(confidence, 2),\n",
    "            \"global_baseline\": baseline,\n",
    "            \"local_adjustment\": round(local_adjustment, 2),\n",
    "            \"population_estimate\": total_population,\n",
    "            \"competition_count\": comp_count,\n",
    "            \"notes\": notes\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating multiplier: {e}\")\n",
    "        # Return a default value with low confidence\n",
    "        return {\n",
    "            \"multiplier\": global_baseline_multipliers.get(business_type, 1.0),\n",
    "            \"confidence\": 0.5,\n",
    "            \"global_baseline\": global_baseline_multipliers.get(business_type, 1.0),\n",
    "            \"local_adjustment\": 1.0,\n",
    "            \"population_estimate\": 0,\n",
    "            \"competition_count\": 0,\n",
    "            \"notes\": \"Error in calculation. Using baseline value.\"\n",
    "        }\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with a cafe in a generic location\n",
    "    result = get_business_type_multiplier(\"cafe\", 40.7128, -74.0060, 2000)  # NYC coordinates\n",
    "    print(\"Business Multiplier Result:\")\n",
    "    for key, value in result.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population (within radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Business Location Analysis\n",
      "==================================================\n",
      "\n",
      "Analyzing cafe in Paris, France:\n",
      "WorldPop data unavailable, using OSM estimation...\n",
      "Using default population estimation...\n",
      "  Multiplier: 1.28 (Confidence: 0.9)\n",
      "  Population: 12,566\n",
      "  Competitors: 824\n",
      "  Income Index: 0.5\n",
      "  Notes: High competition (824 competitors). Consider differentiation.\n",
      "\n",
      "Analyzing restaurant in Tokyo, Japan:\n",
      "WorldPop data unavailable, using OSM estimation...\n",
      "Using default population estimation...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 363\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m business_type, location \u001b[38;5;129;01min\u001b[39;00m test_locations:\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAnalyzing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbusiness_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocation\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     result = \u001b[43manalyze_business_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbusiness_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius_km\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Multiplier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mmultiplier\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (Confidence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    366\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Population: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mpopulation\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 274\u001b[39m, in \u001b[36manalyze_business_location\u001b[39m\u001b[34m(business_type, place_name, radius_km)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;66;03m# 2. Calculate Local Demand Score\u001b[39;00m\n\u001b[32m    273\u001b[39m total_population = get_population_within_radius(lat, lon, radius_km)\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m avg_income_index = \u001b[43mget_income_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius_km\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m local_demand_score = total_population * avg_income_index\n\u001b[32m    277\u001b[39m \u001b[38;5;66;03m# 3. Calculate Local Supply Score (Competition)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 166\u001b[39m, in \u001b[36mget_income_index\u001b[39m\u001b[34m(lat, lon, radius_km)\u001b[39m\n\u001b[32m    154\u001b[39m overpass_url = \u001b[33m\"\u001b[39m\u001b[33mhttp://overpass-api.de/api/interpreter\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    155\u001b[39m overpass_query = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[33m[out:json][timeout:25];\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[33m(\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    163\u001b[39m \u001b[33mout count;\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverpass_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverpass_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m data = response.json()\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# Count commercial entities\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py:587\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    582\u001b[39m send_kwargs = {\n\u001b[32m    583\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    584\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    585\u001b[39m }\n\u001b[32m    586\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m587\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py:701\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    698\u001b[39m start = preferred_clock()\n\u001b[32m    700\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    704\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\adapters.py:486\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    483\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    501\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py:790\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    787\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    789\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    806\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py:536\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connection.py:454\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[32m    453\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    457\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    708\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from geopy.geocoders import Nominatim\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Global baseline multipliers (from industry reports)\n",
    "global_baseline_multipliers = {\n",
    "    \"cafe\": 1.2,\n",
    "    \"restaurant\": 1.0,\n",
    "    \"gym\": 0.8,\n",
    "    \"clothing_store\": 0.9,\n",
    "    \"supermarket\": 1.5,\n",
    "    \"pharmacy\": 1.1,\n",
    "    \"electronics_store\": 1.3,\n",
    "    \"jewelry_store\": 1.4,\n",
    "    \"book_store\": 0.7,\n",
    "    \"bar\": 1.2\n",
    "}\n",
    "\n",
    "# --- Step 1: Get coordinates from place name ---\n",
    "def get_coordinates(place_name):\n",
    "    \"\"\"Get latitude and longitude for any location worldwide\"\"\"\n",
    "    geolocator = Nominatim(user_agent=\"business_analysis_app\")\n",
    "    try:\n",
    "        location = geolocator.geocode(place_name)\n",
    "        if location:\n",
    "            return (location.latitude, location.longitude)\n",
    "        else:\n",
    "            print(f\"Location '{place_name}' not found. Using fallback estimation.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Geocoding error: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Step 2: Create circle polygon (GeoJSON) ---\n",
    "def create_circle_geojson(lat, lon, radius_km, num_points=36):\n",
    "    \"\"\"Create a circular polygon for API queries\"\"\"\n",
    "    coords = []\n",
    "    for i in range(num_points):\n",
    "        angle = 2 * math.pi * i / num_points\n",
    "        dx = radius_km / 111.32 * math.cos(angle)   # ~111.32 km per degree latitude\n",
    "        dy = radius_km / (111.32 * math.cos(math.radians(lat))) * math.sin(angle)\n",
    "        coords.append([lon + dy, lat + dx])\n",
    "    coords.append(coords[0])  # close polygon\n",
    "\n",
    "    geojson = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {},\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Polygon\",\n",
    "                    \"coordinates\": [coords]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    return geojson\n",
    "\n",
    "# --- Step 3: Query WorldPop API with GeoJSON ---\n",
    "def fetch_population_worldpop(lat, lon, radius_km=5, year=2020):\n",
    "    \"\"\"Get population data from WorldPop API\"\"\"\n",
    "    try:\n",
    "        geojson = create_circle_geojson(lat, lon, radius_km)\n",
    "\n",
    "        url = \"https://api.worldpop.org/v1/services/stats\"\n",
    "        params = {\n",
    "            \"dataset\": \"wpgppop\",   # WorldPop global population dataset\n",
    "            \"year\": str(year),\n",
    "            \"geojson\": json.dumps(geojson)  # must be stringified\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"data\" in data and \"total_population\" in data[\"data\"]:\n",
    "                return data[\"data\"][\"total_population\"]\n",
    "        \n",
    "        return None  # API didn't return valid data\n",
    "    except Exception as e:\n",
    "        print(f\"WorldPop API error: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Step 4: Alternative population estimation using OpenStreetMap ---\n",
    "def estimate_population_osm(lat, lon, radius_km):\n",
    "    \"\"\"Fallback population estimation using OpenStreetMap data\"\"\"\n",
    "    try:\n",
    "        radius_meters = radius_km * 1000\n",
    "        \n",
    "        # Query for residential buildings\n",
    "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        overpass_query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          node[\"building\"~\"residential|apartments|house|detached\"](around:{radius_meters},{lat},{lon});\n",
    "          way[\"building\"~\"residential|apartments|house|detached\"](around:{radius_meters},{lat},{lon});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\"\n",
    "        \n",
    "        response = requests.post(overpass_url, data=overpass_query, timeout=15)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Count buildings\n",
    "        building_count = 0\n",
    "        for element in data.get('elements', []):\n",
    "            if element.get('type') == 'count':\n",
    "                building_count = element.get('total', 0)\n",
    "                break\n",
    "        \n",
    "        # Estimate population (4 people per building on average)\n",
    "        estimated_population = building_count * 4\n",
    "        \n",
    "        # Adjust for urban vs rural (more dense in cities)\n",
    "        urban_density_factor = 1.5  # Adjust based on location type if possible\n",
    "        return int(estimated_population * urban_density_factor)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"OSM estimation error: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Step 5: Get population with fallbacks ---\n",
    "def get_population_within_radius(lat, lon, radius_km=5):\n",
    "    \"\"\"Get population with multiple fallback methods\"\"\"\n",
    "    # Try WorldPop first\n",
    "    population = fetch_population_worldpop(lat, lon, radius_km)\n",
    "    \n",
    "    # If WorldPop fails, try OSM estimation\n",
    "    if population is None or population == 0:\n",
    "        print(\"WorldPop data unavailable, using OSM estimation...\")\n",
    "        population = estimate_population_osm(lat, lon, radius_km)\n",
    "    \n",
    "    # If both methods fail, use a reasonable default based on area\n",
    "    if population is None or population == 0:\n",
    "        print(\"Using default population estimation...\")\n",
    "        # Estimate based on area (people per sq km)\n",
    "        area_sq_km = math.pi * (radius_km ** 2)\n",
    "        \n",
    "        # Default population densities (people per sq km)\n",
    "        # Urban: 2000, Suburban: 1000, Rural: 200\n",
    "        population = int(area_sq_km * 1000)  # Default to suburban density\n",
    "    \n",
    "    return max(population, 100)  # Ensure minimum population\n",
    "\n",
    "# --- Step 6: Income estimation ---\n",
    "def get_income_index(lat, lon, radius_km):\n",
    "    \"\"\"Estimate income level using commercial activity as proxy\"\"\"\n",
    "    try:\n",
    "        radius_meters = radius_km * 1000\n",
    "        \n",
    "        # Query for commercial activities\n",
    "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        overpass_query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          node[\"shop\"](around:{radius_meters},{lat},{lon});\n",
    "          node[\"amenity\"~\"restaurant|cafe|bank\"](around:{radius_meters},{lat},{lon});\n",
    "          way[\"shop\"](around:{radius_meters},{lat},{lon});\n",
    "          way[\"amenity\"~\"restaurant|cafe|bank\"](around:{radius_meters},{lat},{lon});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\"\n",
    "        \n",
    "        response = requests.post(overpass_url, data=overpass_query, timeout=15)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Count commercial entities\n",
    "        commercial_count = 0\n",
    "        for element in data.get('elements', []):\n",
    "            if element.get('type') == 'count':\n",
    "                commercial_count = element.get('total', 0)\n",
    "                break\n",
    "        \n",
    "        # More commercial activity = higher income area (proxy)\n",
    "        income_index = 0.5 + (commercial_count * 0.01)  # Base 0.5, +0.01 per commercial entity\n",
    "        return min(max(income_index, 0.5), 1.5)  # Cap between 0.5-1.5\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Income estimation error: {e}\")\n",
    "        return 1.0  # Default average income\n",
    "\n",
    "# --- Step 7: Get nearby businesses ---\n",
    "def get_nearby_places(lat, lon, radius_km, business_type):\n",
    "    \"\"\"Get nearby businesses using Overpass API\"\"\"\n",
    "    try:\n",
    "        radius_meters = radius_km * 1000\n",
    "        \n",
    "        # Map business types to OSM tags\n",
    "        osm_tags = {\n",
    "            \"cafe\": '[\"amenity\"=\"cafe\"]',\n",
    "            \"restaurant\": '[\"amenity\"=\"restaurant\"]',\n",
    "            \"gym\": '[\"leisure\"=\"fitness_centre\"]',\n",
    "            \"clothing_store\": '[\"shop\"=\"clothes\"]',\n",
    "            \"supermarket\": '[\"shop\"=\"supermarket\"]',\n",
    "            \"pharmacy\": '[\"amenity\"=\"pharmacy\"]',\n",
    "            \"electronics_store\": '[\"shop\"=\"electronics\"]',\n",
    "            \"jewelry_store\": '[\"shop\"=\"jewelry\"]',\n",
    "            \"book_store\": '[\"shop\"=\"books\"]',\n",
    "            \"bar\": '[\"amenity\"=\"bar\"]'\n",
    "        }\n",
    "        \n",
    "        tag_query = osm_tags.get(business_type, '[\"shop\"]')\n",
    "        \n",
    "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        overpass_query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          node{tag_query}(around:{radius_meters},{lat},{lon});\n",
    "        );\n",
    "        out;\n",
    "        \"\"\"\n",
    "        \n",
    "        response = requests.post(overpass_url, data=overpass_query, timeout=15)\n",
    "        data = response.json()\n",
    "        \n",
    "        businesses = []\n",
    "        for element in data.get('elements', []):\n",
    "            if element.get('type') == 'node':\n",
    "                business = {\n",
    "                    'name': element.get('tags', {}).get('name', 'Unknown'),\n",
    "                    'user_ratings_total': 10,  # Default value\n",
    "                    'price_level': 1  # Default value\n",
    "                }\n",
    "                businesses.append(business)\n",
    "            \n",
    "        return businesses\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting nearby places: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Step 8: Calculate confidence score ---\n",
    "def calculate_confidence(population, competition_count):\n",
    "    \"\"\"Calculate confidence score based on data quality\"\"\"\n",
    "    # Base confidence on population data reliability\n",
    "    pop_confidence = min(population / 5000, 1.0)  # More population = more reliable\n",
    "    \n",
    "    # Adjust for competition data (more competition data = more reliable)\n",
    "    comp_confidence = min(competition_count / 10, 1.0)\n",
    "    \n",
    "    # Overall confidence (weighted average)\n",
    "    confidence = (pop_confidence * 0.6) + (comp_confidence * 0.4)\n",
    "    \n",
    "    return max(0.5, min(confidence, 0.9))  # Keep between 0.5-0.9\n",
    "\n",
    "# --- Step 9: Main business analysis function ---\n",
    "def analyze_business_location(business_type, place_name, radius_km=2):\n",
    "    \"\"\"\n",
    "    Analyze a business location globally\n",
    "    Returns: multiplier, confidence, and detailed analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get coordinates\n",
    "        coords = get_coordinates(place_name)\n",
    "        if coords is None:\n",
    "            # Use fallback with default values\n",
    "            return {\n",
    "                \"multiplier\": global_baseline_multipliers.get(business_type, 1.0),\n",
    "                \"confidence\": 0.5,\n",
    "                \"notes\": \"Location not found. Using baseline multiplier.\",\n",
    "                \"population\": 0,\n",
    "                \"competition_count\": 0\n",
    "            }\n",
    "            \n",
    "        lat, lon = coords\n",
    "        \n",
    "        # 1. Get the global baseline for the business type\n",
    "        baseline = global_baseline_multipliers.get(business_type, 1.0)\n",
    "\n",
    "        # 2. Calculate Local Demand Score\n",
    "        total_population = get_population_within_radius(lat, lon, radius_km)\n",
    "        avg_income_index = get_income_index(lat, lon, radius_km)\n",
    "        local_demand_score = total_population * avg_income_index\n",
    "\n",
    "        # 3. Calculate Local Supply Score (Competition)\n",
    "        competing_businesses = get_nearby_places(lat, lon, radius_km, business_type)\n",
    "        competition_count = len(competing_businesses)\n",
    "        \n",
    "        # Calculate the \"strength\" of each competitor\n",
    "        total_competition_strength = 0\n",
    "        for business in competing_businesses:\n",
    "            strength = business.get('user_ratings_total', 10) * business.get('price_level', 1)\n",
    "            total_competition_strength += strength\n",
    "\n",
    "        local_supply_score = total_competition_strength\n",
    "\n",
    "        # 4. Calculate local adjustment\n",
    "        if local_supply_score == 0:\n",
    "            local_adjustment = 1.8  # Bonus for no competition (capped)\n",
    "        else:\n",
    "            # Normalize the ratio to avoid extreme values\n",
    "            raw_ratio = local_demand_score / local_supply_score\n",
    "            # Apply sigmoid-like function to keep between 0.5-2.0\n",
    "            local_adjustment = 0.5 + 1.5 / (1 + math.exp(-0.000001 * (raw_ratio - 500000)))\n",
    "            \n",
    "        local_adjustment = max(0.5, min(2.0, local_adjustment))\n",
    "\n",
    "        # 5. Calculate Final Multiplier\n",
    "        final_multiplier = baseline * local_adjustment\n",
    "\n",
    "        # 6. Calculate Confidence\n",
    "        confidence = calculate_confidence(total_population, competition_count)\n",
    "\n",
    "        # 7. Generate notes\n",
    "        if competition_count == 0:\n",
    "            notes = \"No direct competitors found. High opportunity but verify local demand.\"\n",
    "        elif competition_count < 3:\n",
    "            notes = f\"Low competition ({competition_count} competitors). Good market conditions.\"\n",
    "        elif competition_count < 8:\n",
    "            notes = f\"Moderate competition ({competition_count} competitors). Viable market.\"\n",
    "        else:\n",
    "            notes = f\"High competition ({competition_count} competitors). Consider differentiation.\"\n",
    "\n",
    "        return {\n",
    "            \"multiplier\": round(final_multiplier, 2),\n",
    "            \"confidence\": round(confidence, 2),\n",
    "            \"population\": total_population,\n",
    "            \"competition_count\": competition_count,\n",
    "            \"income_index\": round(avg_income_index, 2),\n",
    "            \"notes\": notes,\n",
    "            \"location\": place_name,\n",
    "            \"coordinates\": (lat, lon),\n",
    "            \"radius_km\": radius_km\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in business analysis: {e}\")\n",
    "        # Return a default value with low confidence\n",
    "        return {\n",
    "            \"multiplier\": global_baseline_multipliers.get(business_type, 1.0),\n",
    "            \"confidence\": 0.5,\n",
    "            \"population\": 0,\n",
    "            \"competition_count\": 0,\n",
    "            \"income_index\": 1.0,\n",
    "            \"notes\": \"Error in analysis. Using baseline value.\",\n",
    "            \"location\": place_name,\n",
    "            \"radius_km\": radius_km\n",
    "        }\n",
    "\n",
    "# --- Step 10: Run the analysis ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with different locations globally\n",
    "    test_locations = [\n",
    "        (\"cafe\", \"Paris, France\"),\n",
    "        (\"restaurant\", \"Tokyo, Japan\"),\n",
    "        (\"gym\", \"New York, USA\"),\n",
    "        (\"supermarket\", \"London, UK\"),\n",
    "        (\"pharmacy\", \"Sydney, Australia\"),\n",
    "        (\"electronics_store\", \"Seoul, South Korea\"),\n",
    "        (\"book_store\", \"Toronto, Canada\"),\n",
    "        (\"bar\", \"Berlin, Germany\"),\n",
    "        (\"clothing_store\", \"Milan, Italy\"),\n",
    "        (\"jewelry_store\", \"Dubai, UAE\")\n",
    "    ]\n",
    "    \n",
    "    print(\"Global Business Location Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for business_type, location in test_locations:\n",
    "        print(f\"\\nAnalyzing {business_type} in {location}:\")\n",
    "        result = analyze_business_location(business_type, location, radius_km=2)\n",
    "        \n",
    "        print(f\"  Multiplier: {result['multiplier']} (Confidence: {result['confidence']})\")\n",
    "        print(f\"  Population: {result['population']:,}\")\n",
    "        print(f\"  Competitors: {result['competition_count']}\")\n",
    "        print(f\"  Income Index: {result['income_index']}\")\n",
    "        print(f\"  Notes: {result['notes']}\")\n",
    "        \n",
    "        # Add a small delay to avoid overloading APIs\n",
    "        time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
