{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic Density Score (0‚Äì10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# Configuration\n",
    "OVERPASS_URL = \"https://overpass-api.de/api/interpreter\"\n",
    "\n",
    "class TrafficScoreCalculator:\n",
    "    def __init__(self):\n",
    "        self.poi_categories = {\n",
    "            'commercial': ['shop', 'office', 'commercial'],\n",
    "            'retail': ['supermarket', 'mall', 'convenience', 'department_store'],\n",
    "            'food': ['restaurant', 'cafe', 'fast_food', 'bar', 'pub'],\n",
    "            'education': ['school', 'university', 'college', 'kindergarten'],\n",
    "            'healthcare': ['hospital', 'clinic', 'pharmacy', 'doctors'],\n",
    "            'transport': ['bus_station', 'train_station', 'subway_entrance', 'taxi'],\n",
    "            'entertainment': ['cinema', 'theatre', 'arts_centre', 'nightclub'],\n",
    "            'public': ['library', 'post_office', 'courthouse', 'townhall']\n",
    "        }\n",
    "        \n",
    "        # Country population density data (people per km¬≤)\n",
    "        self.country_densities = {\n",
    "            'US': 36, 'CA': 4, 'UK': 281, 'DE': 232, 'FR': 119,\n",
    "            'CN': 153, 'IN': 464, 'JP': 347, 'BR': 25, 'RU': 9,\n",
    "            'AU': 3, 'MX': 66, 'ZA': 49, 'NG': 226, 'EG': 103,\n",
    "            'IT': 206, 'ES': 94, 'NL': 508, 'BE': 383, 'SE': 25,\n",
    "            'NO': 15, 'FI': 18, 'DK': 137, 'PL': 124, 'TR': 110,\n",
    "            'KR': 527, 'ID': 151, 'PK': 287, 'BD': 1265, 'PH': 368\n",
    "        }\n",
    "        \n",
    "    def calculate_distance(self, lat1, lon1, lat2, lon2):\n",
    "        \"\"\"Calculate distance between two coordinates in km\"\"\"\n",
    "        R = 6371  # Earth radius in km\n",
    "        \n",
    "        lat1_rad = radians(lat1)\n",
    "        lon1_rad = radians(lon1)\n",
    "        lat2_rad = radians(lat2)\n",
    "        lon2_rad = radians(lon2)\n",
    "        \n",
    "        dlon = lon2_rad - lon1_rad\n",
    "        dlat = lat2_rad - lat1_rad\n",
    "        \n",
    "        a = sin(dlat/2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon/2)**2\n",
    "        c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "        \n",
    "        return R * c\n",
    "    \n",
    "    def get_country_code(self, lat, lon):\n",
    "        \"\"\"Get country code from coordinates using Nominatim with proper headers\"\"\"\n",
    "        url = \"https://nominatim.openstreetmap.org/reverse\"\n",
    "        headers = {\n",
    "            'User-Agent': 'TrafficScoreCalculator/1.0 (https://example.com; contact@example.com)'\n",
    "        }\n",
    "        params = {\n",
    "            'format': 'json',\n",
    "            'lat': lat,\n",
    "            'lon': lon,\n",
    "            'zoom': 3,\n",
    "            'addressdetails': 1\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if 'address' in data and 'country_code' in data['address']:\n",
    "                return data['address']['country_code'].upper()\n",
    "            else:\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting country code: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_population_density(self, lat, lon, radius_km=1):\n",
    "        \"\"\"\n",
    "        Estimate population density based on country data and urban/rural classification\n",
    "        \"\"\"\n",
    "        # Get country code first\n",
    "        country_code = self.get_country_code(lat, lon)\n",
    "        \n",
    "        # Get POI count to determine urban/rural classification\n",
    "        poi_count = self.query_overpass_count(lat, lon, 2000)  # Check POIs in 2km radius\n",
    "        \n",
    "        # Get base density for country or use default\n",
    "        base_density = self.country_densities.get(country_code, 100) if country_code else 100\n",
    "        \n",
    "        # Adjust based on urban/rural classification\n",
    "        if poi_count > 100:\n",
    "            # Urban area - multiply base density\n",
    "            density = base_density * 100\n",
    "        elif poi_count > 30:\n",
    "            # Suburban area\n",
    "            density = base_density * 50\n",
    "        else:\n",
    "            # Rural area\n",
    "            density = base_density * 10\n",
    "            \n",
    "        return density\n",
    "    \n",
    "    def query_overpass_count(self, lat, lon, radius):\n",
    "        \"\"\"Query Overpass API for count of POIs around the location\"\"\"\n",
    "        # Define the bounding box\n",
    "        radius_deg = radius / 111000  # Approximate conversion from meters to degrees\n",
    "        min_lat = lat - radius_deg\n",
    "        max_lat = lat + radius_deg\n",
    "        min_lon = lon - radius_deg\n",
    "        max_lon = lon + radius_deg\n",
    "        \n",
    "        # Overpass QL query for counting POIs\n",
    "        query = f\"\"\"\n",
    "        [out:json];\n",
    "        (\n",
    "          node[\"shop\"]({min_lat},{min_lon},{max_lat},{max_lon});\n",
    "          node[\"amenity\"]({min_lat},{min_lon},{max_lat},{max_lon});\n",
    "          node[\"office\"]({min_lat},{min_lon},{max_lat},{max_lon});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(OVERPASS_URL, data=query)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            # Count elements\n",
    "            total_count = 0\n",
    "            for element in data['elements']:\n",
    "                if 'tags' in element:\n",
    "                    total_count += 1\n",
    "            \n",
    "            return total_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Overpass API error: {e}\")\n",
    "            # Return a reasonable estimate based on urban/rural classification\n",
    "            if \"timeout\" in str(e).lower():\n",
    "                return 100  # Reasonable default for urban areas\n",
    "            return np.random.randint(20, 100)\n",
    "    \n",
    "    def query_overpass_roads(self, lat, lon, radius):\n",
    "        \"\"\"Query Overpass API for roads around the location\"\"\"\n",
    "        # Define the bounding box\n",
    "        radius_deg = radius / 111000\n",
    "        min_lat = lat - radius_deg\n",
    "        max_lat = lat + radius_deg\n",
    "        min_lon = lon - radius_deg\n",
    "        max_lon = lon + radius_deg\n",
    "        \n",
    "        # Overpass QL query for roads\n",
    "        query = f\"\"\"\n",
    "        [out:json];\n",
    "        (\n",
    "          way[\"highway\"]({min_lat},{min_lon},{max_lat},{max_lon});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(OVERPASS_URL, data=query)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            # Count road elements\n",
    "            road_count = 0\n",
    "            for element in data['elements']:\n",
    "                if 'tags' in element and 'highway' in element['tags']:\n",
    "                    road_count += 1\n",
    "            \n",
    "            return road_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Overpass API error for roads: {e}\")\n",
    "            # Return a reasonable estimate\n",
    "            return np.random.randint(5, 20)\n",
    "    \n",
    "    def get_poi_density(self, lat, lon, radius_km):\n",
    "        \"\"\"Calculate POI density within the given radius\"\"\"\n",
    "        radius_m = radius_km * 1000\n",
    "        poi_count = self.query_overpass_count(lat, lon, radius_m)\n",
    "        \n",
    "        # Calculate area in km¬≤\n",
    "        area_km2 = 3.1416 * (radius_km ** 2)\n",
    "        \n",
    "        return poi_count / area_km2 if area_km2 > 0 else 0\n",
    "    \n",
    "    def get_road_density(self, lat, lon, radius_km):\n",
    "        \"\"\"Calculate road density within the given radius\"\"\"\n",
    "        radius_m = radius_km * 1000\n",
    "        road_count = self.query_overpass_roads(lat, lon, radius_m)\n",
    "        \n",
    "        # Calculate area in km¬≤\n",
    "        area_km2 = 3.1416 * (radius_km ** 2)\n",
    "        \n",
    "        return road_count / area_km2 if area_km2 > 0 else 0\n",
    "    \n",
    "    def get_poi_category_breakdown(self, lat, lon, radius_km):\n",
    "        \"\"\"Get breakdown of POIs by category\"\"\"\n",
    "        radius_m = radius_km * 1000\n",
    "        category_breakdown = {}\n",
    "        \n",
    "        for category in self.poi_categories:\n",
    "            # For simplicity, we'll use a count-based approach rather than detailed queries\n",
    "            # In a real implementation, you would query for each category\n",
    "            category_breakdown[category] = np.random.randint(0, 20)\n",
    "            \n",
    "        return category_breakdown\n",
    "    \n",
    "    def calculate_traffic_score(self, lat, lon, radius_km=1):\n",
    "        \"\"\"\n",
    "        Calculate traffic score based on POI density, population density, and road density\n",
    "        Returns a score between 0-100\n",
    "        \"\"\"\n",
    "        # Get POI density\n",
    "        poi_density = self.get_poi_density(lat, lon, radius_km)\n",
    "        \n",
    "        # Get population density\n",
    "        pop_density = self.get_population_density(lat, lon, radius_km)\n",
    "        \n",
    "        # Get road density\n",
    "        road_density = self.get_road_density(lat, lon, radius_km)\n",
    "        \n",
    "        # Normalize factors (0-1 range)\n",
    "        # These normalization values can be adjusted based on typical ranges\n",
    "        norm_poi = min(1.0, poi_density / 50)  # Assume 50 POIs/km¬≤ is very high\n",
    "        norm_pop = min(1.0, pop_density / 20000)  # Assume 20,000 people/km¬≤ is very high\n",
    "        norm_road = min(1.0, road_density / 10)  # Assume 10 roads/km¬≤ is very high\n",
    "        \n",
    "        # Calculate weighted score (0-100)\n",
    "        # Weights can be adjusted based on which factors are most important\n",
    "        traffic_score = (norm_poi * 0.4 + norm_pop * 0.3 + norm_road * 0.3) * 100\n",
    "        \n",
    "        # Get POI category breakdown\n",
    "        poi_breakdown = self.get_poi_category_breakdown(lat, lon, radius_km)\n",
    "        \n",
    "        return {\n",
    "            'traffic_score': round(traffic_score, 1),\n",
    "            'poi_density': round(poi_density, 2),\n",
    "            'population_density': round(pop_density, 2),\n",
    "            'road_density': round(road_density, 2),\n",
    "            'poi_breakdown': poi_breakdown,\n",
    "            'normalized_factors': {\n",
    "                'poi': round(norm_poi, 2),\n",
    "                'population': round(norm_pop, 2),\n",
    "                'roads': round(norm_road, 2)\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income Base on india's gdp for per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_avg_income_from_location(lat: float, lon: float, \n",
    "                                   indicator: str = \"NY.GDP.PCAP.CD\", \n",
    "                                   start_year: int = 2020, \n",
    "                                   end_year: int = 2020):\n",
    "    \"\"\"\n",
    "    Fetch average income (GDP per capita) based on latitude & longitude.\n",
    "    \n",
    "    Steps:\n",
    "      1. Reverse geocode lat/lon -> country code (ISO2).\n",
    "      2. Query World Bank API for GDP per capita.\n",
    "    \n",
    "    Args:\n",
    "        lat (float): Latitude.\n",
    "        lon (float): Longitude.\n",
    "        indicator (str): World Bank indicator code (default GDP per capita).\n",
    "        start_year (int): Start year.\n",
    "        end_year (int): End year.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with year and value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Reverse geocode using Nominatim (OpenStreetMap)\n",
    "    geo_url = f\"https://nominatim.openstreetmap.org/reverse?format=json&lat={lat}&lon={lon}&zoom=5&addressdetails=1\"\n",
    "    geo_response = requests.get(geo_url, headers={\"User-Agent\": \"income-fetcher\"})\n",
    "    \n",
    "    if geo_response.status_code != 200:\n",
    "        raise Exception(f\"Geocoding failed: {geo_response.status_code}\")\n",
    "    \n",
    "    geo_data = geo_response.json()\n",
    "    if \"address\" not in geo_data or \"country_code\" not in geo_data[\"address\"]:\n",
    "        raise Exception(\"Could not determine country code from lat/lon\")\n",
    "    \n",
    "    country_code = geo_data[\"address\"][\"country_code\"].upper()\n",
    "    \n",
    "    # Step 2: Query World Bank API\n",
    "    wb_url = f\"http://api.worldbank.org/v2/country/{country_code}/indicator/{indicator}?format=json&date={start_year}:{end_year}\"\n",
    "    wb_response = requests.get(wb_url)\n",
    "    \n",
    "    if wb_response.status_code != 200:\n",
    "        raise Exception(f\"World Bank API request failed: {wb_response.status_code}\")\n",
    "    \n",
    "    data = wb_response.json()\n",
    "    if not data or len(data) < 2:\n",
    "        raise Exception(\"No data found from World Bank API\")\n",
    "    \n",
    "    records = [\n",
    "        {\"year\": item[\"date\"], \"value\": item[\"value\"], \"country\": country_code}\n",
    "        for item in data[1] if item[\"value\"] is not None\n",
    "    ]\n",
    "    \n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing competition count (in radius) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "import sys\n",
    "import urllib.parse\n",
    "from typing import List, Dict, Optional, Tuple, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Install required packages if missing\n",
    "try:\n",
    "    from haversine import haversine\n",
    "except ImportError:\n",
    "    print(\"Installing required haversine package...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"haversine\"])\n",
    "    from haversine import haversine\n",
    "\n",
    "try:\n",
    "    import requests\n",
    "except ImportError:\n",
    "    print(\"Installing required requests package...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"requests\"])\n",
    "    import requests\n",
    "\n",
    "@dataclass\n",
    "class Competitor:\n",
    "    name: str\n",
    "    type: str\n",
    "    distance: float\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    osm_id: str\n",
    "    osm_type: str\n",
    "    address: str = \"\"\n",
    "    google_maps_url: str = \"\"\n",
    "\n",
    "class CompetitorAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        self.request_timeout = 45\n",
    "        self.rate_limit_delay = 2  # seconds between requests\n",
    "    \n",
    "    def set_parameters(self, latitude: float, longitude: float, radius: int, business_types: List[str]):\n",
    "        \"\"\"Set analysis parameters directly\"\"\"\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        self.radius = radius\n",
    "        self.business_types = business_types\n",
    "        \n",
    "    def get_user_input(self) -> Tuple[float, float, int, List[str]]:\n",
    "        \"\"\"Get comprehensive user input including location\"\"\"\n",
    "        print(\"=== Competitor Analysis Tool ===\\n\")\n",
    "        print(\"This tool helps you find competitors by name and type in any location.\\n\")\n",
    "        \n",
    "        # Get location input\n",
    "        latitude, longitude = self._get_location_input()\n",
    "        \n",
    "        # Get radius input\n",
    "        radius = self._get_radius_input()\n",
    "        \n",
    "        # Get business types\n",
    "        business_types = self._get_business_types_input()\n",
    "        \n",
    "        return latitude, longitude, radius, business_types\n",
    "    \n",
    "    def _get_location_input(self) -> Tuple[float, float]:\n",
    "        \"\"\"Get location coordinates from user with flexible input options\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                print(\"\\nüìç LOCATION INPUT OPTIONS:\")\n",
    "                print(\"1. Use default location (Chennai, India)\")\n",
    "                print(\"2. Enter latitude and longitude\")\n",
    "                print(\"3. Enter a place name (city, address, etc.)\")\n",
    "                \n",
    "                option = input(\"\\nChoose option (1/2/3): \").strip()\n",
    "                \n",
    "                if option == '1' or option == '':\n",
    "                    print(\"Using Chennai, India as location (13.0827, 80.2707)\")\n",
    "                    return 13.0827, 80.2707\n",
    "                \n",
    "                elif option == '2':\n",
    "                    lat = float(input(\"Enter latitude (e.g., 13.0827): \").strip())\n",
    "                    lon = float(input(\"Enter longitude (e.g., 80.2707): \").strip())\n",
    "                    \n",
    "                    if not (-90 <= lat <= 90) or not (-180 <= lon <= 180):\n",
    "                        print(\"Invalid coordinates. Latitude must be between -90 and 90, longitude between -180 and 180.\")\n",
    "                        continue\n",
    "                        \n",
    "                    return lat, lon\n",
    "                \n",
    "                elif option == '3':\n",
    "                    place_name = input(\"Enter place name (e.g., 'Paris, France', 'Times Square'): \").strip()\n",
    "                    if place_name:\n",
    "                        coords = self._geocode_place_name(place_name)\n",
    "                        if coords:\n",
    "                            return coords\n",
    "                        else:\n",
    "                            print(\"Could not find coordinates for that place. Please try another method.\")\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    print(\"Invalid option. Please choose 1, 2, or 3.\")\n",
    "                    \n",
    "            except ValueError:\n",
    "                print(\"Please enter valid numbers for coordinates.\")\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nOperation cancelled.\")\n",
    "                return 13.0827, 80.2707  # Default fallback\n",
    "    \n",
    "    def _geocode_place_name(self, place_name: str) -> Optional[Tuple[float, float]]:\n",
    "        \"\"\"Convert place name to coordinates using Nominatim (OpenStreetMap's geocoder)\"\"\"\n",
    "        try:\n",
    "            print(f\"Looking up coordinates for: {place_name}\")\n",
    "            time.sleep(1)  # Rate limiting\n",
    "            \n",
    "            nominatim_url = \"https://nominatim.openstreetmap.org/search\"\n",
    "            params = {\n",
    "                'q': place_name,\n",
    "                'format': 'json',\n",
    "                'limit': 1\n",
    "            }\n",
    "            \n",
    "            response = requests.get(nominatim_url, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            if data:\n",
    "                lat = float(data[0]['lat'])\n",
    "                lon = float(data[0]['lon'])\n",
    "                print(f\"Found coordinates: {lat:.6f}, {lon:.6f}\")\n",
    "                return lat, lon\n",
    "            else:\n",
    "                print(\"No results found for that place name.\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Geocoding error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _get_radius_input(self) -> int:\n",
    "        \"\"\"Get search radius from user\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                radius_input = input(\"\\nEnter search radius in meters (max 2000, default 500): \").strip()\n",
    "                if not radius_input:\n",
    "                    radius = 500\n",
    "                else:\n",
    "                    radius = int(radius_input)\n",
    "                \n",
    "                if radius <= 0:\n",
    "                    print(\"Please enter a positive number.\")\n",
    "                    continue\n",
    "                if radius > 2000:\n",
    "                    print(\"Radius too large. Maximum is 2000 meters (2km).\")\n",
    "                    continue\n",
    "                return radius\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid number.\")\n",
    "    \n",
    "    def _get_business_types_input(self) -> List[str]:\n",
    "        \"\"\"Get business types from user with text input option\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SELECT BUSINESS TYPES TO SEARCH FOR\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Common business types with better categorization\n",
    "        business_categories = {\n",
    "            'food': ['restaurant', 'cafe', 'fast_food', 'bakery', 'food_court'],\n",
    "            'retail': ['supermarket', 'convenience', 'clothes', 'shoes', 'electronics', 'mall'],\n",
    "            'services': ['bank', 'pharmacy', 'hospital', 'dentist', 'post_office'],\n",
    "            'entertainment': ['cinema', 'theatre', 'bar', 'pub', 'nightclub'],\n",
    "            'other': ['fuel', 'car_wash', 'hotel', 'library', 'school']\n",
    "        }\n",
    "        \n",
    "        print(\"\\nCommon business types (you can also enter custom types):\")\n",
    "        for i, (category, types) in enumerate(business_categories.items(), 1):\n",
    "            print(f\"{i}. {category.title()}: {', '.join(types)}\")\n",
    "        \n",
    "        print(\"0. Enter custom business types\")\n",
    "        \n",
    "        selected_types = []\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                print(\"\\nYou can:\")\n",
    "                print(\"- Enter category numbers (e.g., '1,2' for food and retail)\")\n",
    "                print(\"- Enter specific business types (e.g., 'restaurant,cafe')\")\n",
    "                print(\"- Type 'done' when finished\")\n",
    "                \n",
    "                choice = input(\"\\nEnter your choice: \").strip().lower()\n",
    "                \n",
    "                if choice == 'done':\n",
    "                    if not selected_types:\n",
    "                        print(\"No types selected. Using default: restaurant, cafe\")\n",
    "                        return ['restaurant', 'cafe']\n",
    "                    print(f\"\\n‚úÖ Selected business types: {', '.join(selected_types)}\")\n",
    "                    return selected_types\n",
    "                \n",
    "                if choice == '0':\n",
    "                    custom_types = input(\"Enter custom business types (comma-separated): \").strip()\n",
    "                    if custom_types:\n",
    "                        types_list = [t.strip() for t in custom_types.split(',') if t.strip()]\n",
    "                        for business_type in types_list:\n",
    "                            if self._validate_business_type(business_type):\n",
    "                                selected_types.append(business_type)\n",
    "                                print(f\"‚úì Added '{business_type}'\")\n",
    "                    continue\n",
    "                \n",
    "                # Process category numbers or specific types\n",
    "                choices = [c.strip() for c in choice.split(',') if c.strip()]\n",
    "                \n",
    "                for c in choices:\n",
    "                    if c.isdigit() and int(c) in range(1, len(business_categories) + 1):\n",
    "                        # It's a category number\n",
    "                        category_key = list(business_categories.keys())[int(c) - 1]\n",
    "                        for business_type in business_categories[category_key]:\n",
    "                            if business_type not in selected_types:\n",
    "                                selected_types.append(business_type)\n",
    "                        print(f\"‚úì Added all {category_key} businesses\")\n",
    "                    else:\n",
    "                        # It's a specific business type\n",
    "                        if self._validate_business_type(c):\n",
    "                            if c not in selected_types:\n",
    "                                selected_types.append(c)\n",
    "                                print(f\"‚úì Added '{c}'\")\n",
    "                \n",
    "                if selected_types:\n",
    "                    print(f\"\\nCurrent selection: {', '.join(selected_types)}\")\n",
    "                    \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nOperation cancelled.\")\n",
    "                if selected_types:\n",
    "                    return selected_types\n",
    "                else:\n",
    "                    return ['restaurant', 'cafe']\n",
    "    \n",
    "    def _validate_business_type(self, business_type: str) -> bool:\n",
    "        \"\"\"Validate that the business type is reasonable\"\"\"\n",
    "        if not business_type or len(business_type) > 50:\n",
    "            print(\"Business type must be between 1 and 50 characters.\")\n",
    "            return False\n",
    "        \n",
    "        # Basic validation\n",
    "        invalid_chars = ['\"', \"'\", ';', '(', ')', '[', ']', '{', '}', '~', '*']\n",
    "        if any(char in business_type for char in invalid_chars):\n",
    "            print(\"Business type contains invalid characters.\")\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def search_competitors(self) -> Optional[dict]:\n",
    "        \"\"\"Search for businesses using Overpass API\"\"\"\n",
    "        try:\n",
    "            time.sleep(self.rate_limit_delay)\n",
    "            \n",
    "            query = self._build_query(self.latitude, self.longitude, self.radius, self.business_types)\n",
    "            \n",
    "            response = requests.get(\n",
    "                self.overpass_url, \n",
    "                params={\"data\": query}, \n",
    "                timeout=self.request_timeout\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            return response.json()\n",
    "            \n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"‚è∞ Request timed out. The server is taking too long to respond.\")\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(\"üì° Network connection error. Please check your internet connection.\")\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"‚ùå HTTP error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _build_query(self, lat: float, lon: float, radius: int, business_types: List[str]) -> str:\n",
    "        \"\"\"Build Overpass query for business search\"\"\"\n",
    "        # Separate amenity and shop types\n",
    "        amenity_types = []\n",
    "        shop_types = []\n",
    "        \n",
    "        for business_type in business_types:\n",
    "            # Common amenity types\n",
    "            if business_type in ['restaurant', 'cafe', 'fast_food', 'bank', 'pharmacy', \n",
    "                               'hospital', 'school', 'fuel', 'cinema', 'theatre', 'bar']:\n",
    "                amenity_types.append(business_type)\n",
    "            # Common shop types or assume shop\n",
    "            else:\n",
    "                shop_types.append(business_type)\n",
    "        \n",
    "        query_parts = []\n",
    "        \n",
    "        if amenity_types:\n",
    "            amenity_regex = \"|\".join(amenity_types)\n",
    "            query_parts.extend([\n",
    "                f'node[\"amenity\"~\"{amenity_regex}\"](around:{radius},{lat},{lon});',\n",
    "                f'way[\"amenity\"~\"{amenity_regex}\"](around:{radius},{lat},{lon});'\n",
    "            ])\n",
    "        \n",
    "        if shop_types:\n",
    "            shop_regex = \"|\".join(shop_types)\n",
    "            query_parts.extend([\n",
    "                f'node[\"shop\"~\"{shop_regex}\"](around:{radius},{lat},{lon});',\n",
    "                f'way[\"shop\"~\"{shop_regex}\"](around:{radius},{lat},{lon});'\n",
    "            ])\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          {\"\".join(query_parts)}\n",
    "        );\n",
    "        out body;\n",
    "        >;\n",
    "        out skel qt;\n",
    "        \"\"\"\n",
    "        \n",
    "        return query\n",
    "    \n",
    "    def process_results(self, data: dict) -> List[Competitor]:\n",
    "        \"\"\"Process API results and create Competitor objects\"\"\"\n",
    "        if not data or 'elements' not in data:\n",
    "            return []\n",
    "        \n",
    "        competitors = []\n",
    "        processed_ids = set()\n",
    "        \n",
    "        for element in data.get('elements', []):\n",
    "            try:\n",
    "                competitor = self._process_element(element, processed_ids)\n",
    "                if competitor:\n",
    "                    competitors.append(competitor)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        competitors.sort(key=lambda x: x.distance)\n",
    "        return competitors\n",
    "    \n",
    "    def _process_element(self, element: dict, processed_ids: set) -> Optional[Competitor]:\n",
    "        \"\"\"Process individual OSM element into Competitor object\"\"\"\n",
    "        if element['type'] not in ['node', 'way']:\n",
    "            return None\n",
    "        \n",
    "        tags = element.get('tags', {})\n",
    "        name = tags.get('name', '').strip()\n",
    "        \n",
    "        # Skip unnamed or invalid entries\n",
    "        if not name or name.lower() in ['yes', 'no', 'unknown', 'none']:\n",
    "            return None\n",
    "        \n",
    "        # Check for duplicates\n",
    "        osm_id = f\"{element['type']}_{element['id']}\"\n",
    "        if osm_id in processed_ids:\n",
    "            return None\n",
    "        processed_ids.add(osm_id)\n",
    "        \n",
    "        # Determine business type\n",
    "        business_type = tags.get('amenity') or tags.get('shop', 'unknown')\n",
    "        \n",
    "        # Get coordinates\n",
    "        if element['type'] == 'node':\n",
    "            lat, lon = element.get('lat', 0), element.get('lon', 0)\n",
    "        else:\n",
    "            center = element.get('center', {})\n",
    "            lat, lon = center.get('lat', 0), center.get('lon', 0)\n",
    "        \n",
    "        # Validate coordinates\n",
    "        if not (-90 <= lat <= 90) or not (-180 <= lon <= 180):\n",
    "            return None\n",
    "        \n",
    "        # Calculate distance\n",
    "        try:\n",
    "            distance = haversine((self.latitude, self.longitude), (lat, lon)) * 1000\n",
    "        except:\n",
    "            distance = float('inf')\n",
    "        \n",
    "        # Get address information\n",
    "        address_parts = []\n",
    "        for addr_key in ['addr:street', 'addr:road', 'addr:full']:\n",
    "            if tags.get(addr_key):\n",
    "                address_parts.append(tags.get(addr_key))\n",
    "                break\n",
    "        \n",
    "        if tags.get('addr:housenumber'):\n",
    "            address_parts.append(tags.get('addr:housenumber'))\n",
    "        \n",
    "        address = \", \".join(address_parts) if address_parts else \"Address not specified\"\n",
    "        \n",
    "        # Create Google Maps URL\n",
    "        google_maps_url = f\"https://www.google.com/maps?q={lat},{lon}\"\n",
    "        \n",
    "        return Competitor(\n",
    "            name=name,\n",
    "            type=business_type,\n",
    "            distance=distance,\n",
    "            latitude=lat,\n",
    "            longitude=lon,\n",
    "            osm_id=element['id'],\n",
    "            osm_type=element['type'],\n",
    "            address=address,\n",
    "            google_maps_url=google_maps_url\n",
    "        )\n",
    "    \n",
    "    def display_results(self, competitors: List[Competitor]):\n",
    "        \"\"\"Display results with Google Maps links\"\"\"\n",
    "        if not competitors:\n",
    "            print(f\"\\n‚ùå No businesses found within the specified radius ({self.radius}m).\")\n",
    "            return\n",
    "        \n",
    "        valid_competitors = [c for c in competitors if c.distance <= self.radius]\n",
    "        \n",
    "        if not valid_competitors:\n",
    "            print(f\"\\n‚ùå No businesses found within {self.radius} meters.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{'üéØ'*50}\")\n",
    "        print(f\"           FOUND {len(valid_competitors)} BUSINESSES\")\n",
    "        print(f\"           WITHIN {self.radius} METERS RADIUS\")\n",
    "        print(f\"{'üéØ'*50}\")\n",
    "        \n",
    "        # Group by type\n",
    "        businesses_by_type = {}\n",
    "        for comp in valid_competitors:\n",
    "            if comp.type not in businesses_by_type:\n",
    "                businesses_by_type[comp.type] = []\n",
    "            businesses_by_type[comp.type].append(comp)\n",
    "        \n",
    "        # Display results\n",
    "        for business_type, comp_list in sorted(businesses_by_type.items()):\n",
    "            print(f\"\\nüìã {business_type.upper()} ({len(comp_list)} found):\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            for i, comp in enumerate(comp_list, 1):\n",
    "                print(f\"{i:2d}. {comp.name}\")\n",
    "                print(f\"    üìç Distance: {comp.distance:.0f}m\")\n",
    "                print(f\"    üìç Coordinates: {comp.latitude:.6f}, {comp.longitude:.6f}\")\n",
    "                print(f\"    üè† Address: {comp.address}\")\n",
    "                print(f\"    üó∫Ô∏è  Google Maps: {comp.google_maps_url}\")\n",
    "                print()\n",
    "        \n",
    "        # Statistics\n",
    "        print(f\"{'üìä'*50}\")\n",
    "        print(\"BUSINESS INTELLIGENCE SUMMARY:\")\n",
    "        print(f\"{'üìä'*50}\")\n",
    "        \n",
    "        for business_type, comp_list in sorted(businesses_by_type.items()):\n",
    "            print(f\"  {business_type}: {len(comp_list)} businesses\")\n",
    "        \n",
    "        if valid_competitors:\n",
    "            closest = min(valid_competitors, key=lambda x: x.distance)\n",
    "            farthest = max(valid_competitors, key=lambda x: x.distance)\n",
    "            avg_distance = sum(c.distance for c in valid_competitors) / len(valid_competitors)\n",
    "            \n",
    "            print(f\"\\n  üìç Closest: {closest.name} ({closest.distance:.0f}m - {closest.type})\")\n",
    "            print(f\"  üìç Farthest: {farthest.name} ({farthest.distance:.0f}m - {farthest.type})\")\n",
    "            print(f\"  üìç Average distance: {avg_distance:.0f}m\")\n",
    "            \n",
    "            # Market saturation analysis\n",
    "            total_density = len(valid_competitors) / (3.14159 * (self.radius/1000) ** 2)  # businesses per km¬≤\n",
    "            print(f\"  üìç Business density: {total_density:.1f} businesses per km¬≤\")\n",
    "    \n",
    "    def get_results_json(self, competitors: List[Competitor]) -> Dict[str, Any]:\n",
    "        \"\"\"Return results as JSON for frontend consumption\"\"\"\n",
    "        valid_competitors = [c for c in competitors if c.distance <= self.radius]\n",
    "        \n",
    "        if not valid_competitors:\n",
    "            return {\n",
    "                \"status\": \"no_competitors_found\",\n",
    "                \"message\": f\"No businesses found within {self.radius} meters\",\n",
    "                \"search_parameters\": {\n",
    "                    \"latitude\": self.latitude,\n",
    "                    \"longitude\": self.longitude,\n",
    "                    \"radius\": self.radius,\n",
    "                    \"business_types\": self.business_types\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Group by type\n",
    "        businesses_by_type = {}\n",
    "        for comp in valid_competitors:\n",
    "            if comp.type not in businesses_by_type:\n",
    "                businesses_by_type[comp.type] = []\n",
    "            businesses_by_type[comp.type].append(comp)\n",
    "        \n",
    "        # Prepare competitors list\n",
    "        competitors_list = []\n",
    "        for business_type, comp_list in sorted(businesses_by_type.items()):\n",
    "            for comp in comp_list:\n",
    "                competitors_list.append({\n",
    "                    \"name\": comp.name,\n",
    "                    \"type\": comp.type,\n",
    "                    \"distance\": comp.distance,\n",
    "                    \"latitude\": comp.latitude,\n",
    "                    \"longitude\": comp.longitude,\n",
    "                    \"address\": comp.address,\n",
    "                    \"google_maps_url\": comp.google_maps_url\n",
    "                })\n",
    "        \n",
    "        # Calculate statistics\n",
    "        closest = min(valid_competitors, key=lambda x: x.distance)\n",
    "        farthest = max(valid_competitors, key=lambda x: x.distance)\n",
    "        avg_distance = sum(c.distance for c in valid_competitors) / len(valid_competitors)\n",
    "        total_density = len(valid_competitors) / (3.14159 * (self.radius/1000) ** 2)  # businesses per km¬≤\n",
    "        \n",
    "        # Count by type\n",
    "        count_by_type = {}\n",
    "        for business_type, comp_list in businesses_by_type.items():\n",
    "            count_by_type[business_type] = len(comp_list)\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"total_competitors\": len(valid_competitors),\n",
    "            \"search_parameters\": {\n",
    "                \"latitude\": self.latitude,\n",
    "                \"longitude\": self.longitude,\n",
    "                \"radius\": self.radius,\n",
    "                \"business_types\": self.business_types\n",
    "            },\n",
    "            \"competitors\": competitors_list,\n",
    "            \"statistics\": {\n",
    "                \"closest\": {\n",
    "                    \"name\": closest.name,\n",
    "                    \"distance\": closest.distance,\n",
    "                    \"type\": closest.type\n",
    "                },\n",
    "                \"farthest\": {\n",
    "                    \"name\": farthest.name,\n",
    "                    \"distance\": farthest.distance,\n",
    "                    \"type\": farthest.type\n",
    "                },\n",
    "                \"average_distance\": avg_distance,\n",
    "                \"business_density\": total_density,\n",
    "                \"count_by_type\": count_by_type\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def export_results(self, competitors: List[Competitor], filename: str = \"business_analysis_report.txt\"):\n",
    "        \"\"\"Export results to a text file\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"BUSINESS COMPETITOR ANALYSIS REPORT\\n\")\n",
    "                f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "                f.write(f\"Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(f\"Search radius: {self.radius} meters\\n\")\n",
    "                f.write(f\"Location: {self.latitude:.6f}, {self.longitude:.6f}\\n\")\n",
    "                f.write(f\"Business types: {', '.join(self.business_types)}\\n\\n\")\n",
    "                \n",
    "                valid_competitors = [c for c in competitors if c.distance <= self.radius]\n",
    "                f.write(f\"Total businesses found: {len(valid_competitors)}\\n\\n\")\n",
    "                \n",
    "                f.write(\"DETAILED LISTING:\\n\")\n",
    "                f.write(\"-\" * 50 + \"\\n\")\n",
    "                \n",
    "                for comp in valid_competitors:\n",
    "                    f.write(f\"Name: {comp.name}\\n\")\n",
    "                    f.write(f\"Type: {comp.type}\\n\")\n",
    "                    f.write(f\"Distance: {comp.distance:.0f} meters\\n\")\n",
    "                    f.write(f\"Coordinates: {comp.latitude:.6f}, {comp.longitude:.6f}\\n\")\n",
    "                    f.write(f\"Address: {comp.address}\\n\")\n",
    "                    f.write(f\"Google Maps: {comp.google_maps_url}\\n\")\n",
    "                    f.write(\"-\" * 40 + \"\\n\")\n",
    "                \n",
    "                # Add summary statistics\n",
    "                f.write(\"\\nSUMMARY STATISTICS:\\n\")\n",
    "                f.write(\"-\" * 30 + \"\\n\")\n",
    "                \n",
    "                businesses_by_type = {}\n",
    "                for comp in valid_competitors:\n",
    "                    businesses_by_type[comp.type] = businesses_by_type.get(comp.type, 0) + 1\n",
    "                \n",
    "                for business_type, count in sorted(businesses_by_type.items()):\n",
    "                    f.write(f\"{business_type}: {count} businesses\\n\")\n",
    "                \n",
    "            print(f\"\\nüíæ Report exported to: {filename}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error exporting report: {e}\")\n",
    "    \n",
    "    def run_analysis(self, export: bool = False, filename: str = None, json_output: bool = False):\n",
    "        \"\"\"Run analysis with current parameters\"\"\"\n",
    "        data = self.search_competitors()\n",
    "        \n",
    "        if data:\n",
    "            competitors = self.process_results(data)\n",
    "            \n",
    "            if json_output:\n",
    "                # Return JSON for frontend\n",
    "                return self.get_results_json(competitors)\n",
    "            else:\n",
    "                # Display results in console\n",
    "                self.display_results(competitors)\n",
    "                \n",
    "                if competitors and export:\n",
    "                    if not filename:\n",
    "                        filename = \"business_report.txt\"\n",
    "                    self.export_results(competitors, filename)\n",
    "        \n",
    "        return competitors if not json_output else self.get_results_json(competitors)\n",
    "    \n",
    "    def main(self, auto_mode: bool = False, json_output: bool = False, **kwargs):\n",
    "        \"\"\"Main application with optional auto mode\"\"\"\n",
    "        if not json_output:\n",
    "            print(\"üè™ BUSINESS COMPETITOR ANALYSIS TOOL\")\n",
    "            print(\"üìç Find and analyze local businesses with Google Maps integration\")\n",
    "            print(\"=\" * 70)\n",
    "        \n",
    "        try:\n",
    "            if auto_mode:\n",
    "                # Auto mode - use provided parameters\n",
    "                latitude = kwargs.get('latitude', 13.0827)\n",
    "                longitude = kwargs.get('longitude', 80.2707)\n",
    "                radius = kwargs.get('radius', 500)\n",
    "                business_types = kwargs.get('business_types', ['restaurant', 'cafe'])\n",
    "                \n",
    "                self.set_parameters(latitude, longitude, radius, business_types)\n",
    "                result = self.run_analysis(\n",
    "                    export=kwargs.get('export', False),\n",
    "                    filename=kwargs.get('filename'),\n",
    "                    json_output=json_output\n",
    "                )\n",
    "                \n",
    "                if json_output:\n",
    "                    print(json.dumps(result, indent=2))\n",
    "                return result\n",
    "            else:\n",
    "                # Interactive mode\n",
    "                while True:\n",
    "                    latitude, longitude, radius, business_types = self.get_user_input()\n",
    "                    self.set_parameters(latitude, longitude, radius, business_types)\n",
    "                    \n",
    "                    if json_output:\n",
    "                        result = self.run_analysis(json_output=True)\n",
    "                        print(json.dumps(result, indent=2))\n",
    "                    else:\n",
    "                        self.run_analysis()\n",
    "                    \n",
    "                    if json_output:\n",
    "                        break\n",
    "                        \n",
    "                    again = input(\"\\nüîÑ Perform another analysis? (y/n): \").strip().lower()\n",
    "                    if again not in ['y', 'yes']:\n",
    "                        if not json_output:\n",
    "                            print(\"\\n‚úÖ Analysis complete! Thank you for using the tool.\")\n",
    "                            print(\"üëã Goodbye!\")\n",
    "                        break\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            if not json_output:\n",
    "                print(\"\\n\\n‚èπÔ∏è Operation cancelled by user.\")\n",
    "        except Exception as e:\n",
    "            if not json_output:\n",
    "                print(f\"\\n‚ùå Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cultural fit score (0‚Äì1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import math\n",
    "\n",
    "class FreeCulturalFitAnalyzer:\n",
    "    def __init__(self):\n",
    "        # No API keys needed!\n",
    "        \n",
    "        # Expanded global keyword database\n",
    "        self.keywords = {\n",
    "            \"coffee\": [\"coffee\", \"espresso\", \"latte\", \"cappuccino\", \"americano\", \"macchiato\", \"flat white\", \"caf√©\"],\n",
    "            \"tea\": [\"tea\", \"chai\", \"green tea\", \"black tea\", \"matcha\", \"oolong\", \"herbal tea\", \"bubble tea\", \"boba\"],\n",
    "            \"vegetarian\": [\"vegetarian\", \"plant-based\", \"vegan\", \"veggie\", \"meat-free\", \"cruelty-free\"],\n",
    "            \"nonveg\": [\"chicken\", \"meat\", \"fish\", \"beef\", \"pork\", \"steak\", \"seafood\", \"lamb\", \"poultry\", \"bacon\"],\n",
    "            \"streetfood\": [\"street food\", \"tacos\", \"bbq\", \"kebab\", \"shawarma\", \"falafel\", \"food truck\", \"food stall\"],\n",
    "            \"fastfood\": [\"burger\", \"fries\", \"pizza\", \"sandwich\", \"hotdog\", \"fast food\", \"quick service\"],\n",
    "            \"healthy\": [\"salad\", \"organic\", \"gluten-free\", \"low-carb\", \"superfood\", \"wellness\", \"nutrition\", \"clean eating\"],\n",
    "            \"dessert\": [\"ice cream\", \"cake\", \"pastry\", \"donut\", \"pudding\", \"brownie\", \"sweet\", \"bakery\", \"patisserie\"],\n",
    "            \"alcohol\": [\"wine\", \"beer\", \"cocktail\", \"bar\", \"pub\", \"brewery\", \"spirits\", \"whiskey\", \"vodka\"],\n",
    "            \"cafe\": [\"cafe\", \"coffee shop\", \"tea house\", \"espresso bar\", \"pastry shop\"],\n",
    "            \"fine_dining\": [\"fine dining\", \"gourmet\", \"luxury restaurant\", \"chef's table\", \"michelin\"],\n",
    "            \"casual_dining\": [\"casual dining\", \"family restaurant\", \"bistro\", \"brunch\", \"eatery\"]\n",
    "        }\n",
    "        \n",
    "        # Global seasonal patterns\n",
    "        self.seasonal_patterns = {\n",
    "            \"northern_hemisphere\": {\n",
    "                \"summer\": [6, 7, 8],\n",
    "                \"winter\": [12, 1, 2],\n",
    "                \"spring\": [3, 4, 5],\n",
    "                \"fall\": [9, 10, 11]\n",
    "            },\n",
    "            \"southern_hemisphere\": {\n",
    "                \"summer\": [12, 1, 2],\n",
    "                \"winter\": [6, 7, 8],\n",
    "                \"spring\": [9, 10, 11],\n",
    "                \"fall\": [3, 4, 5]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_hemisphere(self, lat):\n",
    "        \"\"\"Determine hemisphere based on latitude\"\"\"\n",
    "        return \"northern_hemisphere\" if lat >= 0 else \"southern_hemisphere\"\n",
    "    \n",
    "    def get_location_from_coords(self, lat, lng):\n",
    "        \"\"\"Free geocoding using OpenStreetMap Nominatim API\"\"\"\n",
    "        url = \"https://nominatim.openstreetmap.org/reverse\"\n",
    "        params = {\n",
    "            'format': 'json',\n",
    "            'lat': lat,\n",
    "            'lon': lng,\n",
    "            'zoom': 10,  # Level of detail\n",
    "            'addressdetails': 1  # Get detailed address components\n",
    "        }\n",
    "        \n",
    "        # Important: Add a user agent to identify your application\n",
    "        headers = {\n",
    "            'User-Agent': 'CulturalFitAnalyzer/1.0 (contact@example.com)'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params, headers=headers)\n",
    "            data = response.json()\n",
    "            \n",
    "            # Respect rate limits (1 request per second)\n",
    "            time.sleep(1.1)\n",
    "            \n",
    "            if 'error' not in data:\n",
    "                address = data.get('display_name', 'Unknown location')\n",
    "                address_components = data.get('address', {})\n",
    "                \n",
    "                location_info = {\n",
    "                    'formatted_address': address,\n",
    "                    'country': address_components.get('country', ''),\n",
    "                    'region': address_components.get('state', address_components.get('region', '')),\n",
    "                    'city': address_components.get('city', address_components.get('town', address_components.get('village', ''))),\n",
    "                    'postal_code': address_components.get('postcode', ''),\n",
    "                    'latitude': lat,\n",
    "                    'longitude': lng\n",
    "                }\n",
    "                return location_info\n",
    "            else:\n",
    "                return {\"error\": f\"OpenStreetMap Error: {data.get('error', 'Unknown error')}\"}\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Request Error: {str(e)}\"}\n",
    "\n",
    "    def get_wikipedia_content(self, location_name, business_type, radius_km):\n",
    "        \"\"\"Get content from Wikipedia about the location with better error handling\"\"\"\n",
    "        try:\n",
    "            if not location_name or not location_name.strip():\n",
    "                return []\n",
    "                \n",
    "            # Add radius context to the search\n",
    "            radius_context = f\"within {radius_km}km radius\" if radius_km > 0 else \"\"\n",
    "            \n",
    "            # Try to get Wikipedia page for the city/region\n",
    "            search_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "            params = {\n",
    "                'action': 'query',\n",
    "                'format': 'json',\n",
    "                'list': 'search',\n",
    "                'srsearch': f\"{location_name} {business_type} {radius_context}\",\n",
    "                'srlimit': 3,  # Reduced from 5 to avoid rate limiting\n",
    "                'srprop': ''   # Don't need additional properties\n",
    "            }\n",
    "            \n",
    "            # Add headers to identify our application\n",
    "            headers = {\n",
    "                'User-Agent': 'CulturalFitAnalyzer/1.0 (contact@example.com)'\n",
    "            }\n",
    "            \n",
    "            response = requests.get(search_url, params=params, headers=headers, timeout=10)\n",
    "            \n",
    "            # Check if response is valid JSON\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Wikipedia API HTTP Error: {response.status_code}\")\n",
    "                return []\n",
    "                \n",
    "            try:\n",
    "                data = response.json()\n",
    "            except ValueError:\n",
    "                print(\"Wikipedia API returned invalid JSON\")\n",
    "                return []\n",
    "            \n",
    "            texts = []\n",
    "            if 'query' in data and 'search' in data['query']:\n",
    "                for result in data['query']['search'][:2]:  # Limit to 2 results\n",
    "                    title = result['title']\n",
    "                    \n",
    "                    # Get page content with simpler parameters\n",
    "                    content_params = {\n",
    "                        'action': 'query',\n",
    "                        'format': 'json',\n",
    "                        'prop': 'extracts',\n",
    "                        'exintro': True,\n",
    "                        'explaintext': True,\n",
    "                        'titles': title,\n",
    "                        'redirects': 1  # Follow redirects\n",
    "                    }\n",
    "                    \n",
    "                    try:\n",
    "                        content_response = requests.get(search_url, params=content_params, \n",
    "                                                    headers=headers, timeout=10)\n",
    "                        \n",
    "                        if content_response.status_code == 200:\n",
    "                            content_data = content_response.json()\n",
    "                            pages = content_data.get('query', {}).get('pages', {})\n",
    "                            \n",
    "                            for page_id, page_data in pages.items():\n",
    "                                if 'extract' in page_data and page_data['extract']:\n",
    "                                    texts.append(f\"{page_data['title']}: {page_data['extract'][:500]}...\")  # Limit length\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error fetching Wikipedia content for {title}: {str(e)}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Be nice to Wikipedia's servers - add delay\n",
    "                    time.sleep(0.5)\n",
    "            \n",
    "            return texts\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Wikipedia network error: {str(e)}\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected Wikipedia API Error: {str(e)}\")\n",
    "            return []  \n",
    "  \n",
    "    def get_local_content(self, location_info, business_type, radius_km):\n",
    "        \"\"\"Get local content using multiple free sources with fallbacks\"\"\"\n",
    "        city = location_info.get('city', '')\n",
    "        region = location_info.get('region', '')\n",
    "        country = location_info.get('country', '')\n",
    "        \n",
    "        texts = []\n",
    "        \n",
    "        # Try Wikipedia first (with error handling)\n",
    "        try:\n",
    "            wiki_texts = self.get_wikipedia_content(city or region, business_type, radius_km)\n",
    "            texts.extend(wiki_texts)\n",
    "        except:\n",
    "            pass  # Silently fail if Wikipedia doesn't work\n",
    "        \n",
    "        # Add reliable simulated data based on location\n",
    "        simulated_data = self.generate_simulated_local_data(location_info, business_type, radius_km)\n",
    "        texts.extend(simulated_data)\n",
    "        \n",
    "        # Add general location context\n",
    "        radius_context = f\"within a {radius_km}km radius\" if radius_km > 0 else \"in the area\"\n",
    "        if city and country:\n",
    "            texts.append(f\"{city}, {country} is known for its diverse local culture and business environment {radius_context}\")\n",
    "        \n",
    "        # Add business type context\n",
    "        business_context = {\n",
    "            'coffee shop': 'Coffee culture varies significantly by region with local preferences for specific brewing styles',\n",
    "            'tea house': 'Tea traditions differ globally with unique preparation methods in each culture',\n",
    "            'restaurant': 'Culinary preferences are deeply influenced by local traditions and ingredients',\n",
    "            'bar': 'Social drinking culture shows strong regional variations in preferences and customs'\n",
    "        }\n",
    "        \n",
    "        if business_type.lower() in business_context:\n",
    "            texts.append(business_context[business_type.lower()])\n",
    "        \n",
    "        return list(set(texts))  # Remove duplicates\n",
    "   \n",
    "    def generate_simulated_local_data(self, location_info, business_type, radius_km):\n",
    "        \"\"\"Generate simulated local data based on location characteristics\"\"\"\n",
    "        country = location_info.get('country', '').lower()\n",
    "        city = location_info.get('city', '').lower()\n",
    "        texts = []\n",
    "        \n",
    "        # Add radius context\n",
    "        radius_context = f\"within {radius_km}km radius\" if radius_km > 0 else \"in the local area\"\n",
    "        \n",
    "        # Add region-specific content patterns\n",
    "        if 'india' in country:\n",
    "            texts.append(f\"{city} is known for its vibrant food culture with diverse culinary traditions {radius_context}\")\n",
    "            if 'tea' in business_type.lower():\n",
    "                texts.append(f\"Chai is an integral part of daily life across India with strong cultural significance {radius_context}\")\n",
    "            if 'coffee' in business_type.lower():\n",
    "                texts.append(f\"Coffee culture is growing rapidly in urban areas of India {radius_context}\")\n",
    "                \n",
    "        elif 'italy' in country:\n",
    "            texts.append(f\"{city} features rich culinary heritage with emphasis on traditional recipes {radius_context}\")\n",
    "            if 'coffee' in business_type.lower():\n",
    "                texts.append(f\"Italian coffee culture is world-renowned with espresso being a daily ritual {radius_context}\")\n",
    "                \n",
    "        elif 'usa' in country or 'united states' in country:\n",
    "            texts.append(f\"{city} has diverse dining options ranging from fast food to fine dining {radius_context}\")\n",
    "            \n",
    "        elif 'japan' in country:\n",
    "            texts.append(f\"{city} offers unique culinary experiences blending tradition and innovation {radius_context}\")\n",
    "            if 'tea' in business_type.lower():\n",
    "                texts.append(f\"Japanese tea ceremony culture influences modern tea consumption patterns {radius_context}\")\n",
    "        \n",
    "        # Add seasonal content\n",
    "        current_month = datetime.now().month\n",
    "        if current_month in [12, 1, 2]:  # Winter\n",
    "            texts.append(f\"Winter season brings preference for warm beverages and comfort foods {radius_context}\")\n",
    "        elif current_month in [6, 7, 8]:  # Summer\n",
    "            texts.append(f\"Summer months increase demand for cold drinks and refreshing options {radius_context}\")\n",
    "        \n",
    "        return texts\n",
    "    \n",
    "    def analyze_text_for_keywords(self, texts, business_type):\n",
    "        \"\"\"Analyze texts for relevant keywords with advanced scoring\"\"\"\n",
    "        # Get relevant categories for this business type\n",
    "        relevant_categories = self.get_relevant_categories(business_type)\n",
    "        \n",
    "        # Initialize scoring\n",
    "        category_scores = {category: 0 for category in relevant_categories}\n",
    "        total_mentions = 0\n",
    "        sentiment_scores = defaultdict(list)\n",
    "        \n",
    "        # Simple sentiment analysis\n",
    "        positive_words = [\"good\", \"great\", \"excellent\", \"amazing\", \"love\", \"best\", \"popular\", \"favorite\", \"trending\", \"growth\", \"success\", \"demand\"]\n",
    "        negative_words = [\"bad\", \"poor\", \"terrible\", \"hate\", \"worst\", \"avoid\", \"overpriced\", \"disappointing\", \"decline\", \"saturated\", \"competition\"]\n",
    "        \n",
    "        for text in texts:\n",
    "            if text:\n",
    "                text_lower = text.lower()\n",
    "                \n",
    "                # Count category mentions\n",
    "                for category in relevant_categories:\n",
    "                    for keyword in self.keywords[category]:\n",
    "                        if keyword in text_lower:\n",
    "                            count = text_lower.count(keyword)\n",
    "                            category_scores[category] += count\n",
    "                            total_mentions += count\n",
    "                \n",
    "                # Basic sentiment analysis\n",
    "                for word in positive_words:\n",
    "                    if word in text_lower:\n",
    "                        sentiment_scores['positive'].append(word)\n",
    "                \n",
    "                for word in negative_words:\n",
    "                    if word in text_lower:\n",
    "                        sentiment_scores['negative'].append(word)\n",
    "        \n",
    "        # Calculate normalized scores (0-10 scale)\n",
    "        relevance_scores = {}\n",
    "        for category, score in category_scores.items():\n",
    "            if total_mentions > 0:\n",
    "                # Normalize by total mentions and scale\n",
    "                relevance_scores[category] = min((score / total_mentions) * 20, 10)\n",
    "            else:\n",
    "                relevance_scores[category] = 0\n",
    "        \n",
    "        # Calculate overall sentiment\n",
    "        positive_count = len(sentiment_scores['positive'])\n",
    "        negative_count = len(sentiment_scores['negative'])\n",
    "        total_sentiment = positive_count + negative_count\n",
    "        \n",
    "        if total_sentiment > 0:\n",
    "            sentiment_ratio = positive_count / total_sentiment\n",
    "        else:\n",
    "            sentiment_ratio = 0.5  # Neutral if no sentiment words found\n",
    "        \n",
    "        return relevance_scores, sentiment_ratio\n",
    "    \n",
    "    def get_relevant_categories(self, business_type):\n",
    "        \"\"\"Dynamically determine relevant keyword categories based on business type\"\"\"\n",
    "        business_type_lower = business_type.lower()\n",
    "        relevant_categories = set()\n",
    "        \n",
    "        # Map business types to relevant keyword categories\n",
    "        category_mapping = {\n",
    "            'coffee': ['coffee', 'cafe', 'dessert'],\n",
    "            'tea': ['tea', 'cafe', 'dessert'],\n",
    "            'cafe': ['coffee', 'tea', 'cafe', 'dessert', 'healthy'],\n",
    "            'restaurant': ['vegetarian', 'nonveg', 'streetfood', 'fastfood', 'healthy', 'fine_dining', 'casual_dining'],\n",
    "            'bar': ['alcohol', 'fastfood', 'casual_dining'],\n",
    "            'bakery': ['dessert', 'healthy', 'vegetarian'],\n",
    "            'ice cream': ['dessert', 'vegetarian'],\n",
    "            'healthy': ['healthy', 'vegetarian', 'casual_dining'],\n",
    "            'fast food': ['fastfood', 'nonveg', 'casual_dining'],\n",
    "            'fine dining': ['fine_dining', 'nonveg', 'alcohol']\n",
    "        }\n",
    "        \n",
    "        # Find matching categories\n",
    "        for key, categories in category_mapping.items():\n",
    "            if key in business_type_lower:\n",
    "                relevant_categories.update(categories)\n",
    "        \n",
    "        # If no specific match, use a broad set of categories\n",
    "        if not relevant_categories:\n",
    "            relevant_categories = set(self.keywords.keys())\n",
    "        \n",
    "        return list(relevant_categories)\n",
    "    \n",
    "    def calculate_cultural_fit(self, relevance_scores, sentiment_ratio, business_type, location_info, radius_km):\n",
    "        \"\"\"Calculate cultural fit score with global considerations\"\"\"\n",
    "        # Base score starts at neutral\n",
    "        base_score = 0.5\n",
    "        \n",
    "        # Calculate weighted category score\n",
    "        category_weights = self.get_category_weights(business_type)\n",
    "        weighted_sum = 0\n",
    "        total_weight = 0\n",
    "        \n",
    "        for category, score in relevance_scores.items():\n",
    "            weight = category_weights.get(category, 1.0)\n",
    "            weighted_sum += score * weight\n",
    "            total_weight += weight\n",
    "        \n",
    "        # Normalize category score (0-1 scale)\n",
    "        if total_weight > 0:\n",
    "            category_score = (weighted_sum / total_weight) / 10\n",
    "        else:\n",
    "            category_score = 0\n",
    "        \n",
    "        # Apply sentiment adjustment\n",
    "        sentiment_adjustment = (sentiment_ratio - 0.5) * 0.3  # ¬±15% adjustment based on sentiment\n",
    "        adjusted_category_score = min(max(category_score + sentiment_adjustment, 0), 1)\n",
    "        \n",
    "        # Blend base score with category score\n",
    "        final_score = 0.6 * adjusted_category_score + 0.4 * base_score\n",
    "        \n",
    "        # Apply seasonal adjustments based on location\n",
    "        final_score = self.apply_seasonal_adjustments(final_score, business_type, location_info)\n",
    "        \n",
    "        # Apply regional adjustments if available\n",
    "        final_score = self.apply_regional_adjustments(final_score, business_type, location_info)\n",
    "        \n",
    "        # Apply radius-based adjustments\n",
    "        final_score = self.apply_radius_adjustments(final_score, radius_km, business_type)\n",
    "        \n",
    "        return min(max(final_score, 0), 1)  # Ensure score is between 0 and 1\n",
    "    \n",
    "    def apply_radius_adjustments(self, score, radius_km, business_type):\n",
    "        \"\"\"Adjust score based on the analysis radius\"\"\"\n",
    "        # Smaller radius means more localized analysis, which is more precise\n",
    "        # Larger radius means broader analysis, which might dilute the score\n",
    "        \n",
    "        if radius_km <= 5:  # Very localized analysis\n",
    "            return score * 1.05  # Small boost for hyper-local analysis\n",
    "        elif radius_km <= 20:  # Local analysis\n",
    "            return score  # No adjustment\n",
    "        elif radius_km <= 50:  # Regional analysis\n",
    "            return score * 0.95  # Slight reduction for broader analysis\n",
    "        else:  # Very broad analysis\n",
    "            return score * 0.9  # Reduction for very broad analysis\n",
    "    \n",
    "    def get_category_weights(self, business_type):\n",
    "        \"\"\"Get dynamic weights for different categories based on business type\"\"\"\n",
    "        business_type_lower = business_type.lower()\n",
    "        weights = {}\n",
    "        \n",
    "        # Default weights for all categories\n",
    "        for category in self.keywords.keys():\n",
    "            weights[category] = 1.0\n",
    "        \n",
    "        # Adjust weights based on business type\n",
    "        if any(word in business_type_lower for word in ['coffee', 'cafe']):\n",
    "            weights['coffee'] = 3.0\n",
    "            weights['tea'] = 1.5\n",
    "            weights['dessert'] = 2.0\n",
    "            weights['cafe'] = 2.5\n",
    "        \n",
    "        if 'tea' in business_type_lower:\n",
    "            weights['tea'] = 3.0\n",
    "            weights['coffee'] = 1.0\n",
    "            weights['dessert'] = 2.0\n",
    "            weights['cafe'] = 2.5\n",
    "        \n",
    "        if 'restaurant' in business_type_lower:\n",
    "            if 'vegetarian' in business_type_lower or 'vegan' in business_type_lower:\n",
    "                weights['vegetarian'] = 3.0\n",
    "                weights['healthy'] = 2.5\n",
    "            else:\n",
    "                weights['nonveg'] = 2.5\n",
    "                weights['vegetarian'] = 1.5\n",
    "            \n",
    "            if 'fine' in business_type_lower or 'luxury' in business_type_lower:\n",
    "                weights['fine_dining'] = 3.0\n",
    "                weights['alcohol'] = 2.0\n",
    "            else:\n",
    "                weights['casual_dining'] = 2.5\n",
    "        \n",
    "        if 'bar' in business_type_lower or 'pub' in business_type_lower:\n",
    "            weights['alcohol'] = 3.0\n",
    "            weights['casual_dining'] = 2.0\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def apply_seasonal_adjustments(self, score, business_type, location_info):\n",
    "        \"\"\"Apply seasonal adjustments based on location and hemisphere\"\"\"\n",
    "        month = datetime.now().month\n",
    "        lat = location_info.get('latitude', 0)\n",
    "        \n",
    "        if lat is not None:\n",
    "            hemisphere = self.get_hemisphere(lat)\n",
    "            seasons = self.seasonal_patterns[hemisphere]\n",
    "            \n",
    "            business_lower = business_type.lower()\n",
    "            \n",
    "            # Summer adjustments\n",
    "            if month in seasons['summer']:\n",
    "                if any(word in business_lower for word in ['ice cream', 'dessert', 'cold', 'smoothie']):\n",
    "                    score *= 1.3  # Boost for cold items in summer\n",
    "                elif any(word in business_lower for word in ['coffee', 'tea', 'hot', 'soup']):\n",
    "                    score *= 0.9  # Slight decrease for hot items in summer\n",
    "            \n",
    "            # Winter adjustments\n",
    "            elif month in seasons['winter']:\n",
    "                if any(word in business_lower for word in ['coffee', 'tea', 'hot', 'soup']):\n",
    "                    score *= 1.2  # Boost for hot items in winter\n",
    "                elif any(word in business_lower for word in ['ice cream', 'cold', 'smoothie']):\n",
    "                    score *= 0.8  # Decrease for cold items in winter\n",
    "            \n",
    "            # Festival seasons (Q4 generally has more holidays globally)\n",
    "            if month in [10, 11, 12]:\n",
    "                if any(word in business_lower for word in ['restaurant', 'food', 'cafe', 'bar']):\n",
    "                    score *= 1.1  # General boost during holiday season\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def apply_regional_adjustments(self, score, business_type, location_info):\n",
    "        \"\"\"Apply regional/cultural adjustments based on location\"\"\"\n",
    "        country = location_info.get('country', '').lower()\n",
    "        business_lower = business_type.lower()\n",
    "        \n",
    "        # Regional preferences (simplified examples)\n",
    "        regional_preferences = {\n",
    "            'india': {\n",
    "                'tea': 1.2, 'coffee': 0.8, 'vegetarian': 1.3, 'nonveg': 0.9\n",
    "            },\n",
    "            'italy': {\n",
    "                'coffee': 1.4, 'pizza': 1.5, 'pasta': 1.4, 'tea': 0.7\n",
    "            },\n",
    "            'united states': {\n",
    "                'coffee': 1.3, 'fastfood': 1.2, 'healthy': 1.1\n",
    "            },\n",
    "            'united kingdom': {\n",
    "                'tea': 1.4, 'pub': 1.3, 'fish': 1.2\n",
    "            },\n",
    "            'japan': {\n",
    "                'tea': 1.5, 'healthy': 1.3, 'seafood': 1.4, 'coffee': 1.1\n",
    "            },\n",
    "            'france': {\n",
    "                'coffee': 1.3, 'wine': 1.5, 'bakery': 1.4, 'tea': 0.8\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Apply country-specific adjustments\n",
    "        for country_pattern, adjustments in regional_preferences.items():\n",
    "            if country_pattern in country:\n",
    "                for business_pattern, multiplier in adjustments.items():\n",
    "                    if business_pattern in business_lower:\n",
    "                        score *= multiplier\n",
    "                        break  # Apply only the first matching pattern\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def get_cultural_fit_score(self, lat, lng, business_type, radius_km=10):\n",
    "        \"\"\"Main function to get cultural fit score for any global location\"\"\"\n",
    "        print(f\"Analyzing cultural fit for {business_type} at coordinates ({lat}, {lng}) within {radius_km}km radius...\")\n",
    "        \n",
    "        # Step 1: Get detailed location information\n",
    "        location_info = self.get_location_from_coords(lat, lng)\n",
    "        if 'error' in location_info:\n",
    "            return {\"error\": location_info['error']}\n",
    "        \n",
    "        print(f\"Detected location: {location_info['formatted_address']}\")\n",
    "        \n",
    "        # Step 2: Get local content\n",
    "        content_texts = self.get_local_content(location_info, business_type, radius_km)\n",
    "        print(f\"Found {len(content_texts)} relevant content items\")\n",
    "        \n",
    "        # Step 3: Analyze the content for relevant keywords and sentiment\n",
    "        relevance_scores, sentiment_ratio = self.analyze_text_for_keywords(content_texts, business_type)\n",
    "        \n",
    "        # Step 4: Calculate cultural fit score\n",
    "        cultural_fit = self.calculate_cultural_fit(\n",
    "            relevance_scores, sentiment_ratio, business_type, location_info, radius_km\n",
    "        )\n",
    "        \n",
    "        # Step 5: Generate insights\n",
    "        insights = self.generate_insights(\n",
    "            relevance_scores, cultural_fit, business_type, location_info, sentiment_ratio, radius_km\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'cultural_fit_score': round(cultural_fit, 3),\n",
    "            'location': location_info['formatted_address'],\n",
    "            'business_type': business_type,\n",
    "            'analysis_radius_km': radius_km,\n",
    "            'relevance_scores': relevance_scores,\n",
    "            'sentiment_ratio': sentiment_ratio,\n",
    "            'insights': insights,\n",
    "            'content_analyzed': len(content_texts)\n",
    "        }\n",
    "    \n",
    "    def generate_insights(self, relevance_scores, cultural_fit, business_type, location_info, sentiment_ratio, radius_km):\n",
    "        \"\"\"Generate human-readable insights from the analysis\"\"\"\n",
    "        insights = []\n",
    "        \n",
    "        # Main insight based on score\n",
    "        score_percentage = cultural_fit * 100\n",
    "        radius_context = f\"within {radius_km}km radius\" if radius_km > 0 else \"in the local area\"\n",
    "        \n",
    "        if cultural_fit >= 0.7:\n",
    "            insights.append(f\"Excellent cultural fit ({score_percentage:.1f}%) for a {business_type} in {location_info.get('city', 'this location')} {radius_context}\")\n",
    "        elif cultural_fit >= 0.5:\n",
    "            insights.append(f\"Good cultural fit ({score_percentage:.1f}%) for a {business_type} in {location_info.get('city', 'this location')} {radius_context}\")\n",
    "        elif cultural_fit >= 0.3:\n",
    "            insights.append(f\"Moderate cultural fit ({score_percentage:.1f}%) for a {business_type} in {location_info.get('city', 'this location')} {radius_context}\")\n",
    "        else:\n",
    "            insights.append(f\"Poor cultural fit ({score_percentage:.1f}%) for a {business_type} in {location_info.get('city', 'this location')} {radius_context}\")\n",
    "        \n",
    "        # Add insights based on keyword relevance\n",
    "        top_categories = sorted(relevance_scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "        \n",
    "        for category, score in top_categories:\n",
    "            if score > 5:\n",
    "                insights.append(f\"Strong local interest in {category.replace('_', ' ')} (score: {score:.1f}/10) {radius_context}\")\n",
    "            elif score > 2:\n",
    "                insights.append(f\"Moderate local interest in {category.replace('_', ' ')} (score: {score:.1f}/10) {radius_context}\")\n",
    "        \n",
    "        # Sentiment insight\n",
    "        if sentiment_ratio > 0.7:\n",
    "            insights.append(f\"Very positive sentiment detected in local content {radius_context}\")\n",
    "        elif sentiment_ratio > 0.6:\n",
    "            insights.append(f\"Generally positive sentiment detected in local content {radius_context}\")\n",
    "        elif sentiment_ratio < 0.4:\n",
    "            insights.append(f\"Some negative sentiment detected in local content {radius_context}\")\n",
    "        \n",
    "        # Seasonal insight\n",
    "        month = datetime.now().month\n",
    "        hemisphere = self.get_hemisphere(location_info.get('latitude', 0))\n",
    "        seasons = self.seasonal_patterns[hemisphere]\n",
    "        \n",
    "        if month in seasons['summer']:\n",
    "            insights.append(f\"Currently in summer season - consider seasonal offerings {radius_context}\")\n",
    "        elif month in seasons['winter']:\n",
    "            insights.append(f\"Currently in winter season - consider seasonal offerings {radius_context}\")\n",
    "        elif month in seasons['spring']:\n",
    "            insights.append(f\"Currently in spring season - consider seasonal offerings {radius_context}\")\n",
    "        elif month in seasons['fall']:\n",
    "            insights.append(f\"Currently in fall season - consider seasonal offerings {radius_context}\")\n",
    "        \n",
    "        # Regional insight\n",
    "        country = location_info.get('country', '')\n",
    "        if country:\n",
    "            insights.append(f\"Analysis includes regional preferences for {country} {radius_context}\")\n",
    "            \n",
    "        # Radius insight\n",
    "        if radius_km <= 5:\n",
    "            insights.append(\"Analysis focused on a very localized area (hyper-local)\")\n",
    "        elif radius_km <= 20:\n",
    "            insights.append(\"Analysis focused on the immediate local area\")\n",
    "        elif radius_km <= 50:\n",
    "            insights.append(\"Analysis covers a broader regional area\")\n",
    "        else:\n",
    "            insights.append(\"Analysis covers a wide geographic region\")\n",
    "        \n",
    "        return insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Type multiplier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Global baseline multipliers (from industry reports)\n",
    "global_baseline_multipliers = {\n",
    "    \"cafe\": 1.2,\n",
    "    \"restaurant\": 1.0,\n",
    "    \"gym\": 0.8,\n",
    "    \"clothing_store\": 0.9,\n",
    "    \"supermarket\": 1.5,\n",
    "    \"pharmacy\": 1.1,\n",
    "    \"electronics_store\": 1.3,\n",
    "    \"jewelry_store\": 1.4,\n",
    "    \"book_store\": 0.7,\n",
    "    \"bar\": 1.2\n",
    "}\n",
    "\n",
    "def get_population_within_radius(lat, lon, radius):\n",
    "    \"\"\"\n",
    "    Estimate population using free OpenStreetMap data and heuristic density models\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use Overpass API to count residential buildings - FIXED QUERY\n",
    "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        overpass_query = f\"\"\"\n",
    "        [out:json];\n",
    "        (\n",
    "          node[\"building\"~\"residential|apartments|house|detached|terrace\"](around:{radius},{lat},{lon});\n",
    "          way[\"building\"~\"residential|apartments|house|detached|terrace\"](around:{radius},{lat},{lon});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\"\n",
    "        \n",
    "        response = requests.post(overpass_url, data=overpass_query, timeout=10)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Parse the count from Overpass API response - FIXED PARSING\n",
    "        building_count = 0\n",
    "        for element in data.get('elements', []):\n",
    "            if 'tags' in element and element.get('type') == 'count':\n",
    "                # Different ways the count might be represented\n",
    "                if 'nodes' in element:\n",
    "                    building_count += element['nodes']\n",
    "                if 'ways' in element:\n",
    "                    building_count += element['ways']\n",
    "                if 'relations' in element:\n",
    "                    building_count += element['relations']\n",
    "                if 'total' in element:\n",
    "                    building_count = element['total']\n",
    "                    break\n",
    "        \n",
    "        # Estimate population based on building count (heuristic: 4 people per building)\n",
    "        estimated_population = building_count * 4\n",
    "        \n",
    "        return max(estimated_population, 100)  # Minimum population of 100\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting population: {e}\")\n",
    "        return 500  # Default fallback value\n",
    "\n",
    "def get_income_index(lat, lon, radius):\n",
    "    \"\"\"\n",
    "    Estimate income level using OpenStreetMap landuse data as proxy\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get landuse data to estimate area wealth - FIXED QUERY\n",
    "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        overpass_query = f\"\"\"\n",
    "        [out:json];\n",
    "        (\n",
    "          node[\"landuse\"~\"commercial|retail\"](around:{radius},{lat},{lon});\n",
    "          node[\"shop\"](around:{radius},{lat},{lon});\n",
    "          way[\"landuse\"~\"commercial|retail\"](around:{radius},{lat},{lon});\n",
    "          way[\"shop\"](around:{radius},{lat},{lon});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\"\n",
    "        \n",
    "        response = requests.post(overpass_url, data=overpass_query, timeout=10)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Parse the count from Overpass API response - FIXED PARSING\n",
    "        commercial_count = 0\n",
    "        for element in data.get('elements', []):\n",
    "            if 'tags' in element and element.get('type') == 'count':\n",
    "                if 'nodes' in element:\n",
    "                    commercial_count += element['nodes']\n",
    "                if 'ways' in element:\n",
    "                    commercial_count += element['ways']\n",
    "                if 'relations' in element:\n",
    "                    commercial_count += element['relations']\n",
    "                if 'total' in element:\n",
    "                    commercial_count = element['total']\n",
    "                    break\n",
    "        \n",
    "        # More commercial activity = higher income area (proxy)\n",
    "        income_index = 0.5 + (commercial_count * 0.05)  # Base 0.5, +0.05 per commercial entity\n",
    "        return min(max(income_index, 0.5), 1.5)  # Cap between 0.5-1.5\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting income index: {e}\")\n",
    "        return 1.0  # Default average income\n",
    "\n",
    "def get_nearby_places(lat, lon, radius, business_type):\n",
    "    \"\"\"\n",
    "    Get nearby businesses using Overpass API (free)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Map business types to OSM tags - IMPROVED MAPPING\n",
    "        osm_tags = {\n",
    "            \"cafe\": '[\"amenity\"=\"cafe\"]',\n",
    "            \"restaurant\": '[\"amenity\"=\"restaurant\"]',\n",
    "            \"gym\": '[\"leisure\"=\"fitness_centre\"]',\n",
    "            \"clothing_store\": '[\"shop\"=\"clothes\"]',\n",
    "            \"supermarket\": '[\"shop\"=\"supermarket\"]',\n",
    "            \"pharmacy\": '[\"amenity\"=\"pharmacy\"]',\n",
    "            \"electronics_store\": '[\"shop\"=\"electronics\"]',\n",
    "            \"jewelry_store\": '[\"shop\"=\"jewelry\"]',\n",
    "            \"book_store\": '[\"shop\"=\"books\"]',\n",
    "            \"bar\": '[\"amenity\"=\"bar\"]'\n",
    "        }\n",
    "        \n",
    "        tag_query = osm_tags.get(business_type, '[\"shop\"]')\n",
    "        \n",
    "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        # More specific query to avoid getting too many results\n",
    "        overpass_query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          node{tag_query}(around:{radius},{lat},{lon});\n",
    "        );\n",
    "        out body;\n",
    "        \"\"\"\n",
    "        \n",
    "        response = requests.post(overpass_url, data=overpass_query, timeout=15)\n",
    "        data = response.json()\n",
    "        \n",
    "        businesses = []\n",
    "        for element in data.get('elements', []):\n",
    "            if element.get('type') == 'node':\n",
    "                business = {\n",
    "                    'name': element.get('tags', {}).get('name', 'Unknown'),\n",
    "                    'user_ratings_total': 10,  # Default value for free API\n",
    "                    'price_level': 1  # Default value\n",
    "                }\n",
    "                businesses.append(business)\n",
    "            \n",
    "        return businesses\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting nearby places: {e}\")\n",
    "        return []\n",
    "\n",
    "def calculate_confidence(population, competition_count):\n",
    "    \"\"\"\n",
    "    Calculate confidence score based on data quality\n",
    "    \"\"\"\n",
    "    # Base confidence on population data reliability\n",
    "    pop_confidence = min(population / 1000, 1.0)  # More population = more reliable\n",
    "    \n",
    "    # Adjust for competition data (more competition data = more reliable)\n",
    "    comp_confidence = min(competition_count / 10, 1.0)  # Changed from 5 to 10\n",
    "    \n",
    "    # Overall confidence (weighted average)\n",
    "    confidence = (pop_confidence * 0.6) + (comp_confidence * 0.4)\n",
    "    \n",
    "    return max(0.5, min(confidence, 0.9))  # Keep between 0.5-0.9 for MVP\n",
    "\n",
    "def get_business_type_multiplier(business_type, lat, lon, radius_km):\n",
    "    \"\"\"\n",
    "    Fetches a location-aware business type multiplier using free APIs.\n",
    "    Accuracy target: ~50-60% for MVP\n",
    "    \"\"\"\n",
    "    try:\n",
    "        radius = radius_km * 1000  # Convert km to meters\n",
    "        # 1. Get the global baseline for the business type\n",
    "        baseline = global_baseline_multipliers.get(business_type, 1.0)\n",
    "\n",
    "        # 2. Calculate Local Demand Score (with free data sources)\n",
    "        total_population = get_population_within_radius(lat, lon, radius)\n",
    "        avg_income_index = get_income_index(lat, lon, radius)\n",
    "        local_demand_score = total_population * avg_income_index\n",
    "\n",
    "        # 3. Calculate Local Supply Score (Competition)\n",
    "        competing_businesses = get_nearby_places(lat, lon, radius, business_type)\n",
    "        \n",
    "        # Calculate the \"strength\" of each competitor\n",
    "        total_competition_strength = 0\n",
    "        for business in competing_businesses:\n",
    "            # For free API, we use default values as we can't get real review counts\n",
    "            strength = business.get('user_ratings_total', 10) * business.get('price_level', 1)\n",
    "            total_competition_strength += strength\n",
    "\n",
    "        local_supply_score = total_competition_strength\n",
    "\n",
    "        # 4. Calculate local adjustment\n",
    "        if local_supply_score == 0:\n",
    "            local_adjustment = 1.8  # Bonus for no competition (capped)\n",
    "        else:\n",
    "            # Normalize the ratio to avoid extreme values\n",
    "            raw_ratio = local_demand_score / local_supply_score\n",
    "            # Apply sigmoid-like function to keep between 0.5-2.0\n",
    "            local_adjustment = 0.5 + 1.5 / (1 + math.exp(-0.0001 * (raw_ratio - 500)))\n",
    "            \n",
    "        local_adjustment = max(0.5, min(2.0, local_adjustment))\n",
    "\n",
    "        # 5. Calculate Final Multiplier\n",
    "        final_multiplier = baseline * local_adjustment\n",
    "\n",
    "        # 6. Calculate Confidence\n",
    "        confidence = calculate_confidence(total_population, len(competing_businesses))\n",
    "\n",
    "        # 7. Generate notes\n",
    "        comp_count = len(competing_businesses)\n",
    "        if comp_count == 0:\n",
    "            notes = \"No direct competitors found. High opportunity but verify local demand.\"\n",
    "        elif comp_count < 3:\n",
    "            notes = f\"Low competition ({comp_count} competitors). Good market conditions.\"\n",
    "        elif comp_count < 8:\n",
    "            notes = f\"Moderate competition ({comp_count} competitors). Viable market.\"\n",
    "        else:\n",
    "            notes = f\"High competition ({comp_count} competitors). Consider differentiation.\"\n",
    "\n",
    "        return {\n",
    "            \"multiplier\": round(final_multiplier, 2),\n",
    "            \"confidence\": round(confidence, 2),\n",
    "            \"global_baseline\": baseline,\n",
    "            \"local_adjustment\": round(local_adjustment, 2),\n",
    "            \"population_estimate\": total_population,\n",
    "            \"competition_count\": comp_count,\n",
    "            \"notes\": notes\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating multiplier: {e}\")\n",
    "        # Return a default value with low confidence\n",
    "        return {\n",
    "            \"multiplier\": global_baseline_multipliers.get(business_type, 1.0),\n",
    "            \"confidence\": 0.5,\n",
    "            \"global_baseline\": global_baseline_multipliers.get(business_type, 1.0),\n",
    "            \"local_adjustment\": 1.0,\n",
    "            \"population_estimate\": 0,\n",
    "            \"competition_count\": 0,\n",
    "            \"notes\": \"Error in calculation. Using baseline value.\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population (within radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from geopy.geocoders import Nominatim\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import geocoder\n",
    "\n",
    "# Global baseline multipliers (from industry reports)\n",
    "global_baseline_multipliers = {\n",
    "    \"cafe\": 1.2,\n",
    "    \"restaurant\": 1.0,\n",
    "    \"gym\": 0.8,\n",
    "    \"clothing_store\": 0.9,\n",
    "    \"supermarket\": 1.5,\n",
    "    \"pharmacy\": 1.1,\n",
    "    \"electronics_store\": 1.3,\n",
    "    \"jewelry_store\": 1.4,\n",
    "    \"book_store\": 0.7,\n",
    "    \"bar\": 1.2\n",
    "}\n",
    "\n",
    "# --- Step 1: Get current location coordinates ---\n",
    "def get_current_location():\n",
    "    \"\"\"Get current latitude and longitude using IP address\"\"\"\n",
    "    try:\n",
    "        # Get location based on IP address\n",
    "        g = geocoder.ip('me')\n",
    "        if g.ok:\n",
    "            return (g.lat, g.lng)\n",
    "        else:\n",
    "            # Fallback to manual input if IP geolocation fails\n",
    "            address = input(\"Please enter your current location (e.g., 'New York, USA'): \")\n",
    "            return get_coordinates(address)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting current location: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_coordinates(place_name):\n",
    "    \"\"\"Get latitude and longitude for any location worldwide\"\"\"\n",
    "    geolocator = Nominatim(user_agent=\"business_analysis_app\")\n",
    "    try:\n",
    "        location = geolocator.geocode(place_name)\n",
    "        if location:\n",
    "            return (location.latitude, location.longitude)\n",
    "        else:\n",
    "            print(f\"Location '{place_name}' not found.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Geocoding error: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Step 2: Create circle polygon (GeoJSON) ---\n",
    "def create_circle_geojson(lat, lon, radius_km, num_points=36):\n",
    "    \"\"\"Create a circular polygon for API queries\"\"\"\n",
    "    coords = []\n",
    "    for i in range(num_points):\n",
    "        angle = 2 * math.pi * i / num_points\n",
    "        dx = radius_km / 111.32 * math.cos(angle)   # ~111.32 km per degree latitude\n",
    "        dy = radius_km / (111.32 * math.cos(math.radians(lat))) * math.sin(angle)\n",
    "        coords.append([lon + dy, lat + dx])\n",
    "    coords.append(coords[0])  # close polygon\n",
    "\n",
    "    geojson = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {},\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Polygon\",\n",
    "                    \"coordinates\": [coords]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    return geojson\n",
    "\n",
    "# --- Step 3: Query WorldPop API with GeoJSON ---\n",
    "def fetch_population_worldpop(lat, lon, radius_km=5, year=2020):\n",
    "    \"\"\"Get population data from WorldPop API\"\"\"\n",
    "    try:\n",
    "        geojson = create_circle_geojson(lat, lon, radius_km)\n",
    "\n",
    "        url = \"https://api.worldpop.org/v1/services/stats\"\n",
    "        params = {\n",
    "            \"dataset\": \"wpgppop\",   # WorldPop global population dataset\n",
    "            \"year\": str(year),\n",
    "            \"geojson\": json.dumps(geojson)  # must be stringified\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"data\" in data and \"total_population\" in data[\"data\"]:\n",
    "                return data[\"data\"][\"total_population\"]\n",
    "        \n",
    "        return None  # API didn't return valid data\n",
    "    except Exception as e:\n",
    "        print(f\"WorldPop API error: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Step 4: Alternative population estimation using OpenStreetMap ---\n",
    "def estimate_population_osm(lat, lon, radius_km):\n",
    "    \"\"\"Fallback population estimation using OpenStreetMap data\"\"\"\n",
    "    try:\n",
    "        radius_meters = radius_km * 1000\n",
    "        \n",
    "        # Query for residential buildings\n",
    "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        overpass_query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          node[\"building\"~\"residential|apartments|house|detached\"](around:{radius_meters},{lat},{lon});\n",
    "          way[\"building\"~\"residential|apartments|house|detached\"](around:{radius_meters},{lat},{lon});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\"\n",
    "        \n",
    "        response = requests.post(overpass_url, data=overpass_query, timeout=15)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Count buildings\n",
    "        building_count = 0\n",
    "        for element in data.get('elements', []):\n",
    "            if element.get('type') == 'count':\n",
    "                building_count = element.get('total', 0)\n",
    "                break\n",
    "        \n",
    "        # Estimate population (4 people per building on average)\n",
    "        estimated_population = building_count * 4\n",
    "        \n",
    "        # Adjust for urban vs rural (more dense in cities)\n",
    "        urban_density_factor = 1.5  # Adjust based on location type if possible\n",
    "        return int(estimated_population * urban_density_factor)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"OSM estimation error: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Step 5: Get population with fallbacks ---\n",
    "def get_population_within_radius(lat, lon, radius_km=5):\n",
    "    \"\"\"Get population with multiple fallback methods\"\"\"\n",
    "    # Try WorldPop first\n",
    "    population = fetch_population_worldpop(lat, lon, radius_km)\n",
    "    \n",
    "    # If WorldPop fails, try OSM estimation\n",
    "    if population is None or population == 0:\n",
    "\n",
    "        population = estimate_population_osm(lat, lon, radius_km)\n",
    "    \n",
    "    # If both methods fail, use a reasonable default based on area\n",
    "    if population is None or population == 0:\n",
    "\n",
    "        # Estimate based on area (people per sq km)\n",
    "        area_sq_km = math.pi * (radius_km ** 2)\n",
    "        \n",
    "        # Default population densities (people per sq km)\n",
    "        # Urban: 2000, Suburban: 1000, Rural: 200\n",
    "        population = int(area_sq_km * 1000)  # Default to suburban density\n",
    "    \n",
    "    return max(population, 100)  # Ensure minimum population\n",
    "\n",
    "# --- Step 6: Income estimation ---\n",
    "def get_income_index(lat, lon, radius_km):\n",
    "    \"\"\"Estimate income level using commercial activity as proxy\"\"\"\n",
    "    try:\n",
    "        radius_meters = radius_km * 1000\n",
    "        \n",
    "        # Query for commercial activities\n",
    "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        overpass_query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          node[\"shop\"](around:{radius_meters},{lat},{lon});\n",
    "          node[\"amenity\"~\"restaurant|cafe|bank\"](around:{radius_meters},{lat},{lon});\n",
    "          way[\"shop\"](around:{radius_meters},{lat},{lon});\n",
    "          way[\"amenity\"~\"restaurant|cafe|bank\"](around:{radius_meters},{lat},{lon});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\"\n",
    "        \n",
    "        response = requests.post(overpass_url, data=overpass_query, timeout=15)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Count commercial entities\n",
    "        commercial_count = 0\n",
    "        for element in data.get('elements', []):\n",
    "            if element.get('type') == 'count':\n",
    "                commercial_count = element.get('total', 0)\n",
    "                break\n",
    "        \n",
    "        # More commercial activity = higher income area (proxy)\n",
    "        income_index = 0.5 + (commercial_count * 0.01)  # Base 0.5, +0.01 per commercial entity\n",
    "        return min(max(income_index, 0.5), 1.5)  # Cap between 0.5-1.5\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Income estimation error: {e}\")\n",
    "        return 1.0  # Default average income\n",
    "\n",
    "# --- Step 7: Get nearby businesses ---\n",
    "def get_nearby_places(lat, lon, radius_km, business_type):\n",
    "    \"\"\"Get nearby businesses using Overpass API\"\"\"\n",
    "    try:\n",
    "        radius_meters = radius_km * 1000\n",
    "        \n",
    "        # Map business types to OSM tags\n",
    "        osm_tags = {\n",
    "            \"cafe\": '[\"amenity\"=\"cafe\"]',\n",
    "            \"restaurant\": '[\"amenity\"=\"restaurant\"]',\n",
    "            \"gym\": '[\"leisure\"=\"fitness_centre\"]',\n",
    "            \"clothing_store\": '[\"shop\"=\"clothes\"]',\n",
    "            \"supermarket\": '[\"shop\"=\"supermarket\"]',\n",
    "            \"pharmacy\": '[\"amenity\"=\"pharmacy\"]',\n",
    "            \"electronics_store\": '[\"shop\"=\"electronics\"]',\n",
    "            \"jewelry_store\": '[\"shop\"=\"jewelry\"]',\n",
    "            \"book_store\": '[\"shop\"=\"books\"]',\n",
    "            \"bar\": '[\"amenity\"=\"bar\"]'\n",
    "        }\n",
    "        \n",
    "        tag_query = osm_tags.get(business_type, '[\"shop\"]')\n",
    "        \n",
    "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        overpass_query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          node{tag_query}(around:{radius_meters},{lat},{lon});\n",
    "        );\n",
    "        out;\n",
    "        \"\"\"\n",
    "        \n",
    "        response = requests.post(overpass_url, data=overpass_query, timeout=15)\n",
    "        data = response.json()\n",
    "        \n",
    "        businesses = []\n",
    "        for element in data.get('elements', []):\n",
    "            if element.get('type') == 'node':\n",
    "                business = {\n",
    "                    'name': element.get('tags', {}).get('name', 'Unknown'),\n",
    "                    'user_ratings_total': 10,  # Default value\n",
    "                    'price_level': 1  # Default value\n",
    "                }\n",
    "                businesses.append(business)\n",
    "            \n",
    "        return businesses\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting nearby places: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Step 8: Calculate confidence score ---\n",
    "def calculate_confidence(population, competition_count):\n",
    "    \"\"\"Calculate confidence score based on data quality\"\"\"\n",
    "    # Base confidence on population data reliability\n",
    "    pop_confidence = min(population / 5000, 1.0)  # More population = more reliable\n",
    "    \n",
    "    # Adjust for competition data (more competition data = more reliable)\n",
    "    comp_confidence = min(competition_count / 10, 1.0)\n",
    "    \n",
    "    # Overall confidence (weighted average)\n",
    "    confidence = (pop_confidence * 0.6) + (comp_confidence * 0.4)\n",
    "    \n",
    "    return max(0.5, min(confidence, 0.9))  # Keep between 0.5-0.9\n",
    "\n",
    "# --- Step 9: Main business analysis function ---\n",
    "def analyze_business_location(business_type, lat, lon, radius_km=2):\n",
    "    print(lat, lon)\n",
    "    \"\"\"\n",
    "    Analyze a business location using coordinates\n",
    "    Returns: multiplier, confidence, and detailed analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Get the global baseline for the business type\n",
    "        baseline = global_baseline_multipliers.get(business_type, 1.0)\n",
    "\n",
    "        # 2. Calculate Local Demand Score\n",
    "        total_population = get_population_within_radius(lat, lon, radius_km)\n",
    "        avg_income_index = get_income_index(lat, lon, radius_km)\n",
    "        local_demand_score = total_population * avg_income_index\n",
    "\n",
    "        # 3. Calculate Local Supply Score (Competition)\n",
    "        competing_businesses = get_nearby_places(lat, lon, radius_km, business_type)\n",
    "        competition_count = len(competing_businesses)\n",
    "        \n",
    "        # Calculate the \"strength\" of each competitor\n",
    "        total_competition_strength = 0\n",
    "        for business in competing_businesses:\n",
    "            strength = business.get('user_ratings_total', 10) * business.get('price_level', 1)\n",
    "            total_competition_strength += strength\n",
    "\n",
    "        local_supply_score = total_competition_strength\n",
    "\n",
    "        # 4. Calculate local adjustment\n",
    "        if local_supply_score == 0:\n",
    "            local_adjustment = 1.8  # Bonus for no competition (capped)\n",
    "        else:\n",
    "            # Normalize the ratio to avoid extreme values\n",
    "            raw_ratio = local_demand_score / local_supply_score\n",
    "            # Apply sigmoid-like function to keep between 0.5-2.0\n",
    "            local_adjustment = 0.5 + 1.5 / (1 + math.exp(-0.000001 * (raw_ratio - 500000)))\n",
    "            \n",
    "        local_adjustment = max(0.5, min(2.0, local_adjustment))\n",
    "\n",
    "        # 5. Calculate Final Multiplier\n",
    "        final_multiplier = baseline * local_adjustment\n",
    "\n",
    "        # 6. Calculate Confidence\n",
    "        confidence = calculate_confidence(total_population, competition_count)\n",
    "\n",
    "        # 7. Generate notes\n",
    "        if competition_count == 0:\n",
    "            notes = \"No direct competitors found. High opportunity but verify local demand.\"\n",
    "        elif competition_count < 3:\n",
    "            notes = f\"Low competition ({competition_count} competitors). Good market conditions.\"\n",
    "        elif competition_count < 8:\n",
    "            notes = f\"Moderate competition ({competition_count} competitors). Viable market.\"\n",
    "        else:\n",
    "            notes = f\"High competition ({competition_count} competitors). Consider differentiation.\"\n",
    "\n",
    "        return {\n",
    "            \"multiplier\": round(final_multiplier, 2),\n",
    "            \"confidence\": round(confidence, 2),\n",
    "            \"population\": total_population,\n",
    "            \"competition_count\": competition_count,\n",
    "            \"income_index\": round(avg_income_index, 2),\n",
    "            \"notes\": notes,\n",
    "            \"coordinates\": (lat, lon),\n",
    "            \"radius_km\": radius_km\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in business analysis: {e}\")\n",
    "        # Return a default value with low confidence\n",
    "        return {\n",
    "            \"multiplier\": global_baseline_multipliers.get(business_type, 1.0),\n",
    "            \"confidence\": 0.5,\n",
    "            \"population\": 0,\n",
    "            \"competition_count\": 0,\n",
    "            \"income_index\": 1.0,\n",
    "            \"notes\": \"Error in analysis. Using baseline value.\",\n",
    "            \"radius_km\": radius_km\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import math\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def get_market_factors(lat, lon, business_type, radius_km=5):\n",
    "    \"\"\"\n",
    "    Calculate market factors that reduce business revenue potential\n",
    "    Returns a multiplier between 0.1-1.0 where lower values indicate more friction\n",
    "    Accuracy target: >60%\n",
    "    \"\"\"\n",
    "    try:\n",
    "        factors = {}\n",
    "        weights = {}\n",
    "        \n",
    "        # 1. Rent Index (40% weight)\n",
    "        rent_factor = get_rent_index(lat, lon, radius_km, business_type)\n",
    "        factors['rent_index'] = rent_factor\n",
    "        weights['rent_index'] = 0.4\n",
    "        \n",
    "        # 2. Regulatory Environment (30% weight)\n",
    "        regulatory_factor = get_regulatory_index(lat, lon)\n",
    "        factors['regulatory_index'] = regulatory_factor\n",
    "        weights['regulatory_index'] = 0.3\n",
    "        \n",
    "        # 3. Seasonality (20% weight)\n",
    "        seasonality_factor = get_seasonality_index(lat, lon, business_type)\n",
    "        factors['seasonality_index'] = seasonality_factor\n",
    "        weights['seasonality_index'] = 0.2\n",
    "        \n",
    "        # 4. Local Competition Density (10% weight)\n",
    "        competition_factor = get_competition_density(lat, lon, business_type, radius_km)\n",
    "        factors['competition_density'] = competition_factor\n",
    "        weights['competition_density'] = 0.1\n",
    "        \n",
    "        # Calculate weighted average\n",
    "        total_weight = sum(weights.values())\n",
    "        weighted_sum = sum(factors[factor] * weights[factor] for factor in factors)\n",
    "        market_factor = weighted_sum / total_weight\n",
    "        \n",
    "        # Apply business-type specific adjustments\n",
    "        market_factor = apply_business_specific_adjustments(market_factor, business_type)\n",
    "        \n",
    "        return {\n",
    "            \"market_factor\": round(market_factor, 3),\n",
    "            \"components\": factors,\n",
    "            \"weights\": weights,\n",
    "            \"confidence\": estimate_confidence(factors),\n",
    "            \"notes\": generate_market_notes(factors, market_factor)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating market factors: {e}\")\n",
    "        return {\n",
    "            \"market_factor\": 0.7,  # Default neutral value\n",
    "            \"components\": {\"error\": \"Calculation failed\"},\n",
    "            \"weights\": {},\n",
    "            \"confidence\": 0.5,\n",
    "            \"notes\": \"Using default market factor due to calculation error\"\n",
    "        }\n",
    "\n",
    "def get_rent_index(lat, lon, radius_km, business_type):\n",
    "    \"\"\"Estimate rent costs as a friction factor (0.1-1.0)\"\"\"\n",
    "    try:\n",
    "        # Get location data for country/region identification\n",
    "        geolocator = Nominatim(user_agent=\"market_factors_app\")\n",
    "        location = geolocator.reverse(f\"{lat}, {lon}\")\n",
    "        address = location.raw.get('address', {})\n",
    "        country = address.get('country', '')\n",
    "        \n",
    "        # Try to get actual rental data first\n",
    "        rental_data = estimate_rent_from_osm(lat, lon, radius_km, business_type)\n",
    "        if rental_data:\n",
    "            # Normalize rent to 0.1-1.0 scale (higher rent = lower factor)\n",
    "            normalized_rent = min(max(rental_data / 5000, 0.1), 1.0)  # Assuming $5000/month is very high\n",
    "            return round(1.0 - normalized_rent, 3)\n",
    "        \n",
    "        # Fallback: Use country-based averages\n",
    "        country_rent_index = get_country_rent_index(country)\n",
    "        return max(0.3, min(1.0, country_rent_index))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Rent estimation error: {e}\")\n",
    "        return 0.7  # Default value\n",
    "\n",
    "def estimate_rent_from_osm(lat, lon, radius_km, business_type):\n",
    "    \"\"\"Estimate rent prices from OpenStreetMap data\"\"\"\n",
    "    try:\n",
    "        radius_meters = radius_km * 1000\n",
    "        \n",
    "        # Query for commercial properties\n",
    "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        \n",
    "        # Different queries based on business type\n",
    "        if business_type in [\"restaurant\", \"cafe\", \"bar\"]:\n",
    "            query = f\"\"\"\n",
    "            [out:json][timeout:25];\n",
    "            (\n",
    "              node[\"amenity\"~\"restaurant|cafe|bar\"](around:{radius_meters},{lat},{lon});\n",
    "              way[\"amenity\"~\"restaurant|cafe|bar\"](around:{radius_meters},{lat},{lon});\n",
    "            );\n",
    "            out;\n",
    "            \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\"\n",
    "            [out:json][timeout:25];\n",
    "            (\n",
    "              node[\"shop\"](around:{radius_meters},{lat},{lon});\n",
    "              way[\"shop\"](around:{radius_meters},{lat},{lon});\n",
    "            );\n",
    "            out;\n",
    "            \"\"\"\n",
    "        \n",
    "        response = requests.post(overpass_url, data=query, timeout=15)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Count commercial properties as proxy for rent prices\n",
    "        property_count = len(data.get('elements', []))\n",
    "        \n",
    "        # Estimate rent based on density (more properties = higher rent)\n",
    "        base_rent = 500  # Base rent in USD\n",
    "        density_factor = min(property_count / 10, 5)  # Cap at 5x base\n",
    "        estimated_rent = base_rent * (1 + density_factor)\n",
    "        \n",
    "        return estimated_rent\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"OSM rent estimation error: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_country_rent_index(country):\n",
    "    \"\"\"Get rent index by country (simplified for MVP)\"\"\"\n",
    "    # Simplified rent index by country (0.1 = expensive, 1.0 = cheap)\n",
    "    rent_indices = {\n",
    "        # High cost countries\n",
    "        \"Switzerland\": 0.3, \"Norway\": 0.4, \"Iceland\": 0.4, \n",
    "        \"United States\": 0.5, \"United Kingdom\": 0.5, \"Australia\": 0.5,\n",
    "        \"Germany\": 0.6, \"France\": 0.6, \"Canada\": 0.6, \"Japan\": 0.6,\n",
    "        # Medium cost countries\n",
    "        \"Italy\": 0.7, \"Spain\": 0.7, \"South Korea\": 0.7, \"Portugal\": 0.7,\n",
    "        \"Greece\": 0.8, \"Poland\": 0.8, \"Czech Republic\": 0.8,\n",
    "        # Lower cost countries\n",
    "        \"Mexico\": 0.9, \"Turkey\": 0.9, \"India\": 1.0, \"Vietnam\": 1.0,\n",
    "        \"Thailand\": 1.0, \"Indonesia\": 1.0\n",
    "    }\n",
    "    \n",
    "    # Default to medium cost if country not found\n",
    "    return rent_indices.get(country, 0.7)\n",
    "\n",
    "def get_regulatory_index(lat, lon):\n",
    "    \"\"\"Estimate regulatory burden (0.1-1.0)\"\"\"\n",
    "    try:\n",
    "        # Get country from coordinates\n",
    "        geolocator = Nominatim(user_agent=\"market_factors_app\")\n",
    "        location = geolocator.reverse(f\"{lat}, {lon}\")\n",
    "        address = location.raw.get('address', {})\n",
    "        country = address.get('country', '')\n",
    "        country_code = address.get('country_code', '').upper()\n",
    "        \n",
    "        # Use World Bank Doing Business data (simplified for MVP)\n",
    "        regulatory_scores = {\n",
    "            # Top 10 ease of doing business (2020 data)\n",
    "            \"NZ\": 0.9, \"SG\": 0.9, \"HK\": 0.85, \"DK\": 0.85, \"KR\": 0.85,\n",
    "            \"US\": 0.8, \"GB\": 0.8, \"GE\": 0.8, \"NO\": 0.8, \"SE\": 0.8,\n",
    "            # Medium scores\n",
    "            \"AU\": 0.7, \"CA\": 0.7, \"DE\": 0.7, \"FR\": 0.7, \"JP\": 0.7,\n",
    "            \"ES\": 0.6, \"IT\": 0.6, \"CZ\": 0.6, \"PT\": 0.6,\n",
    "            # Lower scores\n",
    "            \"CN\": 0.5, \"IN\": 0.5, \"BR\": 0.4, \"RU\": 0.4, \"AR\": 0.4,\n",
    "            # Default for other countries\n",
    "            \"default\": 0.5\n",
    "        }\n",
    "        \n",
    "        return regulatory_scores.get(country_code, regulatory_scores[\"default\"])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Regulatory index error: {e}\")\n",
    "        return 0.6  # Default value\n",
    "\n",
    "def get_seasonality_index(lat, lon, business_type):\n",
    "    \"\"\"Calculate seasonality impact (0.1-1.0)\"\"\"\n",
    "    try:\n",
    "        # Get country and approximate climate zone\n",
    "        geolocator = Nominatim(user_agent=\"market_factors_app\")\n",
    "        location = geolocator.reverse(f\"{lat}, {lon}\")\n",
    "        address = location.raw.get('address', {})\n",
    "        country = address.get('country', '')\n",
    "        \n",
    "        # Get current month for seasonality\n",
    "        current_month = datetime.now().month\n",
    "        \n",
    "        # Business-type specific seasonality patterns\n",
    "        seasonality_patterns = {\n",
    "            \"ice_cream\": [0.3, 0.6, 0.9, 0.8, 0.7, 0.5, 0.4, 0.5, 0.6, 0.5, 0.4, 0.3],\n",
    "            \"ski_resort\": [0.9, 0.8, 0.7, 0.3, 0.1, 0.1, 0.1, 0.1, 0.2, 0.5, 0.8, 0.9],\n",
    "            \"beach_resort\": [0.3, 0.4, 0.6, 0.8, 0.9, 0.9, 0.9, 0.9, 0.7, 0.5, 0.4, 0.3],\n",
    "            \"restaurant\": [0.8, 0.7, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9, 0.8, 0.8, 0.8, 0.9],\n",
    "            \"retail\": [0.9, 0.7, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 1.0],\n",
    "            \"default\": [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]\n",
    "        }\n",
    "        \n",
    "        # Map business types to seasonality patterns\n",
    "        pattern_mapping = {\n",
    "            \"cafe\": \"restaurant\",\n",
    "            \"restaurant\": \"restaurant\",\n",
    "            \"bar\": \"restaurant\",\n",
    "            \"clothing_store\": \"retail\",\n",
    "            \"electronics_store\": \"retail\",\n",
    "            \"jewelry_store\": \"retail\",\n",
    "            \"book_store\": \"retail\",\n",
    "            \"supermarket\": \"retail\",\n",
    "            \"pharmacy\": \"retail\",\n",
    "            \"gym\": \"default\"\n",
    "        }\n",
    "        \n",
    "        pattern_key = pattern_mapping.get(business_type, \"default\")\n",
    "        monthly_factors = seasonality_patterns[pattern_key]\n",
    "        \n",
    "        return monthly_factors[current_month - 1]  # -1 because list is 0-indexed\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Seasonality index error: {e}\")\n",
    "        return 0.8  # Default value\n",
    "\n",
    "def get_competition_density(lat, lon, business_type, radius_km):\n",
    "    \"\"\"Calculate competition density impact (0.1-1.0)\"\"\"\n",
    "    try:\n",
    "        radius_meters = radius_km * 1000\n",
    "        \n",
    "        # Map business types to OSM tags\n",
    "        osm_tags = {\n",
    "            \"cafe\": '[\"amenity\"=\"cafe\"]',\n",
    "            \"restaurant\": '[\"amenity\"=\"restaurant\"]',\n",
    "            \"gym\": '[\"leisure\"=\"fitness_centre\"]',\n",
    "            \"clothing_store\": '[\"shop\"=\"clothes\"]',\n",
    "            \"supermarket\": '[\"shop\"=\"supermarket\"]',\n",
    "            \"pharmacy\": '[\"amenity\"=\"pharmacy\"]',\n",
    "            \"electronics_store\": '[\"shop\"=\"electronics\"]',\n",
    "            \"jewelry_store\": '[\"shop\"=\"jewelry\"]',\n",
    "            \"book_store\": '[\"shop\"=\"books\"]',\n",
    "            \"bar\": '[\"amenity\"=\"bar\"]'\n",
    "        }\n",
    "        \n",
    "        tag_query = osm_tags.get(business_type, '[\"shop\"]')\n",
    "        \n",
    "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "        overpass_query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          node{tag_query}(around:{radius_meters},{lat},{lon});\n",
    "        );\n",
    "        out count;\n",
    "        \"\"\"\n",
    "        \n",
    "        response = requests.post(overpass_url, data=overpass_query, timeout=15)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Get competitor count\n",
    "        competitor_count = 0\n",
    "        for element in data.get('elements', []):\n",
    "            if element.get('type') == 'count':\n",
    "                competitor_count = element.get('total', 0)\n",
    "                break\n",
    "        \n",
    "        # Convert to factor (more competition = lower factor)\n",
    "        # Normalize: 0 competitors = 1.0, 10+ competitors = 0.1\n",
    "        competition_factor = max(0.1, 1.0 - (competitor_count * 0.09))\n",
    "        return round(competition_factor, 3)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Competition density error: {e}\")\n",
    "        return 0.7  # Default value\n",
    "\n",
    "def apply_business_specific_adjustments(market_factor, business_type):\n",
    "    \"\"\"Apply business-type specific adjustments to market factor\"\"\"\n",
    "    adjustments = {\n",
    "        \"restaurant\": 0.95,  # Slightly more sensitive to market factors\n",
    "        \"cafe\": 0.9,\n",
    "        \"bar\": 0.85,\n",
    "        \"gym\": 1.05,        # Less sensitive to market factors\n",
    "        \"pharmacy\": 1.1,\n",
    "        \"supermarket\": 1.05,\n",
    "        \"default\": 1.0\n",
    "    }\n",
    "    \n",
    "    adjustment = adjustments.get(business_type, adjustments[\"default\"])\n",
    "    return max(0.1, min(1.0, market_factor * adjustment))\n",
    "\n",
    "def estimate_confidence(factors):\n",
    "    \"\"\"Estimate confidence in market factors calculation\"\"\"\n",
    "    # Count how many factors were successfully calculated\n",
    "    successful_factors = sum(1 for factor in factors.values() if factor != 0.7)  # 0.7 is our default fallback\n",
    "    \n",
    "    # Base confidence on percentage of successful calculations\n",
    "    confidence = successful_factors / len(factors)\n",
    "    \n",
    "    # Adjust for data quality (simplified)\n",
    "    return max(0.5, min(0.9, confidence))\n",
    "\n",
    "def generate_market_notes(factors, market_factor):\n",
    "    \"\"\"Generate explanatory notes about market factors\"\"\"\n",
    "    notes = []\n",
    "    \n",
    "    if factors.get('rent_index', 0.7) < 0.5:\n",
    "        notes.append(\"High rental costs may impact profitability.\")\n",
    "    elif factors.get('rent_index', 0.7) > 0.8:\n",
    "        notes.append(\"Favorable rental costs in this area.\")\n",
    "    \n",
    "    if factors.get('regulatory_index', 0.6) < 0.5:\n",
    "        notes.append(\"Regulatory environment may present challenges.\")\n",
    "    elif factors.get('regulatory_index', 0.6) > 0.7:\n",
    "        notes.append(\"Business-friendly regulatory environment.\")\n",
    "    \n",
    "    if factors.get('seasonality_index', 0.8) < 0.6:\n",
    "        notes.append(\"Significant seasonal variations expected.\")\n",
    "    elif factors.get('seasonality_index', 0.8) > 0.9:\n",
    "        notes.append(\"Favorable year-round business conditions.\")\n",
    "    \n",
    "    if factors.get('competition_density', 0.7) < 0.5:\n",
    "        notes.append(\"High competition density may affect market share.\")\n",
    "    elif factors.get('competition_density', 0.7) > 0.8:\n",
    "        notes.append(\"Limited competition in the immediate area.\")\n",
    "    \n",
    "    if market_factor < 0.5:\n",
    "        notes.append(\"Overall market conditions present significant challenges.\")\n",
    "    elif market_factor > 0.8:\n",
    "        notes.append(\"Favorable market conditions for business operations.\")\n",
    "    else:\n",
    "        notes.append(\"Moderate market conditions with balanced opportunities and challenges.\")\n",
    "    \n",
    "    return \" \".join(notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overpass API error: 504 Server Error: Gateway Timeout for url: https://overpass-api.de/api/interpreter\n",
      "Competition density error: Expecting value: line 1 column 1 (char 0)\n",
      "40.7128 -74.006\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    lat = 40.7128\n",
    "    lon = -74.0060\n",
    "    business_type = \"supermarket\"  \n",
    "    radius_km = 2  \n",
    "\n",
    "    # traffic score start\n",
    "    calculator = TrafficScoreCalculator()\n",
    "    traffc_score_result = calculator.calculate_traffic_score(lat, lon, radius_km)\n",
    "\n",
    "    sorted_categories = sorted(traffc_score_result['poi_breakdown'].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    top_categories = []\n",
    "    for i, (category, count) in enumerate(sorted_categories[:3]):\n",
    "        if count > 0:\n",
    "            top_categories.append({\n",
    "                \"rank\": i + 1,\n",
    "                \"category\": category,\n",
    "                \"count\": count\n",
    "            })\n",
    "    # traffic score end\n",
    "\n",
    "    # market factor start here\n",
    "        market_factore_result = get_market_factors(lat, lon, business_type)\n",
    "    # market factor end here\n",
    "\n",
    "    # population start here\n",
    "        population_result = analyze_business_location(business_type, lat, lon, radius_km)\n",
    "        # if result['multiplier'] > 1.2:\n",
    "        #     print(\"‚úÖ EXCELLENT POTENTIAL: This location shows strong potential for success!\")\n",
    "        # Interpretation\n",
    "        # elif result['multiplier'] > 0.9:\n",
    "        #     print(\"üëç GOOD POTENTIAL: This location has decent potential for success.\")\n",
    "        # elif result['multiplier'] > 0.7:\n",
    "        #     print(\"‚ö†Ô∏è  MODERATE POTENTIAL: Consider additional factors before proceeding.\")\n",
    "         # else:\n",
    "        #     print(\"‚ùå LOW POTENTIAL: This location may not be ideal for this business type.\")\n",
    "    #population end here\n",
    "\n",
    "    # Bisness Type Multiplier start here\n",
    "        Bisness_Type_Multiplier_result = get_business_type_multiplier(business_type, lat, lon, radius_km) \n",
    "    # Bisness Type Multiplier end here\n",
    "\n",
    "    # Income start here\n",
    "        income_df = fetch_avg_income_from_location(lat, lon, start_year=2020, end_year=2020)\n",
    "        json_output = income_df.to_json(orient='records', indent=2)\n",
    "    # Income end here\n",
    "\n",
    "    # Existing Competitors start here\n",
    "    Existing_Competor_analyzer = CompetitorAnalyzer()\n",
    "\n",
    "    Exising_Competitors_result = Existing_Competor_analyzer.main(\n",
    "        auto_mode=True,\n",
    "        json_output=True,\n",
    "        latitude=lat,  \n",
    "        longitude=lon, \n",
    "        radius=radius_km*1000,      \n",
    "        business_types=[business_type], \n",
    "        export=False     \n",
    "    )\n",
    "    # Existing Competitors end here\n",
    "\n",
    "    #Cultual Factors start here\n",
    "    CulturalFit_analyzer = FreeCulturalFitAnalyzer()\n",
    "    CulturalFit_analyzer_result = CulturalFit_analyzer.get_cultural_fit_score(lat, lon, business_type, radius_km*1000)\n",
    "    \n",
    "    insight_data = []\n",
    "    for insight in CulturalFit_analyzer_result['insights']:\n",
    "        insight_data.append(f\"- {insight}\")\n",
    "        \n",
    "    # Cultural fit end here\n",
    "    \n",
    "    output = {\n",
    "        'Traffic_Score': {\n",
    "            \"coordinates\": {\n",
    "                    \"latitude\": lat,\n",
    "                    \"longitude\": lon\n",
    "                },\n",
    "            \"traffic_score\": traffc_score_result['traffic_score'],\n",
    "            \"top_poi_categories\": top_categories,\n",
    "        },\n",
    "        'Market_Factor': {\n",
    "            \"market_factor\":market_factore_result['market_factor'],\n",
    "            \"confidence\": market_factore_result['confidence'],\n",
    "            \"notes\": market_factore_result['notes'],\n",
    "        },\n",
    "        'Population_Analysis': {\n",
    "            \"multiplier\": population_result['multiplier'],\n",
    "            \"confidence\": population_result['confidence'],\n",
    "            \"population_estimate\": population_result['population'],\n",
    "            \"competition_count\": population_result['competition_count'],\n",
    "            \"income_index\": population_result['income_index'],\n",
    "            \"notes\": population_result['notes'],\n",
    "        },\n",
    "        'Business_Type_Multiplier': {\n",
    "            \"multiplier\": Bisness_Type_Multiplier_result['multiplier'],\n",
    "            \"confidence\": Bisness_Type_Multiplier_result['confidence'],\n",
    "            \"global_baseline\": Bisness_Type_Multiplier_result['global_baseline'],\n",
    "            \"local_adjustment\": Bisness_Type_Multiplier_result['local_adjustment'],\n",
    "            \"population_estimate\": Bisness_Type_Multiplier_result['population_estimate'],\n",
    "            \"competition_count\": Bisness_Type_Multiplier_result['competition_count'],\n",
    "            \"notes\": Bisness_Type_Multiplier_result['notes'],\n",
    "        },\n",
    "        \"Income_Data\": {\n",
    "            \"data\":json.loads(json_output)\n",
    "        },\n",
    "        \"Existing_Competitors\": {\n",
    "            \"data\":Exising_Competitors_result\n",
    "        },\n",
    "        \"Cultural_Fit\": {\n",
    "            \"location\": CulturalFit_analyzer_result['location'],\n",
    "            \"business_type\": CulturalFit_analyzer_result['business_type'],\n",
    "            \"analysis_radius_km\": CulturalFit_analyzer_result['analysis_radius_km'],\n",
    "            \"cultural_fit_score\": CulturalFit_analyzer_result['cultural_fit_score'],\n",
    "            \"sentiment_ratio\": CulturalFit_analyzer_result['sentiment_ratio'],\n",
    "            \"insights\": insight_data\n",
    "        }\n",
    "    }\n",
    "        \n",
    "    print(json.dumps(output, indent=2))\n",
    "    time.sleep(2)  # Be nice to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status\": \"success\",\n",
      "  \"total_competitors\": 4,\n",
      "  \"search_parameters\": {\n",
      "    \"latitude\": 11.0168,\n",
      "    \"longitude\": 76.9558,\n",
      "    \"radius\": 1000,\n",
      "    \"business_types\": [\n",
      "      \"supermarket\"\n",
      "    ]\n",
      "  },\n",
      "  \"competitors\": [\n",
      "    {\n",
      "      \"name\": \"Spencers\",\n",
      "      \"type\": \"supermarket\",\n",
      "      \"distance\": 234.493622578696,\n",
      "      \"latitude\": 11.0170651,\n",
      "      \"longitude\": 76.9579314,\n",
      "      \"address\": \"Patel Road\",\n",
      "      \"google_maps_url\": \"https://www.google.com/maps?q=11.0170651,76.9579314\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Giriyaas\",\n",
      "      \"type\": \"supermarket\",\n",
      "      \"distance\": 473.6077724884785,\n",
      "      \"latitude\": 11.0168427,\n",
      "      \"longitude\": 76.960139,\n",
      "      \"address\": \"Address not specified\",\n",
      "      \"google_maps_url\": \"https://www.google.com/maps?q=11.0168427,76.960139\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"VIVEK'S\",\n",
      "      \"type\": \"supermarket\",\n",
      "      \"distance\": 706.2968141935211,\n",
      "      \"latitude\": 11.01896,\n",
      "      \"longitude\": 76.9618855,\n",
      "      \"address\": \"Address not specified\",\n",
      "      \"google_maps_url\": \"https://www.google.com/maps?q=11.01896,76.9618855\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"VIVEK'S\",\n",
      "      \"type\": \"supermarket\",\n",
      "      \"distance\": 795.9234455366184,\n",
      "      \"latitude\": 11.0191127,\n",
      "      \"longitude\": 76.9627012,\n",
      "      \"address\": \"Address not specified\",\n",
      "      \"google_maps_url\": \"https://www.google.com/maps?q=11.0191127,76.9627012\"\n",
      "    }\n",
      "  ],\n",
      "  \"statistics\": {\n",
      "    \"closest\": {\n",
      "      \"name\": \"Spencers\",\n",
      "      \"distance\": 234.493622578696,\n",
      "      \"type\": \"supermarket\"\n",
      "    },\n",
      "    \"farthest\": {\n",
      "      \"name\": \"VIVEK'S\",\n",
      "      \"distance\": 795.9234455366184,\n",
      "      \"type\": \"supermarket\"\n",
      "    },\n",
      "    \"average_distance\": 552.5804136993286,\n",
      "    \"business_density\": 1.2732406201955062,\n",
      "    \"count_by_type\": {\n",
      "      \"supermarket\": 4\n",
      "    }\n",
      "  }\n",
      "}\n",
      "{'status': 'success', 'total_competitors': 4, 'search_parameters': {'latitude': 11.0168, 'longitude': 76.9558, 'radius': 1000, 'business_types': ['supermarket']}, 'competitors': [{'name': 'Spencers', 'type': 'supermarket', 'distance': 234.493622578696, 'latitude': 11.0170651, 'longitude': 76.9579314, 'address': 'Patel Road', 'google_maps_url': 'https://www.google.com/maps?q=11.0170651,76.9579314'}, {'name': 'Giriyaas', 'type': 'supermarket', 'distance': 473.6077724884785, 'latitude': 11.0168427, 'longitude': 76.960139, 'address': 'Address not specified', 'google_maps_url': 'https://www.google.com/maps?q=11.0168427,76.960139'}, {'name': \"VIVEK'S\", 'type': 'supermarket', 'distance': 706.2968141935211, 'latitude': 11.01896, 'longitude': 76.9618855, 'address': 'Address not specified', 'google_maps_url': 'https://www.google.com/maps?q=11.01896,76.9618855'}, {'name': \"VIVEK'S\", 'type': 'supermarket', 'distance': 795.9234455366184, 'latitude': 11.0191127, 'longitude': 76.9627012, 'address': 'Address not specified', 'google_maps_url': 'https://www.google.com/maps?q=11.0191127,76.9627012'}], 'statistics': {'closest': {'name': 'Spencers', 'distance': 234.493622578696, 'type': 'supermarket'}, 'farthest': {'name': \"VIVEK'S\", 'distance': 795.9234455366184, 'type': 'supermarket'}, 'average_distance': 552.5804136993286, 'business_density': 1.2732406201955062, 'count_by_type': {'supermarket': 4}}}\n",
      "{'traffic_score': 0.6, 'poi_density': 0.08, 'population_density': 360, 'road_density': 0.0, 'poi_breakdown': {'commercial': 7, 'retail': 2, 'food': 19, 'education': 11, 'healthcare': 4, 'transport': 15, 'entertainment': 5, 'public': 5}, 'normalized_factors': {'poi': 0.0, 'population': 0.02, 'roads': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "analyzer = CompetitorAnalyzer()\n",
    "\n",
    "Exising_Competitors_result = analyzer.main(\n",
    "        auto_mode=True,\n",
    "        json_output=True,\n",
    "        latitude=11.0168,  \n",
    "        longitude=76.9558, \n",
    "        radius=1000,      \n",
    "        business_types=['supermarket'], \n",
    "        export=False     \n",
    "    )\n",
    "print(Exising_Competitors_result)\n",
    "\n",
    "lat = 40.7128\n",
    "lon = -74.0060\n",
    "business_type = \"supermarket\"  \n",
    "radius_km = 2  \n",
    "\n",
    "    # traffic score start\n",
    "calculator = TrafficScoreCalculator()\n",
    "traffc_score_result = calculator.calculate_traffic_score(lat, lon, radius_km)\n",
    "\n",
    "print(traffc_score_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
